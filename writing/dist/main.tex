\documentclass[]{article}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript

%put a newpage before sections http://blog.dreasgrech.com/2010/01/starting-new-page-with-every-section-in.html
\let\stdsection\section
\renewcommand\section{\newpage\stdsection}

% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \usepackage{fontspec}
  \ifxetex
    \usepackage{xltxtra,xunicode}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\usepackage{color}
\usepackage{fancyvrb}
\DefineShortVerb[commandchars=\\\{\}]{\|}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\newenvironment{Shaded}{}{}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
\newcommand{\RegionMarkerTok}[1]{{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
\newcommand{\NormalTok}[1]{{#1}}
\usepackage{longtable}
\usepackage{graphicx}
% We will generate all images so they have a width \maxwidth. This means
% that they will get their normal width if they fit onto the page, but
% are scaled down if they would overflow the margins.
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
\else\Gin@nat@width\fi}
\makeatother
\let\Oldincludegraphics\includegraphics
\renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=\maxwidth]{#1}}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={Jim Higson},
            pdftitle={Oboe.js: An approach to I/O for REST clients which is neither batch nor stream; nor SAX nor DOM},
            colorlinks=true,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{5}

\title{Oboe.js: An approach to I/O for REST clients which is neither batch nor
       stream; nor SAX nor DOM}
\author{Jim Higson}
\date{2013}

\begin{document}
\maketitle


{
\clearpage
\hypersetup{linkcolor=black}
\setcounter{tocdepth}{3}
\tableofcontents
}

\clearpage
\listoffigures

\clearpage

\section{Abstract}

A new design for http client libraries incorporating http streaming,
pattern matching, and incremental parsing, with the aim of improving
performance, fault tolerance, and encouraging a greater degree of loose
coupling between programs. A Javascript client capable of progressively
parsing JSON resources is presented targeting both Node.js and web
browsers. Loose coupling is particularly considered in light of the
application of Agile methodologies to REST and SOA, providing a
framework in which it is acceptable to partially restructure the JSON
format in which a resource is expressed whilst maintaining compatibility
with dependent systems.

A critique is made of current practice under which resources are
entirely retrieved before items of interest are extracted
programmatically. An alternative model is presented allowing the
specification of items of interest using a declarative syntax similar to
JSONPath. The identified items are then provided incrementally while the
resource is still downloading.

In addition to a consideration of performance in absolute terms, the
usability implications of an incremental model are also evaluated with
regards to developer ergonomics and end user perception of performance.

\section{Introduction}

This purpose of this dissertation is to encourage the REST paradigm to
be viewed through a novel lens which in application this may be used to
deliver tangible benefits to many common REST use cases. Although I
express my thesis through programming, the contribution I hope to make
is felt more strongly as a modification in how we \emph{think} about
http than as the delivery of new software.

In the interest of developer ergonomics, REST clients have tended to
style the calling of remote resources similar to the call style of the
host programming language. Depending on the language, one of two schemas
are followed: a synchronous style in which a some invocation halts
execution for the duration of the request before evaluating to the
fetched resource; or asynchronous in which the logic is specified to be
applied to a response once it is available. Languages encourage our
thinking to follow the terms that they easily support(Whorf 1956). While
there is some overlap, languages which promote concurrency though
threading consider blocking in a single thread to be acceptable and will
generally prefer the former mode whereas languages with first class
functions are naturally conversant in callbacks and will prefer the
latter. We should remember in programming that languages limit the
patterns that we readily see (Yukihiro 2003) and that better mappings
may be possible. This observation extends to graphical notations such as
UML whose constructs strongly reflect the programming languages of the
day. For any multi-packet message sent via a network some parts will
arrive before others, at least approximately in-order, but viewed from
inside a language whose statements invariably yield single, discrete
values it comfortable to conceptualise the REST response as a discrete
event. UML sequence diagrams contain the syntax for instantaneously
delivered return values, with no corresponding notation for a resource
whose data is progressively revealed.

In most practical cases where we wish to be fast in performing a task
there is no reasonable distinction between acting \emph{earlier} and
being \emph{quicker}. To create efficient software we should be using
data at the first possible opportunity: examining content \emph{while it
streams} rather than holding it unexamined until it is wholly available.

While the coining of the term REST represented a shift in how we think
about http, away from the transfer of hypertext documents to that of
arbitrary data (Fielding 2000, 407--416), it introduced no fundamentally
new methods. Similarly building on previous ideas, no new computing
techniques need be invented to realise my thesis. As a minimum it
requires an http client which reveals the response whilst it is in
progress and a parser which can begin to interpret that response before
it sees all of it. Nor is it novel to use these preexisting parts in
composition. Every current web browser already implements such a schema;
load any complex webpage -- essentially an aggregation of hypertext and
other resources -- the HTML will be parsed and displayed incrementally
while it is downloading and resources such as images are requested in
parallel as soon as they are referenced. The images may themselves be
presented incrementally in the case of progressive JPEGs or
SVGs\footnote{For quite an obviously visible example of progressive SVG
  loading, try loading this SVG using a recent version of Google Chrome:
  \url{http://upload.wikimedia.org/wikipedia/commons/0/04/Marriage_(Same-Sex_Couples)_Bill,_Second_Reading.svg}
  For the perfectionist SVG artist, not just the final image should be
  considered but also the XML source order, for example in this case it
  would be helpful if the outline of the UK appeared first and the
  exploded sections last.}. This incremental display is achieved through
highly optimised software created for a single task, that of displaying
web pages. The new contribution of this dissertation is to provide a
generic analog applicable to any problem domain.

\subsection{How REST aggregation could be faster}

\begin{figure}[htbp]
\centering
\includegraphics{images/rest_timeline_1.png}
\caption{\textbf{Sequence diagram showing the aggregation of low-level
REST resources.} A client fetches an author's publication list and then
their first three articles. This sequence represents the most commonly
used technique in which the client does not react to the response until
it is complete. In this example the second wave of requests cannot be
made until the original response is complete, at which time they are
issued in quick succession. \label{rest_timeline_1}}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{images/rest_timeline_2.png}
\caption{\textbf{Revised aggregation sequence for a client capable of
progressively interpreting the resources.} Because arrows in UML
sequence diagrams draw returned values as a one-off happening rather
than a continuous process, I have introduced a lighter arrow notation
representing fragments of an incremental response. Each request for an
individual publication is made as soon as the its URL can be extracted
from the publications list and once all required data has been read from
the original response it is aborted rather than continue to download
unnecessary data. \label{rest_timeline_2}}
\end{figure}

Figures \ref{rest_timeline_1} and \ref{rest_timeline_2} comparatively
illustrate how a progressive client may, without adjustments to the
server, be used to produce an aggregated resource sooner. This results
in a moderate improvement in the time taken to show the complete
aggregation but a dramatic improvement in the time to show the first
content. The ability to present the first content as early as possible
is a desirable trait for system usability because it allows the user to
start reading earlier and a progressively rendered display in itself
increases the human perception of speed (Geelhoed et al. 1995). Note
also how the cadence of requests is more steady in Figure
\ref{rest_timeline_2} with four connections opened at roughly equal
intervals rather than a single request followed by a rapid burst of
three. Both clients and servers routinely limit the number of
simultaneous connections per peer so avoiding bursts of requests is
further to our advantage. \hyperref[appendix_http_limits]{Appendix i}
lists some actual limits.

Nodes in an n-tier architecture defy categorisation as `client' or
`server' in a way which is appropriate from all frames of reference. A
node might be labeled as the `server' from the layer below and `client'
from the layer above. Although the ``client software'' labels in the
figures above hint at something running directly on a user's own device,
the same benefits apply if this layer is running remotely. If this layer
were generating a web page on the server-side to be displayed by the
client's browser, the perceptual speed improvements apply because of
http chunked encoding (Stefanov 2009). If this layer were a remote
aggregation service, starting to write out the aggregated response early
provides much the same benefits so long as the client is also able to
interpret it progressively and, even if it were not, the overall
delivery remains faster.

\subsection{Stepping outside the big-small tradeoff}

Where a domain model contains data in a series with continuous ranges
requestable via REST, I have often noticed a tradeoff in the client's
design with regards to how much should be requested in each call.
Because at any time it shows only a small window into a much larger
model, the social networking site Twitter might be a good example. The
Twitter interface designers adopted a popular interface pattern,
Infinite Scrolling (Ahuvia 2013). Starting from an initial page showing
some finite number of tweets, once the user scrolls and reaches the end
of the list the next batch is automatically requested. When loaded, this
new batch is converted to HTML and added to the bottom of the page.
Applied repeatedly the illusion of an infinitely long page in
maintained, albeit punctuated with pauses whenever new content is
loaded. For the programmers working on this presentation layer there is
a tradeoff between sporadically requesting many tweets, yielding long,
infrequent delays and frequently requesting a little, giving an
interface which stutters momentarily but often.

I propose that progressive loading could render this tradeoff
unnecessary by simultaneously delivering the best of both strategies. In
the Twitter example this could be achieved by making large requests but
instead of deferring all rendering until the request completes, add the
individual tweets to the page as they are incrementally parsed out of
the ongoing response. With a streaming transport, the time taken to
receive the first tweet should not vary depending on the total number
that are also being sent so there is no relationship between the size of
the request made and the time taken to first update the interface.

\subsection{Staying fast on a fallible network}

REST operates over networks whose reliability varies widely. On
unreliable networks connections are abruptly dropped and in my opinion
existing http clients handle unexpected terminations suboptimally.
Consider the everyday situation of a person using a smartphone browser
to check their email. Mobile data coverage is often weak outside of
major cities (Gill 2013) so while travelling the signal will be lost and
reestablished many times. The web developer's standard AJAX toolkit is
structured in a way that encourages early terminated connections to be
considered as wholly unsuccessful rather than as partially successful.
For example, the popular AJAX library jQuery automatically parses JSON
or XML responses before passing back to the application but given an
early disconnection there is no attempt to hand over the partial
response. To the programmer who knows where to look the partial
responses are extractable as raw text but handling them involves writing
a special case and is difficult because standard parsers are not
amenable to incomplete markup. Because of this difficulty I can only
find examples of partial messages being dropped without inspection. For
the user checking her email, even if 90\% of her inbox had been
retrieved before her phone signal was lost, the web application will
behave as if it received none and show her nothing. Later, when the
network is available again the inbox will be downloaded from scratch,
including the 90\% which previously delivered. I see much potential for
improvement here.

I propose moving away from this polarised view of
successful/unsuccessful requests to one in which identifiable parts of a
message are recognised as interesting in themselves, regardless of what
follows, and these parts are handed back to the application as streaming
occurs. This follows naturally from a conceptualisation of the http
response as a progressive stream of many small parts; as each part
arrives it should be possible to use it without knowing if the next will
be delivered successfully. Should an early disconnection occur, the
content delivered up to that point will have already been handled so no
special case is required to salvage it. In most cases the only recovery
necessary will be to make a new request for just the part that was
missed. This approach is not incompatible with a problem domain where
the usefulness of an earlier part is dependent on the correct delivery
of the whole providing optimistic locking is used. In this case earlier
parts may be used immediately but their effect rolled back should a
notification of failure be received.

\subsection{Agile methodologies, frequent deployments, and compatibility
today with versions tomorrow}

In most respects a SOA architecture fits well with the fast release
cycle encouraged by Agile methodologies. Because in SOA we may consider
that all data is local rather than global and that the components are
loosely coupled and autonomous, frequent releases of any particular
sub-system shouldn't pose a problem to the correct operation of the
whole. In allowing a design to emerge organically it should be possible
for the structure of resource formats to be realised slowly and
iteratively while a greater understanding of the problem is gained.
Unfortunately in practice the ability to change is hampered by tools
which encourage programming against rigidly specified formats. If a
program is allowed to be tightly coupled to a data format it will resist
changes in the programs which produce data to that format. Working in
enterprise I have often seen the release of dozens of components
cancelled because of a single unit that failed to meet acceptance
criteria. By insisting on exact data formats, subsystems become tightly
coupled and the perfect environment is created for contagion whereby the
updating of any single unit may only be done as part of the updating of
the whole.

An effective response to this problem would be to integrate into a REST
clients the ability to use a response whilst being only loosely coupled
to the \emph{shape} of the message.

\subsection{Deliverables}

To avoid feature creep I am paring down the software deliverables to the
smallest work which can we said to realise my thesis, the guiding
principle being that it is preferable to produce a little well than more
badly. Amongst commentators on start-up companies this is known as a
\emph{zoom-in pivot} (Reis 2011 p172) and the work it produces should be
the \emph{Minimum Viable Product} or MVP (Reis 2011 p106-110). With a
focus on quality I could not deliver a full stack so I am obliged to
implement only solutions which interoperate with existing deployments.
This is advantageous; to somebody looking to improve their system small
enhancements are more inviting than wholesale change.

To reify the vision above, a streaming client is the MVP. Because all
network transmissions may be viewed though a streaming lens an
explicitly streaming server is not required. Additionally, whilst http
servers capable of streaming are quite common even if they are not
always programmed as such, I have been unable to find any example of a
streaming-receptive REST client.

\subsection{Criteria for success}

In evaluating this project, we may say it has been a success if
non-trivial improvements in speed can be made without a corresponding
increase in the difficulty of programming the client. This improvement
may be in terms of the absolute total time required to complete a
representative task or in a user's perception of the speed in completing
the task. Because applications in the target domain are much more
io-bound than CPU-bound, optimisation in terms of the execution time of
a algorithms will be de-emphasised unless especially egregious. The
measuring of speed will include a consideration of performance
degradation due to connections which are terminated early.

Additionally, I shall be considering how the semantics of a message are
expanded as a system's design emerges and commenting on the value of
loose coupling between data formats and the programs which act on them
in avoiding disruption given unanticipated format changes.

\section{Background}

\begin{figure}[htbp]
\centering
\includegraphics{images/architecture.png}
\caption{\textbf{Labelling nodes in an n-tier architecture}. Regardless
of where a node is located, REST may be used as the means of
communication. By focusing on REST clients, nodes in the middleware and
presentation layer fall in our scope. Although network topology is often
split about client and server side, for our purposes categorisation as
tiers is a more meaningful distinction. According to this split the
client-side presentation layer and server-side presentation layer serve
the same purpose, generating mark-up based on aggregated data created in
the middle tier \label{architecture}}
\end{figure}

\subsection{The web as an application platform}

Application design has historically charted an undulating path pulled by
competing approaches of thick and thin clients. Having evolved from a
document viewing system to an application platform for all but the most
specialised tasks, the web perpetuates this narrative by resisting
categorisation as either mode.

While the trend is generally for more client scripting and for some
sites Javascript is now requisite, there are also counter-trends. In
2012 twitter reduced load times to one fifth of their previous design by
moving much of their rendering back to the server-side, commenting that
``The future is coming and it looks just like the past'' (Lea 2012).
Under this architecture short, fast-loading pages are generated on the
server-side but Javascript is also provides progressively enhancement.
Although it does not generate the page anew, the Javascript must know
how to create most of the interface elements so one weakness of this
architecture is that much of the presentation layer logic must be
expressed twice.

Despite client devices taking on responsibilities which would previously
have been performed on a server, there is a limit to how much of the
stack may safely be offloaded in this direction. The client-side
ultimately falls under the control of the user so no important business
decisions should be taken here. A banking site should not allow loan
approval to take place in the browser because for the knowledgeable user
any decision would be possible. Separated from data stores by the public
internet, the client is also a poor place to perform data aggregation or
examine large data sets. For non-trivial applications these restrictions
encourage a middle tier to execute business logic and produce aggregate
data.

While REST may not be the only communications technology employed by an
application architecture, for this project we should examine where the
REST clients fit into the picture. REST is used to pull data from
middleware for the sake of presentation regardless of where the
presentation resides. Likewise, rather than connect to databases
directly, for portability middlewares often communicate with a thin REST
layer which wraps data stores. This suggests three uses:

\begin{itemize}
\itemsep1pt\parskip0pt\parsep0pt
\item
  From web browser to middleware
\item
  From server-side presentation layer to middleware
\item
  From middleware to one or more nodes in a data tier
\end{itemize}

Fortunately, each of these contexts require a similar performance
profile. The node is essentially acting as a router dealing with small
messages containing only the information they requested rather than
dealing with a whole model. As a part of an interactive system low
latency is important whereas throughput can be increased relatively
cheaply by adding more hardware. As demand for the system increases the
total work required grows but the complexity of any one of these tasks
does remains constant. Although serving any particular request might be
done in series, the workload as a whole at these tiers consists of many
independent tasks and as such is embarrassingly parallelisable.

\subsection{Node.js}

Node.js is a general purpose tool for executing Javascript outside of a
browser. I has the aim of low-latency i/o and is used predominantly for
server applications and command line tools. It is difficult to judge to
what degree Javascript is a distraction from Node's principled design
and to what degree the language defines the platform.

In most imperative languages the thread is the basic unit of
concurrency. whereas Node presents the programmer with a single-threaded
abstraction. Threads are an effective means to share parallel
computation over multiple cores but are less well suited to scheduling
concurrent tasks which are mostly i/o dependent. Programming threads
safely with shared access to mutable objects requires great care and
experience, otherwise the programmer is liable to create race
conditions. Considering for example a Java http aggregator; because we
wish to fetch in parallel each http request is assigned to a thread.
These `requester' tasks are computationally simple: make a request, wait
for a complete response, and then participate in a Barrier to wait for
the others. Each thread consumes considerable resources but during its
multi-second lifespan requires only a fraction of a millisecond on the
CPU. It is unlikely any two requests return at exactly the same moment
so usually the threads will process in series rather than parallel
anyway. Even if they do, the actual CPU time required in making an http
request is so short that any concurrent processing is a pyrrhic victory.
Following Node's lead, traditionally thread-based environments are
beginning to embrace asynchronous, single-threaded servers. The Netty
project can be though of as roughly the Java equivalent of Node.

\begin{figure}[htbp]
\centering
\includegraphics{images/placeholder.png}
\caption{\emph{Single-threaded vs multi-threaded scheduling for a http
aggregator}}
\end{figure}

Node builds on a model of event-based, asynchronous i/o that was
established by Javascript execution in web browsers. Although Javascript
in a browser may be performing multiple tasks simultaneously, for
example requesting several resources from the server side, it does so
from within a single-threaded virtual machine. Node similarly
facilitates concurrency by managing an event loop of queued tasks and
providing exclusively non-blocking i/o. Unlike Erlang, Node does not
swap tasks out preemptively, it always waits for tasks to complete
before moving onto the next. This means that each task must complete
quickly to avoid holding up others. \emph{Prima facie} this might seem
like an onerous requirement to put on the programmer but in practice
with only non-blocking i/o each task naturally exits quickly without any
special effort. Accidental non-terminating loops or heavy
number-crunching aside, with no reason for a task to wait it is
difficult to write a node program where the tasks do not complete
quickly.

Each task in node is simply a Javascript function. Node is able to swap
its single Javascript thread between these tasks efficiently while
providing the programmer with an intuitive interface because of
closures. Utilising closures, the responsibility of maintaining state
between issuing an asynchronous call and receiving the callback is
removed from the programmer by folding it invisibly into the language.
This implicit data store requires no syntax and feels so natural and
inevitable that it is often not obvious that the responsibility exists
at all.

Consider the example below. The code schedules three tasks, each of
which are very short and exit quickly allowing Node to finely interlace
them between other concurrent concerns. The \texttt{on} method is used
to attach functions as listeners to streams. However sophisticated and
performant this style of programming, to the developer it is hardly more
difficult an expression than if a blocking io model were followed. It is
certainly easier to get right than synchronising mutable objects for
sharing between threads.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{printResourceToConsole}\NormalTok{(url) \{}

   \OtherTok{http}\NormalTok{.}\FunctionTok{get}\NormalTok{(url)}
      \NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'response'}\NormalTok{, }\KeywordTok{function}\NormalTok{(response)\{}
      
         \CommentTok{// This function will be called when the response starts.}
         \CommentTok{// It logs to the console, adds a listener and quickly exits.}
         
         \CommentTok{// Because it is captured by a closure we are able to reference }
         \CommentTok{// the url parameter after the scope that declared it has finished.            }
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"The response has started for "} \NormalTok{+ path);}
      
         \OtherTok{response}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'data'}\NormalTok{, }\KeywordTok{function}\NormalTok{(chunk) \{      }
            \CommentTok{// This function is called each time some data is received from the }
            \CommentTok{// http request. In this example we write the response to the console}
            \CommentTok{// and quickly exit.}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'Got some response '} \NormalTok{+ chunk);}
                   
         \NormalTok{\}).}\FunctionTok{on}\NormalTok{(}\StringTok{'end'}\NormalTok{, }\KeywordTok{function}\NormalTok{()\{}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'The response is complete'}\NormalTok{);}
         \NormalTok{\})}
         
      \NormalTok{\}).}\FunctionTok{on}\NormalTok{(}\StringTok{"error"}\NormalTok{, }\KeywordTok{function}\NormalTok{(e)\{}
         
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"There was an error: "} \NormalTok{+ }\OtherTok{e}\NormalTok{.}\FunctionTok{message}\NormalTok{);}
      \NormalTok{\});      }
   \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"The request has been made"}\NormalTok{);}
\NormalTok{\}   }
\end{Highlighting}
\end{Shaded}

\begin{quote}
``Node Stream API, which is the core I/O abstraction in Node.js (which
is a tool for I/O) is essentially an abstract in/out interface that can
handle any protocol/stream that also happens to be written in
JavaScript.'' (Ogden 2012)
\end{quote}

In Node i/o is performed through a unified streaming interface
regardless of the source. The streams follow a publisher-subscriber
pattern fitting comfortably with the wider event-driven model. Although
the abstraction provided by streams is quite a thin layer on top of the
host system's socket, it forms a powerful and intuitive interface. For
many tasks it is preferable to program in a `plumbing' style by joining
one stream's output to another's input. In the example below a resource
from the internet is written to the local filesystem.

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{http}\NormalTok{.}\FunctionTok{get}\NormalTok{(url)}
   \NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'response'}\NormalTok{, }\KeywordTok{function}\NormalTok{(response)\{}
      \OtherTok{response}\NormalTok{.}\FunctionTok{pipe}\NormalTok{(}\OtherTok{fs}\NormalTok{.}\FunctionTok{createWriteStream}\NormalTok{(pathToFile));}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

\subsection{Json and XML data transfer formats}

Both XML and JSON are text based, tree shaped data formats with human
and machine readability. One of the design goals of XML was to simplify
SGML to the point that a graduate student could implement a full parser
in a week (Eberhart and Fischer 2002 p287). Continuing this arc of
simpler data formats, JSON ``The fat-free alternative to XML(Douglas
2009)'' isolates Javascript's syntax for literal values into a
stand-alone serialisation language. For the graduate tackling JSON
parsing the task is simpler still, being expressible as fifteen context
free grammars.

Whereas XML's design can be traced to document formats, JSON's lineage
is in a programming language. From these roots isn't surprising that
JSON maps more directly to the metamodel that most programmers think in.
XML parsers produce Elements, Text, Attributes, ProcessingInstruction
which require extra translation before they are convenient to use inside
a programming language. Because JSON already closely resembles how a
programmer would construct a runtime model of their data, fewer steps
are required before using the deserialised form in a given programming
language. The JSON nodes: \emph{strings}, \emph{numbers}, \emph{objects}
and \emph{arrays} will in many cases map directly onto their language
types and, for loosely typed languages at least, the parser output bears
enough similarity to domain model objects that it may be used directly
without any further transformation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \DataTypeTok{people}\NormalTok{: [}
      \NormalTok{\{}\DataTypeTok{name}\NormalTok{: }\StringTok{'John'}\NormalTok{, }\DataTypeTok{town}\NormalTok{:}\StringTok{'Oxford'}\NormalTok{\},}
      \NormalTok{\{}\DataTypeTok{name}\NormalTok{: }\StringTok{'Jack'}\NormalTok{, }\DataTypeTok{town}\NormalTok{:}\StringTok{'Bristol'}\NormalTok{\}}
      \NormalTok{\{}\DataTypeTok{town}\NormalTok{:}\StringTok{'Cambridge'}\NormalTok{, }\DataTypeTok{name}\NormalTok{: }\StringTok{'Walter'}\NormalTok{\}}
   \NormalTok{]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Both JSON and XML are used to serialise to and from orderless constructs
but but while serialised to text, an ordered list of characters, the
nodes are inevitably encountered according to some serialisation order.
There is no rule forbidding serialisation to JSON or XML attributes in
an order-significant way but in general the order is considered to not
be significant in the serialised format's model. In the example above,
the people objects would probably have been written out to represent
either a class with two public properties or a hash map. On receiving
this data the text would be demarshalled into similar structures and
that the data found an ordered expression during transport would be
quickly forgotten. However, when viewing a document through a streaming
and interpreting documents while still incomplete this detail cannot be
ignored as a concern relating only to the accidents of transfer. If
nodes were interpreted based on their first field in the example above
Walter would find a different handling than the other two. Because the
serialisation will contain items which are written to follow an
indeterminate order it will be important to ensure that, despite the
streaming, the REST client does not encourage programming in a way that
depends on the order that these fields are received.

\subsection{Common patterns for connecting to REST services}

For languages such as Javascript or Clojure with a loosely-typed
representation of objects as generic key-value pairs, when a JSON REST
resource is received, the output from the parser resembles the normal
object types closely enough that it is acceptable to use it directly
throughout the program. For XML this is not the case and some marshaling
is required. In more strongly typed OO languages such as Java or C\#,
JSON's relatively freeform, classless objects are less convenient. For
the example JSON from \hyperref[jsonxml2]{the previous section} to be
smoothly consumed, instantiating instances of a domain model Person
class with methods such as \texttt{getName()} and \texttt{getTown()}
would be preferable, representing the remote resource's objects no
differently than if they had originated locally. Automatic marshaling
generalises this process by providing a two-way mapping between the
domain model and its serialisation, either completely automatically or
based on a declarative specification. It is common in strongly typed
languages for REST client libraries to automatically demarshal as part
of receiving a fetched rest response. From the programmer's vantage it
is as if the domain objects themselves had been fetched. Adding an
additional layer, another common design pattern intended to give a
degree of isolation between remote resources and the local domain model
is to demarshal automatically only so far as \emph{Data Transfer
Objects} (DTOs). DTOs are instances of classes which implement no logic
other than storage, and from these DTOs the domain model objects may be
programmatically instantiated. DTOs are more necessary when using XML.
For reading JSON resources we might say that the JSON objects \emph{are}
the DTOs.

The degree of marshaling that is used generally changes only the types
of the entities that the REST client library hands over to the
application developer without affecting the overall structure of the
message. Regardless of the exact types given, having received the
response model the developer will usually start by addressing the
pertinent parts of the response by drilling down into the structures
using assessor operators from the programming language itself.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Java example - programmatic approach to domain model interrogation }

\CommentTok{// The methods used to drill down to desired components }
\CommentTok{// are all getters: getPeople, getName, and getTown.}
 
\DataTypeTok{void} \FunctionTok{handleResponse}\NormalTok{( RestResponse response ) \{}

   \KeywordTok{for}\NormalTok{( Person p : response.}\FunctionTok{getPeople}\NormalTok{() ) \{}
      \FunctionTok{addPersonToDb}\NormalTok{( p.}\FunctionTok{getName}\NormalTok{(), p.}\FunctionTok{getTown}\NormalTok{() );}
   \NormalTok{\}   }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// equivalent Javascript - the programming follows the same basic}
\CommentTok{// process. This time using Javascript's dot operator.}

\KeywordTok{function} \FunctionTok{handleResponse}\NormalTok{( response )\{}

   \OtherTok{response}\NormalTok{.}\OtherTok{people}\NormalTok{.}\FunctionTok{forEach}\NormalTok{( }\KeywordTok{function}\NormalTok{( person )\{}
      \FunctionTok{addPersonToDb}\NormalTok{( }\OtherTok{p}\NormalTok{.}\FunctionTok{name}\NormalTok{, }\OtherTok{p}\NormalTok{.}\FunctionTok{town} \NormalTok{);}
   \NormalTok{\});}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

One weakness in this means of drilling down is that the code making the
inspection is quite tightly coupled to the precise structure of the
thing that it is inspecting. Taking the above example, if the resource
being fetched were later refactored such that the town concept were
refactored into a fuller address with a town-county-country tuple, the
code addressing the structure would also have to change just to continue
to do the same thing. Although this kind of drill-down programming is
commonly practiced and not generally recognised as a code smell,
requiring knock-on changes when an unrelated system is refactored seems
to me as undesirable here as it would be anywhere else.

In \emph{the Red Queen's race} it took ``all the running you can do, to
keep in the same place''. Ideally as a programmer I'd like to expend
effort to make my code to do something new, or to perform something that
it already did better, not so that it keeps the same. Following an
object oriented encapsulation of data such that a caller does not have
to concern themselves with the data structures behind an interface, the
internal implementation may be changed without disruptions to the rest
of the code base. However when the structure of the inter-object
composition is revised, isolation from the changes is less often
recognised as a desirable trait. A method of programming which truly
embraced extreme programming would allow structural refactoring to occur
without disparate, parts having to be modified in parallel.

Extraneous changes also dilute a VCS changelog, making it less easily to
later follow a narrative of code changes which are intrinsic to the
difference in logic expressed by the program, and therefore harder to
later understand the thinking behind the change and the reason for the
change.

\subsection{JsonPath and XPath selector languages}

\label{jsonpathxpath}

The problem of drilling down to pertinent fragments of a message without
tightly coupling to the format could be somewhat solved if instead of
programmatically descending step-by-step, a language were used which
allows the right amount of specificity regarding which parts to select.
For markup languages there are associated query languages whose coupling
is loose enough that not every node that is descended through must be
specified. The best known is XPATH but there is also JSONPath, a JSON
equivalent (Goessner 2007).

As far as possible the JSONPath language follows the javascript to
descend into the same sub-tree.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// in Javascript we can get the town of the second person as:}
\KeywordTok{let} \NormalTok{town = }\OtherTok{subject}\NormalTok{.}\FunctionTok{people}\NormalTok{[}\DecValTok{2}\NormalTok{].}\FunctionTok{town}

\CommentTok{// the equivalent JSONPath expression is identical:}
\KeywordTok{let} \NormalTok{townSelector = }\StringTok{"people[2].town"}

\CommentTok{// We would be wise not to write overly-specific selectors.}
\CommentTok{// JSONPath also provides an ancestor relationship not found in Javascript:}
\KeywordTok{let} \NormalTok{betterTownSelector = }\StringTok{"people[2]..town"}
\end{Highlighting}
\end{Shaded}

Consider the resource below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \DataTypeTok{people}\NormalTok{: [}
      \NormalTok{\{}\DataTypeTok{name}\NormalTok{: }\StringTok{'John'}\NormalTok{, }\DataTypeTok{town}\NormalTok{:}\StringTok{'Oxford'}\NormalTok{\},}
      \NormalTok{\{}\DataTypeTok{name}\NormalTok{: }\StringTok{'Jack'}\NormalTok{, }\DataTypeTok{town}\NormalTok{:}\StringTok{'Bristol'}\NormalTok{\}}
      \NormalTok{\{}\DataTypeTok{town}\NormalTok{:}\StringTok{'Cambridge'}\NormalTok{, }\DataTypeTok{name}\NormalTok{: }\StringTok{'Walter'}\NormalTok{\}}
   \NormalTok{]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The JSONPath \texttt{people.*..town} against the above JSON format would
continue to select correctly after a refactor to the JSON below:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \DataTypeTok{people}\NormalTok{: [}
      \NormalTok{\{  }\DataTypeTok{name}\NormalTok{: }\StringTok{'John'}\NormalTok{, }
         \DataTypeTok{address}\NormalTok{:\{}\DataTypeTok{town}\NormalTok{:}\StringTok{'Oxford'}\NormalTok{, }\DataTypeTok{county}\NormalTok{:}\StringTok{'Oxon'}\NormalTok{, }\DataTypeTok{country}\NormalTok{:}\StringTok{'uk'}\NormalTok{\}}
      \NormalTok{\},}
      \NormalTok{\{  }\DataTypeTok{name}\NormalTok{: }\StringTok{'Jack'}\NormalTok{,}
         \DataTypeTok{address}\NormalTok{:\{}\DataTypeTok{town}\NormalTok{:}\StringTok{'Bristol'}\NormalTok{, }\DataTypeTok{county}\NormalTok{:}\StringTok{'Bristol'}\NormalTok{, }\DataTypeTok{country}\NormalTok{:}\StringTok{'uk'}\NormalTok{\}}
      \NormalTok{\}}
      \NormalTok{\{  }\DataTypeTok{address}\NormalTok{:\{}
            \DataTypeTok{town}\NormalTok{:}\StringTok{'Cambridge'}\NormalTok{, }\DataTypeTok{county}\NormalTok{:}\StringTok{'Cambridgeshire'}\NormalTok{, }
            \DataTypeTok{country}\NormalTok{:}\StringTok{'uk'}
         \NormalTok{\},}
         \DataTypeTok{name}\NormalTok{: }\StringTok{'Walter'}
      \NormalTok{\}}
   \NormalTok{]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Maintaining compatibility with unanticipated format revisions through
selector languages is easier with JSON than XML. The XML metamodel
contains overlapping representations of equivalent entities which a
refactored format is liable to switch between. Each XML element has two
distinct lists of child nodes, attribute children and node list
children; from one perspective attributes are child nodes of their
parent element but they can alternatively be considered as data stored
in the element. Because of this classification ambiguity an XML document
doesn't form a single, correct n-way tree. Because of the difference in
expressivity between attributes which may only be strings and child
nodes which allow recursive structure, this is a common refactor when a
more detailed mapping is required and a scalar value is upgraded to be
compound. XPath selectors written in the most natural way do not track
this change.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{<people>}
   \KeywordTok{<person}\OtherTok{ name=}\StringTok{"John"}\OtherTok{ town=}\StringTok{"Oxford"}\KeywordTok{></person>}
\KeywordTok{</people>}
\end{Highlighting}
\end{Shaded}

The XPath \texttt{//person@town} matches the XML above but because of
the refactor from attribute to child element fails to match the revised
version below.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{<people>}
   \KeywordTok{<person>}
      \KeywordTok{<name>}
         \NormalTok{John}
      \KeywordTok{</name>}
      \KeywordTok{<address>}
         \KeywordTok{<town>}\NormalTok{Oxford}\KeywordTok{</town>} \KeywordTok{<county>}\NormalTok{Oxon}\KeywordTok{</county>}
      \KeywordTok{</address>}
   \KeywordTok{</person>}
\KeywordTok{</people>}
\end{Highlighting}
\end{Shaded}

Reflecting its dual purpose for marking up for documents or data, XML
also invites ambiguous interpretation of the whitespace between tags.
Whitespace is usually meaningful for documents but ignorable for data.
Strictly, whitespace text nodes are a part of the document but in
practice many tree walkers discard them as insignificant. In the XML
above the \texttt{\textless{}person\textgreater{}} element may be
enumerated as either the first or second child of
\texttt{\textless{}people\textgreater{}} depending on whether the
whitespace before it is considered. Likewise, the text inside
\texttt{\textless{}name\textgreater{}} might be \texttt{'John'} or
\texttt{'(newline)(tab)(tab)John'}. Inherited from JSON's programming
language ancestry, the space between tokens is never significant.

Programming against a changing service is always going to be a moving
target, but it is easier to miss with XPATH than with JSON. In JSON each
nodes has only one, unambiguous set of children so the metamodel does
not present the format author with a selection from logical equivalents
that are addressed through different mechanisms. If a scalar value is
updated to a compound only the node itself changes, the addressing of
the node is unaffected.

Generally in descriptive hierarchical data there is a trend for
ancestorship to denote the same relationship between concepts regardless
of the number of intermediate generations. In the example above,
\texttt{town} transitioned from child to grandchild of \texttt{person}
without disturbing the implicit `lives in' relationship. In JSONPath the
\texttt{..} operator provides matching through zero or more generations,
unperturbed when extra levels are added. Of course, this trend will not
hold for every conceivable way of building message semantics because it
is possible that an intermediate node on the path from ancestor to
descendant will change the nature of the expressed relationship. A
slightly contrived example might be if we expanded our model to contain
fuzzy knowledge:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{<people>}
   \KeywordTok{<person>}
      \KeywordTok{<name>}
         \KeywordTok{<isProbably>}\NormalTok{Bob}\KeywordTok{</isProbably>}
      \KeywordTok{</name>}
   \KeywordTok{</person>}
\KeywordTok{</people>}
\end{Highlighting}
\end{Shaded}

Considering the general case, it will not be possible to track all
possible service refactors safely. By necessity a resource consumer
should limit their ambitions to tracking ontology additions which do not
change the meaning of the existing concepts. In practice integration
testing against the beta version of a service will be necessary to be
pre-warned of upcoming, incompatible changes. If an incompatibility is
found the ability to then create an expression which is compatible with
with a present and known future version remains a valuable tool because
it decouples service consumer and provider update schedules, removing
the need for the client to march perfectly in sync with the service.

\subsection{Browser XML Http Request (XHR)}

Making http requests from Javascript, commonly termed AJAX, was so
significant in establishing the modern web architecture that it is
sometimes used synonymously with Javascript-rich web applications.
Although AJAX is an acronym for \textbf{A}synchronous
\textbf{J}avascript (\textbf{a}nd) \textbf{X}ML, this reflects the early
millennial enthusiasm for XML as the one true data format and in
practice any textual format may be transferred. Today JSON is generally
preferred, especially for delivery to client-side web applications.
During the `browser war' years web browsers competed by adding
non-standard features; Internet Explorer made AJAX possible in 2000 by
exposing Microsoft's Active X \emph{Xml Http Request} (XHR) class to the
Javascript sandbox. This was widely copied and near equivalents were
added to all major browsers. In 2006 the interface was eventually
formalised by the W3C (van Kesteren and Jackson 2006). XHR's slow
progresss to standardisation reflected a period of general stagnation
for web standards. HTML4 reached Recommendation status in 2001 but
having subsequently found several evolutionary dead ends such as XHTML,
there would be no major updates until HTML5 started to gather pace some
ten years later.

Despite a reputation for being poorly standardised, as a language
Javascript enjoys consistent implementation. More accurately we would
say that browser APIs exposed to Javascript lack compatibility. Given
this backdrop of vendor extensions and lagging standardisation,
abstraction layers predictably rose in popularity. Various abstractions
competed primarily on developer ergonomics with the popular jQuery and
Prototype.js libraries promoting themselves as \emph{``do more, write
less''} and \emph{``elegant APIs around the clumsy interfaces of
Ajax''}. Written against the unadorned browser, Javascript applications
read as a maze of platform-detection and special cases. Once
applications were built using Javascript abstractions over the
underlying browser differences, they could be written purposefully and
were able to express more complex ideas without becoming
incomprehensible.

JSON is today the main format output by REST end points when requesting
via AJAX. Javascript programmers occupy a privileged position whereby
their serialisation format maps exactly onto the inbuilt types of their
programming language. As such there is never any confusion regarding
which object structure to de-serialise to. Should this advantage seem
insubstantial, contrast with the plethora of confusing and incompatible
representations of JSON that are output by the various Java parsers:
JSON's Object better resembles Java's Map interface than Java Objects,
creating linguistic difficulties, and the confusion between JSON null,
Java null, and Jackson's NullNode\footnote{See
  \url{http://jackson.codehaus.org/1.0.1/javadoc/org/codehaus/jackson/node/NullNode.html}.}
is a common cause of errors. Emboldened by certainty regarding
deserialisation, AJAX libraries directly integrated JSON parsers,
providing a call style for working with remote resources so streamlined
as to require hardly any additional effort.

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{jQuery}\NormalTok{.}\FunctionTok{ajax}\NormalTok{(}\StringTok{'http://example.com/people.json'}\NormalTok{, }\KeywordTok{function}\NormalTok{( people ) \{}

   \CommentTok{// The parsing of the people json into a javascript object}
   \CommentTok{// feels so natural that it is easy to forget from looking }
   \CommentTok{// at the code that parsing happens at all. }
   
   \FunctionTok{alert}\NormalTok{(}\StringTok{'the first person is called '} \NormalTok{+ people[}\DecValTok{0}\NormalTok{].}\FunctionTok{name}\NormalTok{);}
\NormalTok{\});}
\end{Highlighting}
\end{Shaded}

\subsection{XHRs and streaming}

\label{xhrsandstreaming}

Browser abstraction layers brought an improvement in expressivity to web
application programming but were ultimately limited to supporting the
lowest common denominator of the available browser abilities. At the
time that the call style above was developed the most popular browser
gave no means of access to partial responses. Inevitably, it draws a
conceptualisation of the response as a one-time event with no
accommodation offered for progressively delivered data.

The followup standard, XHR2 is now at Working Draft stage. Given
ambitions to build a streaming REST client, of greatest interest is the
progress event:

\begin{quote}
While the download is progressing, queue a task to fire a progress event
named progress about every 50ms or for every byte received, whichever is
least frequent. (van Kesteren 2012)
\end{quote}

The historic lack of streaming for data fetched using XHR stands
incongruously with the browser as a platform in which almost every other
remote resource is interpreted progressively. Examples include
progressive image formats, html, svg, video, and Javascript itself
(script interpretation starts before the script is fully loaded).

The progress event is supported by the latest version of all major
browsers. However, Internet Explorer only added support recently with
version 10 and there is a significant user base remaining on versions 8
and 9.

\subsection{Browser streaming frameworks}

\label{browserstreamingframeworks}

The web's remit is increasingly widening to encompass scenarios which
would have previously been the domain of native applications. In order
to use live data many current webapps employ frameworks which push soft
real-time events to the client side. In comparison to the XHR2 progress
event, this form of streaming has a different but overlapping purpose.
Whereas XHR2 enables downloads to be viewed as short-lived streams but
does not otherwise disrupt the sequence of http's request-response
model, streaming frameworks facilitate an entirely different sequence,
that of perpetual data. Consider a webmail interface; initially the
user's inbox is downloaded via REST and a streaming download might be
used to speed its display. Regardless of if the response is interpreted
progressively, this inbox download is a standard REST call and shares
little in common with the push events which follow to provide instant
notification as new messages arrive.

\textbf{Push tables} sidestep the browser's absent data streaming
abilities by leaning on a resource that it can stream: progressive html.
From the client a page containing a table is hidden in an off-screen
iframe. This table is served from a a page that never completes, fed by
a connection that never closes. When the server wishes to push a message
to the client it writes a new row in this table which is then noticed by
Javascript monitoring the iframe on the client. More recently,
\textbf{Websockets} is a new standard that builds a standardised
streaming transport on top of http's chunked mode. Websockets requires
browser implementation and cannot be retrofitted to older browsers
through Javascript. Websockets are a promising technology but for the
time being patchy support means it cannot be used without a suitable
fallback.

These frameworks do not interoperate at all with REST. Because the
resources they serve never complete they may not be read by a standard
REST client. Unlike REST they also are not amenable to standard http
mechanics such as caching. A server which writes to an esoteric format
requiring a specific, known, specialised client also feels quite
anti-REST, especially when we consider that the format design reflects
the nature of the transport more so than the resource. This form of
streaming is not, however, entirely alien to a SOA mindset. The data
formats, while not designed primarily for human readability are
nontheless text based and a person may take a peek inside the system's
plumbing simply by observing the traffic at a particular URL. In the
case of push-tables, an actual table of the event's properties may be
viewed from a browser as the messages are streamed.

\subsection{Parsing: SAX and Dom}

From the XML world two standard parser types exist, SAX and DOM, with
DOM by far the more popular. Although the terms originate in XML, both
styles of parsers are also available for JSON. DOM performs a parse as a
single evaluation and returns a single object model representing the
whole of the document. Conversely, SAX parsers are probably better
considered as tokenisers, providing a very low-level event driven
interface following the Observer pattern that notifies the programmer of
each token separately as it is found. From DOM's level of abstraction
the markup syntax is a distant concern whereas for SAX each element's
opening and closing tag is noted so the developer may not put the data's
serialisation aside. SAX has the advantages that it may read a document
progressively and has lower memory requirements because it does not
store the parsed tree. Correspondingly, it it popular for embedded
systems on limited hardware which need to handle documents larger than
the available RAM.

Suppose we have some json representing people and want to extract the
name of the first person. Given a DOM parser this may be written quite
succinctly:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{nameOfFirstPerson}\NormalTok{( myJsonString ) \{}

   \CommentTok{// All recent browsers provide JSON.parse as standard. }

   \KeywordTok{var} \NormalTok{document = }\OtherTok{JSON}\NormalTok{.}\FunctionTok{parse}\NormalTok{( myJsonString );}
   \KeywordTok{return} \OtherTok{document}\NormalTok{.}\FunctionTok{people}\NormalTok{[}\DecValTok{0}\NormalTok{].}\FunctionTok{name}\NormalTok{; }\CommentTok{// that was easy!}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

To contrast, the equivalent below uses SAX, expressed in the most
natural way for the technology.\footnote{For an example closer to the
  real world see
  \url{https://github.com/dscape/clarinet/blob/master/samples/twitter.js}.}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{nameOfFirstPerson}\NormalTok{( myJsonString, callbackFunction )\{}


   \KeywordTok{var} \NormalTok{clarinet = }\OtherTok{clarinet}\NormalTok{.}\FunctionTok{parser}\NormalTok{(),}
   
       \CommentTok{// With a SAX parser it is the developer's responsibility }
       \CommentTok{// to track where in the document the cursor currently is,}
       \CommentTok{// Several variables are used to maintain this state.        }
       \NormalTok{inPeopleArray = }\KeywordTok{false}\NormalTok{,   }
       \NormalTok{inPersonObject = }\KeywordTok{false}\NormalTok{,}
       \NormalTok{inNameAttribute = }\KeywordTok{false}\NormalTok{,}
       \NormalTok{found = }\KeywordTok{false}\NormalTok{;}
   
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{onopenarray} \NormalTok{= }\KeywordTok{function}\NormalTok{()\{}
      \CommentTok{// For brevity we'll cheat by assuming there is only one}
      \CommentTok{// array in the document. In practice this would be overly}
      \CommentTok{// brittle.}
      
      \NormalTok{inPeopleArray = }\KeywordTok{true}\NormalTok{; }
   \NormalTok{\};}
   
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{onclosearray} \NormalTok{= }\KeywordTok{function}\NormalTok{()\{}
      \NormalTok{inPeopleArray = }\KeywordTok{false}\NormalTok{;}
   \NormalTok{\};   }
   
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{onopenobject} \NormalTok{= }\KeywordTok{function}\NormalTok{()\{}
      \NormalTok{inPersonObject = inPeopleArray; }
   \NormalTok{\};}
   
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{oncloseobject} \NormalTok{= }\KeywordTok{function}\NormalTok{()\{}
      \NormalTok{inPersonObject = }\KeywordTok{false}\NormalTok{;}
   \NormalTok{\};   }
      
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{onkey} \NormalTok{= }\KeywordTok{function}\NormalTok{(key)\{}
      \NormalTok{inNameAttribute = ( inPeopleObject && key == }\StringTok{'name'}\NormalTok{);}
   \NormalTok{\};}

   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{onvalue} \NormalTok{= }\KeywordTok{function}\NormalTok{(value)\{}
      \KeywordTok{if}\NormalTok{( !found && inNameAttribute ) \{}
         \CommentTok{// finally!}
         \FunctionTok{callbackFunction}\NormalTok{( value );}
         \NormalTok{found = }\KeywordTok{true}\NormalTok{;}
      \NormalTok{\}}
   \NormalTok{\};      }
   
   \OtherTok{clarinet}\NormalTok{.}\FunctionTok{write}\NormalTok{(myJsonString);   }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The developer pays a high price for progressive parsing, the SAX version
is considerably longer and more difficult to read. SAX's low-level
semantics require a lengthy expression and push the responsibility of
maintaining state regarding the current position in the document and the
nodes that have previously been seen onto the programmer. This
maintenance of state tends to programmed once per usage rather than
assembled as the composition of reusable parts. I find the order of the
code under SAX quite unintuitive; event handlers cover multiple
unrelated cases and each concern spans multiple handlers. This lends to
a style of programming in which separate concerns do not find separate
expression in the code. It is also notable that, unlike DOM, as the
depth of the document being interpreted increases, the length of the
programming required to interpret it also increases, mandating more
state be stored and an increased number of cases be covered per event
handler.

While SAX addresses many of the problems raised in this dissertation, I
find the unfriendly developer ergonomics pose too high a barrier to its
adoption for all but fringe uses.

\section{Design and Reflection:}

Using a combination of techniques from the previous chapter I propose
that it is possible to combine the desirable properties from SAX and DOM
parsers into a REST client library which allows streaming but is also
convenient to program.

By observing the flow of data streams through a SAX parser we can say
that the REST workflow is more efficient if we do not wait until we have
everything before we start using the parts that we do have. However, the
SAX model presents poor developer ergonomics because it is not usually
convenient to think on the level of abstraction that it presents: that
of markup tokens. Using SAX, a programmer may only operate on a
convenient abstraction after inferring it from a lengthy series of
callbacks. In terms of ease of use, DOM is generally preferred because
it provides the resource whole and in a convenient form. My design aims
to duplicate this convenience and combine it with progressive
interpretation by removing one restriction: that the node which is given
is always the document root. From a hierarchical markup such as XML or
JSON, when read in order, the sub-trees are fully known before we fully
know their parent tree. We may select pertinent parts of a document and
deliver them as fully-formed entities as soon as they are known, without
waiting for the remainder of the document to arrive.

By my design, identifying the interesting parts of a document before it
is complete involves turning the established model for drilling-down
inside-out. Under asynchronous I/O the programmer's callback
traditionally receives the whole resource and then, inside the callback,
locates the sub-parts that are required for a particular task. Inverting
this process, I propose extracting the locating logic currently found
inside the callback and using it to decide when the callback should be
used. The callback will receive complete fragments from the response
once they have been selected according to this logic.

I will be implementing using the Javascript language because it has good
support for non-blocking I/O and covers both contexts where this project
will be most useful: in-browser programming and server programming.
Focusing on the MVP, I will only be implementing the parsing of one
mark-up language. Although this technique could be applied to any
text-based, tree-shaped markup, I find that JSON best meets my goals
because it is widely supported, easy to parse, and because it defines a
single n-way tree, is amenable to selectors which span multiple format
versions.

JSONPath is especially applicable to node selection as a document is
read because it specifies only constraints on paths and `contains'
relationships. Because of the top-down serialisation order, on
encountering any node in a serialised JSON stream, I will have already
seen enough of the prior document to know its full path. JSONPath would
not be so amenable if it expressed sibling relationships because there
is no similar guarantee of having seen other nodes on the same level
when any particular node is encountered. A new implementation of the
language is required because the existing JSONPath library is
implemented only as a means to search through already gathered objects
and is too narrow in applicability to be useful in our context.

Not all of the JSONPath language is well suited when we consider we are
selecting specifically inside a REST resource. Given this context it is
likely that we will not be examining a full model but rather a subset
that we requested and was assembled on our behalf according to the
parameters that we supplied. We can expect to be interested in all of
the content so search-style selections such as `books costing less than
X' are less useful than queries which identify nodes because of their
type and position such as `all books in the discount set', or, because
we know we are examining \texttt{/books/discount}, simply `all books'.
In creating a new JSONPath implementation I have chosen to follow the
existing language somewhat loosely, thereby specialising the matching
and avoiding unnecessary code. It is difficult to anticipate what the
real-world matching requirements will be but if I deliver now the 20\%
of possible features that I'm reasonably sure will be used for 80\% of
tasks, for the time being any functionality which is not covered may be
implemented inside the callbacks themselves and later added to the
selection language. For example, somebody wishing to filter on the price
of books might use branching to further select inside their callback. I
anticipate that the selections will frequently involve types so it is
useful to analyse the nature of type imposition with regards to JSON.

\subsection{Detecting types in JSON}

JSON markup describes only a few basic types. On a certain level this is
also true for XML -- most nodes are either of type Element or Text.
However, the XML metamodel provides tagnames; essentially, a built-in
type system for subclassifying the elements. JSON has no similar notion
of types beyond the basic constructs: array, object, string, number. To
understand data written in JSON's largely typeless model it is often
useful if we think in terms of a more complex type system. This
imposition of type is the responsibility of the observer rather than of
the observed. The reader of a document is free to choose the taxonomy
they will use to interpret it and this decision will vary depending on
the purposes of the reader. The required specificity of taxonomy differs
by the level of involvement in a field. Whereas `watch' may be a
reasonable type for most data consumers, to a horologist it is likely to
be unsatisfactory without further sub-types. To serve disparate
purposes, the JSONPath variant provided for node selection will have no
inbuilt concept of type, the aim being to support programmers in
creating their own.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{<!--  XML leaves no doubt as to the labels we give to an Element's type.}
\CommentTok{      Although we might further interpret, this is a 'person' -->}
\KeywordTok{<person}\OtherTok{  name=}\StringTok{'...'}\OtherTok{ gender=}\StringTok{"male"}
\OtherTok{         age=}\StringTok{"45"}\OtherTok{ height=}\StringTok{"175cm"}\OtherTok{ profession=}\StringTok{"architect"}\KeywordTok{>}
\KeywordTok{</person>}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/*    JSON meanwhile provides no built-in type concept. }
\CommentTok{      This node's type might be 'thing', 'animal', 'human', 'male', 'man', }
\CommentTok{      'architect', 'artist' or any other of many overlapping impositions }
\CommentTok{      depending on our reason for examining this data */}
\NormalTok{\{  }\StringTok{"name"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"gender"}\NormalTok{:}\StringTok{"male"}\NormalTok{, }\StringTok{"age"}\NormalTok{:}\StringTok{"45"} 
   \StringTok{"height"}\NormalTok{:}\StringTok{"172cm"} \StringTok{"profession"}\NormalTok{:}\StringTok{"architect"}\NormalTok{>}
\NormalTok{\}         }
\end{Highlighting}
\end{Shaded}

In the absence of node typing beyond categorisation as objects, arrays
and various primitives, the key immediately mapping to an object is
often taken as a loose marker of its type. In the below example we may
impose the the type `address' prior to examining the contents because of
the field name in the parent node.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \StringTok{"name"}\NormalTok{: }\StringTok{""}
\NormalTok{,  }\StringTok{"residence"}\NormalTok{: \{}
      \StringTok{"address"}\NormalTok{: [}
         \StringTok{"47"}\NormalTok{, }\StringTok{"Cloud street"}\NormalTok{, }\StringTok{"Dreamytown"}
      \NormalTok{]}
   \NormalTok{\}}
\NormalTok{,  }\StringTok{"employer"}\NormalTok{: \{}
      \StringTok{"name"}\NormalTok{: }\StringTok{"Mega ultra-corp"}
   \NormalTok{,  }\StringTok{"address"}\NormalTok{:[}
         \StringTok{"Floor 2"}\NormalTok{, }\StringTok{"The Offices"}\NormalTok{, }\StringTok{"Alvediston"}\NormalTok{, }\StringTok{"Wiltshire"}      
      \NormalTok{]}
   \NormalTok{\}   }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This means of imposing type is simply expressed in JSONPath. The
selector \texttt{address} would match all nodes whose parent maps to
them via an address key.

As a loosely typed language, Javascript gives no protection against
lists which store disparate types but by sensible convention this is
avoided. Likewise, in JSON, although type is a loose concept, the items
in a collection will generally be of the same type. From here follows a
sister convention illustrated in the example below, whereby each item
from an array is typed according to the key in the grandparent node
which maps to the array.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \StringTok{"residences"}\NormalTok{: \{}
      \StringTok{"addresses"}\NormalTok{: [}
         \NormalTok{[}\StringTok{"10"}\NormalTok{, }\StringTok{"Downing street"}\NormalTok{, }\StringTok{"London"}\NormalTok{]}
      \NormalTok{,  [}\StringTok{"Chequers Court"}\NormalTok{, }\StringTok{"Ellesborough, "}\NormalTok{Buckinghamshire}\StringTok{"]      }
      \NormalTok{,  [}\StringTok{"Beach Hut"}\NormalTok{, }\StringTok{"Secret Island"}\NormalTok{, }\StringTok{"Bahamas"}\NormalTok{]}
      \NormalTok{]}
   \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

In the above JSON, \texttt{addresses.*} would correctly identify the
addresses. The pluralisation of field names such as `address' becoming
`addresses' is common when marshaling from OO languages because the JSON
keys are based on getters whose name typically reflects their
cardinality; \texttt{public Address getAddress()} or
\texttt{public List\textless{}Address\textgreater{} getAddresses()}.
This may pose a problem in some cases and it would be interesting in
future to investigate a system such as Ruby on Rails that natively
understands English pluralisation. I considered introducing unions as an
easy way to cover this situation, allowing expressions resembling
\texttt{address\textbar{}addresses.*} but decided that it is simpler if
this problem is solves outside of the JSONPath language if the
programmer registers two selection specifications against the same
handler function.

In the below example types may not be easily inferred from ancestor
keys.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
   \StringTok{"name"}\NormalTok{: }\StringTok{"..."}
\NormalTok{,  }\StringTok{"residence"}\NormalTok{: \{}
      \StringTok{"number"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"street"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"town"}\NormalTok{:}\StringTok{"..."} 
   \NormalTok{\}}
\NormalTok{,  }\StringTok{"employer"}\NormalTok{:\{}
      \StringTok{"name"}\NormalTok{: }\StringTok{"..."}
   \NormalTok{,  }\StringTok{"premises"}\NormalTok{:[}
         \NormalTok{\{ }\StringTok{"number"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"street"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"town"}\NormalTok{:}\StringTok{"..."} \NormalTok{\}}
      \NormalTok{,  \{ }\StringTok{"number"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"street"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"town"}\NormalTok{:}\StringTok{"..."} \NormalTok{\}}
      \NormalTok{,  \{ }\StringTok{"number"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"street"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"town"}\NormalTok{:}\StringTok{"..."} \NormalTok{\}}
      \NormalTok{]}
   \NormalTok{,  }\StringTok{"registeredOffice"}\NormalTok{:\{}
         \StringTok{"number"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"street"}\NormalTok{:}\StringTok{"..."}\NormalTok{, }\StringTok{"town"}\NormalTok{:}\StringTok{"..."}
      \NormalTok{\}}
   \NormalTok{\}}
\NormalTok{\}  }
\end{Highlighting}
\end{Shaded}

Here, the keys which map onto addresses are named by the relationship
between the parent and child nodes rather than by the type of the child.
The type classification problem could be solved using an ontology with
`address' subtypes `residence', `premises', and `office' but this
solution feels quite heavyweight for a simple selection language. I
chose instead to import the idea of \emph{duck typing} from Python
programing, as named in a 2000 usenet discussion:

\begin{quote}
In other words, don't check whether it IS-a duck: check whether it
QUACKS-like-a duck, WALKS-like-a duck, etc, etc, depending on exactly
what subset of duck-like behaviour you need (Martelli 2000)
\end{quote}

A `duck-definition' for the above JSON would be any object which has
number, street, and town properties. We take an individualistic approach
by deriving type from the node in itself rather than the situation in
which it occurs. Because I find this selection technique simple and
powerful I decided to add it to my JSONPath variant. As discussed in
section \ref{jsonpathxpath}, JSONPath's syntax is designed to resemble
the equivalent Javascript accessors, but Javascript has no syntax for a
value-free list of object keys. The closest available notation is for
object literals so I created a duck-type syntax derived from this by
omitting the values, quotation marks, and commas. The address type
described above would be written as \texttt{\{number street town\}}.
Field order is insignificant so \texttt{\{a b\}} and \texttt{\{b a\}}
are equivalent.

It is difficult to generalise but when selecting items from a document I
believe it will often be useful if nodes which are covariant with the
given type are also matched. We may consider that there is a root duck
type \texttt{\{\}} which matches any node, that we create a
sub-duck-type if we add to the list of required fields, and a
super-duck-type if we remove from it. Because in OOP extended classes
may add new fields, this idea of the attribute list expanding for a
sub-type applies neatly to JSON REST resources marshaled from an OO
representation. In implementation, to conform to a duck-type a node must
have all of the required fields but could also have any others.

\subsection{Importing CSS4's explicit capturing to Oboe's JSONPath}

JSONPath naturally expresses a `contained in' relationship using the dot
notation but no provision is made for the inverse `containing'
relationship. \emph{Cascading Style Sheets}, CSS, the web's styling
language, has historically shared this restriction but a proposal for
extended selectors which is currently at Editor's Draft stage (Etemad
and Atkins 2013) introduces an elegant solution. Rather than add an
explicit `containing' relationship, the draft observes that previously
CSS has always selected the element conforming to the right-most of the
selector terms, allowing only the deepest mentioned element to be
styled. This restriction is lifted by allowing terms to be prefixed with
\texttt{\$} in order to make them explicitly capturing; a selector
without an explicit capturing term continues to work as before. The CSS
selector \texttt{form.important input.mandatory} selects mandatory
inputs inside important forms but
\texttt{\$form.important input.mandatory} selects important forms with
mandatory fields.

The new css4 capturing technique will be adapted for Oboe JSONPath. By
duplicating a syntax which the majority of web developers should become
familiar with over the next few years I hope that Oboe's learning curve
can be made a little more gradual. Taking on this feature, the selector
\texttt{person.\$address.town} would identify an address node with a
town child, or \texttt{\$people.\{name, dob\}} would provide the people
array repeatedly whenever a new person is added to it. Javascript
frameworks such as d3.js and Angular are designed to work with whole
models as they change. Consequently, the interface they present
converses more fluently with collections than individual entities. If we
are downloading data to use with these libraries it is more convenient
if we use explicit capturing so that we are notified whenever the
collection is expanded and can pass it on.

\subsection{Parsing the JSON Response}

While SAX parsers provide an unappealing interface to application
developers, as a starting point to handle low-level parsing in
higher-level libraries they work very well (most XML DOM parsers are
built in this way). The pre-existing Clarinet project is well tested,
liberally licenced, and compact, meeting our needs perfectly. The name
of this project, Oboe.js, was chosen in tribute to the value delivered
by Clarinet.

\subsection{API design}

Everything that Oboe is designed to do can already be achieved by
combining a SAX parser with imperatively coded node selection. This has
not been adopted widely because it requires verbose, difficult
programming in a style which is unfamiliar to most programmers. With
this in mind it is a high priority to design a public API for Oboe which
is concise, simple, and resembles other commonly used tools. If Oboe's
API is made similar to common tools, a lesser modification should be
required to switch existing projects to streaming http.

For some common use cases it should be possible to create an API which
is a close enough equivalent to popular tools that it can be used as a
direct drop-in replacement. Although used in this way no progressive
loading would be enacted, when refactoring towards a goal the first step
is often to create a new expression of the same logic (Martin 2008,
212). By giving basic support for non-progressive downloading, the door
is open for apps to incrementally refactor towards a progressive
expression. Allowing adoption as a series of small, easily manageable
steps rather than a single leap is especially helpful for teams working
under Scrum because all work must fit within a fairly short timeframe.

jQuery is by far the most popular library for AJAX today. The basic call
style for making an AJAX GET request is as follows:

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{jQuery}\NormalTok{.}\FunctionTok{ajax}\NormalTok{(}\StringTok{"resources/shortMessage.txt"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{done}\NormalTok{(}\KeywordTok{function}\NormalTok{( text ) \{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\StringTok{"Got the text: "} \NormalTok{+ text ); }
   \NormalTok{\}).}
   \NormalTok{.}\FunctionTok{fail}\NormalTok{(}\KeywordTok{function}\NormalTok{() \{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\StringTok{"the request failed"} \NormalTok{);      }
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

While jQuery is callback-based and internally event driven, the public
API it exposes does not wrap asynchronously retrieved content in event
objects. Event type is expressed by the name of the method used to add
the listener. These names, \texttt{done} and \texttt{fail}, follow
generic phrasing and are common to every functionality that jQuery
provides asynchronously. Promoting brevity, the methods are chainable so
that several listeners may be added from one statement. Although
Javascript supports exception throwing, a fail event is used. Exceptions
are not applicable to non-blocking I/O because at the time of the
failure the call which provoked the exception will have already been
popped from the call stack.

\texttt{jQuery.ajax} is overloaded and the parameter may be an object,
allowing more information to be given:

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{jQuery}\NormalTok{.}\FunctionTok{ajax}\NormalTok{(\{ }\StringTok{"url"}\NormalTok{:}\StringTok{"resources/shortMessage.txt"}\NormalTok{,}
              \StringTok{"accepts"}\NormalTok{: }\StringTok{"text/plain"}\NormalTok{,}
              \StringTok{"headers"}\NormalTok{: \{ }\StringTok{"X-MY-COOKIE"}\NormalTok{: }\StringTok{"123ABC"} \NormalTok{\}}
           \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

This pattern of passing arguments as an object literal is common in
Javascript for functions which take a large number of arguments,
particularly if some are optional. This avoids having to pad unprovided
optional arguments in the middle of the list with null values and,
because the purpose of the values is apparent from the callee, also
avoids an anti-pattern where a callsite can only be understood after
counting the position of the arguments.

Taking on this style while extending it to cover events for progressive
parsing, we arrive at the following Oboe public API:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(}\StringTok{"resources/people.json"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{node}\NormalTok{( }\StringTok{"person.name"}\NormalTok{, }\KeywordTok{function}\NormalTok{(name, path, ancestors) \{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"There is somebody called "} \NormalTok{+ name);   }
   \NormalTok{\})}
   \NormalTok{.}\FunctionTok{done}\NormalTok{( }\KeywordTok{function}\NormalTok{( wholeJson ) \{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"That is everyone!"}\NormalTok{);}
   \NormalTok{\})}
   \NormalTok{.}\FunctionTok{fail}\NormalTok{( }\KeywordTok{function}\NormalTok{() \{}
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"Actually, the download failed. Please forget "} \NormalTok{+ }
                  \StringTok{"the people I just told you about"}\NormalTok{);}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

In jQuery only one \texttt{done} handler is usually added to a request;
the whole content is always given so there is only one thing to receive.
Under Oboe there will usually be several separately selected areas of
interest inside a JSON document so I anticipate that typically multiple
handlers will be added. A shortcut style is provided for adding several
selector/handler pairs at a time:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(}\StringTok{"resources/people.json"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{node}\NormalTok{(\{  }
      \StringTok{"person.name"}\NormalTok{: }\KeywordTok{function}\NormalTok{(personName, path, ancestors) \{}
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"Let me tell you about "} \NormalTok{+ name + }\StringTok{"..."}\NormalTok{);}
      \NormalTok{\},}
      \StringTok{"person.address.town"}\NormalTok{: }\KeywordTok{function}\NormalTok{(townName, path, ancestors) \{}
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{"they live in "} \NormalTok{+ townName);}
      \NormalTok{\}}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

Note the \texttt{path} and \texttt{ancestors} parameters in the examples
above. These provide additional information regarding the context in
which the identified node was found. Consider the following JSON:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{ }
   \StringTok{"event"}\NormalTok{: }\StringTok{"Mens' 100m sprint"}\NormalTok{,}
   \StringTok{"date"}\NormalTok{: }\StringTok{"5 Aug 2012"}\NormalTok{,}
   \StringTok{"medalWinners"}\NormalTok{: \{}
      \StringTok{"gold"}\NormalTok{:     \{}\StringTok{"name"}\NormalTok{: }\StringTok{"Bolt"}\NormalTok{,    }\StringTok{"time"}\NormalTok{: }\StringTok{"9.63s"}\NormalTok{\},}
      \StringTok{"silver"}\NormalTok{:   \{}\StringTok{"name"}\NormalTok{: }\StringTok{"Blake"}\NormalTok{,   }\StringTok{"time"}\NormalTok{: }\StringTok{"9.75s"}\NormalTok{\},}
      \StringTok{"bronze"}\NormalTok{:   \{}\StringTok{"name"}\NormalTok{: }\StringTok{"Gatlin"}\NormalTok{,  }\StringTok{"time"}\NormalTok{: }\StringTok{"9.79s"}\NormalTok{\}}
   \NormalTok{\}}
\NormalTok{\}  }
\end{Highlighting}
\end{Shaded}

In this JSON we may extract the runners using the pattern
\texttt{\{name time\}} or \texttt{medalWinners.*} but nodes alone are
insufficient because their location communicates information which is as
important as their content. The \texttt{path} parameter provides the
location as an array of strings plotting a descent from the JSON root to
the found node. For example, Bolt has path
\texttt{{[}'medalWinners', 'gold'{]}}. Similarly, the \texttt{ancestors}
array is a list of the ancestors starting at the immediate parent of the
found node and ending with the JSON root node. For all but the root
node, which in any case has no ancestors, the nodes in the ancestor list
will have been only partially parsed.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(}\StringTok{"resources/someJson.json"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{node}\NormalTok{( }\StringTok{"medalWinners.*"}\NormalTok{, }\KeywordTok{function}\NormalTok{(person, path) \{}
   
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\OtherTok{person}\NormalTok{.}\FunctionTok{name} \NormalTok{+ }\StringTok{" won the "} \NormalTok{+ }\FunctionTok{lastOf}\NormalTok{(path) + }\StringTok{" medal "}
         \NormalTok{+ }\StringTok{"with a time of "} \NormalTok{+ }\OtherTok{person}\NormalTok{.}\FunctionTok{time} \NormalTok{);}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

Being loosely typed, Javascript would not enforce that ternary callbacks
are used as selection handlers. Given that before a callback is made the
application programmer must have provided a JSONPath selector for the
locations in the document she is interested in, for most JSON formats
the content alone is sufficient. The API design orders the callback
parameters so that in most common cases a unary or binary function can
be given.

Using Node.js the code style is more obviously event-based. Listeners
are normally added using an \texttt{.on} method and the event name is a
string given as the first argument. Adopting this style, my API design
for oboe.js also allows events to be added as:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(}\StringTok{"resources/someJson.json"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{on}\NormalTok{( }\StringTok{"node"}\NormalTok{, }\StringTok{"medalWinners.*"}\NormalTok{, }\KeywordTok{function}\NormalTok{(person) \{}
   
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\StringTok{"Well done "} \NormalTok{+ }\OtherTok{person}\NormalTok{.}\FunctionTok{name} \NormalTok{);}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

While allowing both styles creates an API which is larger than it needs
to be, creating a library which is targeted at both the client and
server side is a ballance between self-consistency spanning environments
and consistency \emph{with} the environment, I hope this will help
adoption by either camp. The two styles are similar enough that a person
familiar with one should be able to work with the other without
difficulty. Implementating the duplicative parts of the API should
require only a minimal degree of extra coding because they may be
expressed in common using partial completion. Because \texttt{'!'} is
the JSONPath for the root of the document, for some callback \texttt{c},
\texttt{.done(c)} is a equal to \texttt{.node('!', c)}. Likewise,
\texttt{.node} is easily expressible as a partial completion of
\texttt{.on} with \texttt{'node'}. Below a thin interface layer may
share a commonb implementation.

\emph{API allows body to be given as Object and converts into JSON
because it is anticipated that REST services which emmit JSON will also
accept it}

\subsection{Earlier callbacks when paths are found prior to nodes}

Following with the project's aim of giving callbacks as early as
possible, sometimes useful work can be done when a node is known to
exist but before we have the contents of the node. This means that each
node found in a JSON document can potentially trigger notifications at
two points: when it is first addressed and when it is complete. The API
facilitates this by providing a \texttt{path} event following much the
same pattern as \texttt{node}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(}\StringTok{"events.json"}\NormalTok{)}
   \NormalTok{.}\FunctionTok{path}\NormalTok{( }\StringTok{"medalWinners"}\NormalTok{, }\KeywordTok{function}\NormalTok{() \{}
      \CommentTok{// We don"t know the winners yet but we know we have some so let"s}
      \CommentTok{// start drawing the table already:    }
      \OtherTok{gui}\NormalTok{.}\FunctionTok{showMedalTable}\NormalTok{();}
   \NormalTok{\})}
   \NormalTok{.}\FunctionTok{node}\NormalTok{( }\StringTok{"medalWinners.*"}\NormalTok{, }\KeywordTok{function}\NormalTok{(person, path) \{    }
      \KeywordTok{let} \NormalTok{metal = }\FunctionTok{lastOf}\NormalTok{(path);}
      \OtherTok{gui}\NormalTok{.}\FunctionTok{addPersonToMedalTable}\NormalTok{(person, metal);}
   \NormalTok{\})}
   \NormalTok{.}\FunctionTok{fail}\NormalTok{( }\KeywordTok{function}\NormalTok{()\{}
      \CommentTok{// That didn"t work. Revert!}
      \OtherTok{gui}\NormalTok{.}\FunctionTok{hideMedalTable}\NormalTok{();}
   \NormalTok{\});}
\end{Highlighting}
\end{Shaded}

Implementing path notifications requires little extra code, requiring
JSONPath expressions can be evaluated when items are found in addition
to when they are completed.

\subsection{Choice of streaming data transport}

As discussed in section \ref{browserstreamingframeworks}, current
techniques to provide streaming over http encourage a dichotomous split
of traffic as either stream or download. I find that this split is not
necessary and that streaming may be used as the most effective means of
downloading. Streaming services implemented using push pages or
websockets are not REST. Under these frameworks a stream has a URL
address but data in the stream is not addressable. This is similar to
STREST, the \emph{Service Trampled REST} anti-pattern (Cragg 2006), in
which http URLs are viewed as locating endpoints for services rather
than the actual resources. Being unaddressable, the data in the stream
is also uncacheable: an event which is streamed live cannot later, when
it is historic, be retrieved from a cache which was populated by the
stream. These frameworks use http as the underlying transport but I find
they do not follow http's principled design. Because of these concerns,
in the browser I will only be supporting downloading using XHR.

Although I am designing Oboe as a client for ordinary REST resources and
not focusing on the library a means to receive live events, it is
interesting to speculate if Oboe could be used as a REST-compatible
bridge to unify live and static data. Consider a REST service which
gives the results per-constituency for a UK general election. Requesting
historic results, the data is delivered in JSON format much as usual.
Requesting the results for the current year on the night of the
election, an incomplete JSON with the constituencies known so far would
be immediately sent, followed by the remainder sent individually as the
results are called. When all results are known the JSON would finally
close leaving a complete resource. A few days later, somebody wishing to
fetch the results would use the \emph{same url for the historic data as
was used on the night for the live data}. This is possible because the
URL refers only to the data that is required, not to whether it is
current or historic. Because it eventually formed a complete http
response, the data that was streamed is not incompatible with http
caching and a cache which saw the data when it was live could store it
as usual and later serve it as historic. More sophisticated intermediate
caches sitting on the network between client and service recognise when
a new request has the same url as an already ongoing request, serve the
response received so far, and then continue by giving both inbound
requests the content as it arrives from the already established outbound
request. Hence, the resource would be cacheable even while the election
results are streaming. An application developer programming with Oboe
would not have to handle live and historic data as separate cases
because the node and path events they receive are the same. Without
branching, the code which displays results as they are announced would
automatically be able to show historic data.

Taking this idea one step further, Oboe might be used for infinite data
which intentionally never completes. In principle this is not
incompatible with http caching although more research would have to be
done into how current caches handle requests which do not finish. A REST
service which serves infinite resources would have to confirm that it is
delivering to a streaming client, perhaps with a request header.
Otherwise, if a non-streaming REST client were to use the service it
would try to get `all' of the data and never complete its task.

Supporting only XHR as a transport unfortunately means that on older
browsers which do not fire progress events (see section
\ref{xhrsandstreaming}) a progressive conceptualisation of the data
transfer is not possible. I will not be using streaming workarounds such
as push tables because this would create a client which is unable to
connect to the majority of REST services. Degrading gracefully, the best
compatible behaviour is to wait until the document completes and then
interpret the whole content as if it were streamed. Because nothing is
done until the request is complete the callbacks will be fired later
than on a more capable platform but will have the same content and be in
the same order. By reverting to non-progressive AJAX on legacy platforms
application authors will not have to write special cases and the
performance should be no worse than with a traditional ajax library such
as jQuery. On legacy browsers Oboe could not be used to receive live
data because nothing can be read before the request finishes. In the
election results example, no constituencies would be shown until they
had all been called.

Node's standard http library provides a view of the response as a
standard ReadableStream so there will be no problems programming to a
progressive interpretation of http. In Node all streams provide a common
API regardless of their origin so there is no reason not to allow
arbitrary streams to be read. Although Oboe is intended primarily as a
REST client, under Node it will be capable of reading data from any
source. Oboe might be used to read from a local file, an ftp server, a
cryptography source, or the process's standard input.

\subsection{Handling transport failures}

Oboe cannot know the correct behaviour when a connection is lost so this
decision is left to the containing application. Generally on request
failure one of two behaviours are expected: if the actions performed in
response to data so far remains valid in the absence of a full
transmission their effects will be kept and a new request made for just
the missed part; alternatively, if all the data is required for the
actions to be valid, the application should take an optimistic locking
approach and perform a rollback.

\subsection{Oboe.js as a Micro-Library}

Http traffic is often compressed using gzip so that it transfers more
quickly, particularly for entropy-sparse text formats such as
Javascript. Measuring a library's download footprint it usually makes
more sense to compare post-compression. For the sake of adoption smaller
is better because site creators are sensitive to the download size of
their sites. Javascript micro-libraries are listed at
\href{http://microjs.com}{microjs.com}, which includes this project, a
library qualifies as being \emph{micro} if it is delivered in 5kb or
less, 5120 bytes. Micro-libraries tend to follow the ethos that it is
better for an application developer to gather together several tiny
libraries than find one with a one-size-fits-all approach, perhaps
echoing the unix command line tradition for small programs which each do
do exactly one thing. As well as being a small library, in the spirit of
a micro-library a project should impose as few restrictions as possible
on its use and be be agnostic as to which other libraries or programming
styles it will be combined with. Oboe feels on the edge of what is
possible to elegantly do as a micro-library so while the limit is
somewhat arbitrary, and keeping below this limit whilst writing readable
code provides an interesting extra challenge.

\section{Implementation}

\subsection{Components of the project}

\begin{figure}[htbp]
\centering
\includegraphics{images/overallDesign.png}
\caption{\textbf{Major components that make up Oboe.js} illustrating
program flow from http transport to registered callbacks. Every
component is not shown here. Particularly, components whose
responsibility it is to initialise the oboe instance but have no role
once it is running are omitted. UML facet/receptacle notation is used to
show the flow of events with event names in capitals.
\label{overallDesign}}
\end{figure}

Oboe's architecture has been designed to so that I may have as much
confidence as possible regarding the correct working of the library
through automated testing. Designing a system to be amenable to testing
in this case meant splitting into many co-operating parts each with an
easily specified remit.

Internally, communication between components is facilitated by an event
bus which is local to to Oboe instance. Most components interact solely
by picking up events, processing them and publishing further events in
response. Essentially, Oboe's architecture resembles a fairly linear
pipeline visiting a series of units, starting with http data and
sometimes ending with callbacks being notified. This use of an event bus
is a variation on the Observer pattern which removes the need for each
unit to obtain a reference to the previous one so that it may observe
it, giving a highly decoupled shape to the library. Once everything is
wired into the bus very little central control is required and the
larger behaviours emerge as the consequence of this interaction between
finer ones. One downside is perhaps that a central event bus does not
lend itself to a UML class diagram, giving a diagram shape with an event
bus as a central hub and everything else hanging off it as spokes.

\subsection{Automated testing}

Automated testing improves what can be written, not just making what is
written more reliable. Tests deal with the problem of ``irreducible
complexity'' - when a program is made out of parts whose correct
behaviour cannot be observed without all of the program. Allows smaller
units to be verified before verifying the whole.

\begin{figure}[htbp]
\centering
\includegraphics{images/testPyramid.png}
\caption{\textbf{The test pyramid}. Relying on the assumption that
verification of small parts provides a solid base from which to compose
system-level behaviours. A Lot of testing is done on the low-level
components of the system, less on the component level and less still on
a whole-system level where only smoke tests are provided.
\label{testpyramid}}
\end{figure}

The testing itself is a non-trivial undertaking with 80\% of code
written for this project being test specifications. Based on the idea
that a correct system must be built from individually correct units, the
majority of the specifications are unit tests, putting each unit under
the microscope and describing the correct behaviour as completely as
possible. Component tests zoom out from examining individual components
to focus on their correct composition, falsifying only the http traffic.
To avoid testing implementation details the component tests do not look
at the means of coupling between the code units but rather check for the
behaviours which should emerge as a consequence of their composition. At
the apex of the test pyramid are a small number of integration tests.
These verify Oboe as a black box without any knowledge of, or access to
the internals, using only the APIs which are exposed to application
programmers. When running the integration tests a REST service is first
spun up so that correctness of the whole library may be examined against
an actual server.

The desire to be amenable to testing influences the boundaries on which
the application splits into components. Confidently black box testing a
stateful unit as is difficult; because of side-effects it may later
react differently to the same calls. For this reason where state is
required it is stored in very simple state-storing units with intricate
program logic removed. The logic may then be separately expressed as
functions which map from one state to the next. Although comprehensive
coverage is of course impossible and tests are inevitably incomplete,
for whatever results the functions give while under test, uninfluenced
by state I can be sure that they will continue to give in any future
situation. The separate unit holding the state is trivial to test,
having exactly one responsibility: to store the result of a function
call and later pass that result to the next function. This approach
clearly breaks with object oriented style encapsulation by not hiding
data behind the logic which acts on them but I feel the departure is
worthwhile for the greater certainty it allows over the correct
functioning of the program.

Dual-implementation of same interface for streamingHttp might be
considered polymorphism, but a function not a class and both are never
loaded at run time.

Largely for the sake of testing Oboe has also embraced dependency
injection. This means that components do not create the further
components that they require but rather rely on them being provided by
an external wiring. The file \texttt{wire.js} performs the actual
injection. One such example is the streamingHttp component which hides
various incompatible http implementations by publishing their downloaded
content progressively via the event bus. This unit does not know how to
create the underlying browser XHR which it hides. Undoubtedly, by not
instantiating its own dependencies a it presents a less friendly
interface, although this is mitigated somewhat by the interface being
purely internal, the objects it depends on are no longer a hidden
implementation detail but exposed as a part of the component's API. The
advantage of dependency injection here is that unit testing is much
simpler. Unit tests should test exactly one behaviour of one unit. Were
the streaming http object to create its own transport, that part would
also be under test, plus whichever external service that it connects to.
Because Javascript allows redefinition of built in types, this could be
avoided by overwriting the XHR constructor to return a mock but
modifying the built in types for tests opens up the possibilities of
changes leaking between cases. Dependency injection allows a much
simpler test style because it is trivial to inject a stub in place of
the XHR.

Integration tests run against a node service which returns known content
according to known timings, somewhat emulating downloading via a slow
internet connection. For example, the url \texttt{/tenSlowNumbers}
writes out a JSON array of the first ten natural numbers at a rate of
one per second, while \texttt{/echoBackHeaders} writes back the http
headers that it received as a JSON object. The test specifications which
use these services interact with Oboe through the public API alone as an
application author would and try some tricky cases. For example,
requesting ten numbers but registering a listener against the fifth and
aborting the request on seeing it. The correct behaviour is to get no
callback for the sixth, even when running on platforms where the http is
buffered so that all ten will have already been downloaded. \emph{ref
apx for streamsource}

\subsection{Running the tests}

\begin{figure}[htbp]
\centering
\includegraphics{images/placeholder.png}
\caption{\textbf{Relationship between various files and test libraries}
\emph{other half of sketch from notebook}}
\end{figure}

The Grunt task runner was used to automate routine tasks such as
executing the tests and building. Unit and component tests run
automatically whenever a source file changes. As well as being correct
execution, the project is required to not surpass a certain size so the
built size is also checked. As a small, tightly focused project the
majority of programming is refactoring already working code. Running
tests on save provides quick feedback so that mistakes are found as soon
as they are made. Agile practitioners emphasise the importance of tests
that execute quickly (Martin 2008, T9), the 220 unit and component tests
run in less than a second so discovering mistakes is near instant. If
the ``content of any medium is always another medium'' (McLuhan 1964
p8), we might say that the content of programming is the program that is
realised by its execution. A person working in arts and crafts sees the
thing as they work but a programmer will usually not see the execution
simultaneously as they program. Conway observed that an artisan works by
transform-in-place ``start with the working material in place and you
step by step transform it into its final form'' whereas software is
created through intermediate proxies, and attempts to close this gap by
merging programming with the results of programming (Conway 2004
side8-9). When we bring together the medium and the message the cost of
small experimentation is very low and I feel that programming becomes
more explorative and expressive.

The integration tests are not run on save because they intentionally
simulate slow transfers and take some time to run. The integration tests
are used as a final check against built code before a branch in git can
be merged into the master. Once the code has been packaged for
distribution the internals are no longer visible the integration tests
which are coded against the public API are the only runnable tests.
While these tests don't individually test every component, they are
designed to exercise the whole codebase so that a mistake in any
component will be visible through them. Grunt executes the build,
including starting up the test REST services that give the integration
tests something to fetch.

\subsection{Packaging as a single, distributable file}

\begin{figure}[htbp]
\centering
\includegraphics{images/placeholder.png}
\caption{\textbf{Packaging of many javascript files into multiple
single-file packages.} The packages are individually targeted at
different execution contexts, either browsers or node \emph{get from
notebook, split sketch diagram in half}}
\end{figure}

As an interpreted language, Javascript may of course be ran directly
without any prior compilation. While running the same code as I see in
the editor is convenient while programming, it is much less so for
distribution. Although the languages imposes no compulsory build phase,
in practice one is necessary. Dependency managers have not yet become
standard for client-side web development (although Bower is looking
good) so most files are manually downloaded. For a developer wishing to
include my library in their own project a single file is much more
convenient. Should they not have a build process of their own, a single
file is also much faster to transfer to their users, mostly because of
the cost of establishing connections and the http overhead.

Javascript files are interpreted in series by the browser so load-time
dependencies must precede dependants. Unsurprisingly, separate files
once concatenated following the same order as delivered to the browser
will load more quickly but are functionally equivalent, at least barring
syntax errors. Several tools exist to automate this stage of the build
process, incorporating a topological sort of the dependency digraph in
order to find a working concatenation order.

Early in this project I chose \emph{Require.js} although I later moved
on because it was too heavyweight. Javascript as a language doesn't have
an import statement. Require contributes the importing ability to
Javascript from inside the language sandbox as the \texttt{require}
function, a standard asynchronous call. Calls to \texttt{require} AJAX
in and execute the imported source, returning any exported symbols by a
callback. For non-trivial applications this mode is intended mostly for
debugging; because a network hop is involved the protocol is chatty and
slowed by highly latent calls between modules. For efficient delivery
Require also has the \texttt{optimise} command which concatenates into a
single file by using static analysis to deduce a workable source order.
Because \texttt{require} may appear anywhere in the source, this in the
general case is of course undecidable so Require falls back to lazy
loading. In practice undecidability isn't a problem because imports are
generally not subject to branching. In larger webapps lazy loading
speeding up the initial page load and is actually an advantage. The
technique of \emph{Asynchronous Module Definition} (AMD) intentionally
imports rarely-loaded modules in response to events. By resisting the
static analysis the units will not be downloaded until they are needed.

AMD is mostly of interest to web applications with a central hub but
also some rarely used parts. Oboe does not fit this profile: everybody
who uses it will use all of the library. Regardless, I hoped to use
\texttt{optimise} to generate my combined Javascript file. Even after
optimisation, Require's design necessitates that calls to
\texttt{require} stay in the code and that the require.js run-time
component is available to handle these calls. For a micro-library a ???k
overhead was too large to accommodate. Overall, Require seems more
suited to developing stand-alone applications than programming
libraries.

Having abandoned Require, I decided to pick up the simplest tool which
could possibly work. With only 15 source files and a fairly sparse
dependency graph finding a working order on paper wasn't a daunting
task. Combined with a Grunt analogue to the unix \texttt{cat} command I
quickly had a working build process. I adjusted each Javascript file to,
when loaded directly, place its API in the global namespace, then
post-concatenation wrapped the combined in a single function, converting
the APIs inside the function from global to the scope of that function,
thereby hiding the implementation for code outside of Oboe.

For future consideration there is Browserify. This library reverses the
`browser first' image of Javascript by converting applications targeted
at Node into a single file efficiently packaged for delivery to a web
browser, conceptually making Node the primary environment for Javascript
and adapting browser execution to match. Significantly, require leaves
no trace of itself in the concatenated Javascript other than Adaptors
presenting browser APIs as the Node equivalents. Browserify's http
adaptor\footnote{\href{https://github.com/substack/http-browserify}{Https://github.com/substack/http-browserify}.}
is complete but more verbose compared to Oboe's version\footnote{\href{https://github.com/jimhigson/oboe.js/blob/master/src/streamingXhr.js}{Https://github.com/jimhigson/oboe.js/blob/master/src/streamingXhr.js}
  This version is shorter mostly because it is not a generic solution.}.

As well as combining into a single file, Javascript source can made
significantly smaller by removing comments and reducing inaccessible
tokens to a single character. For Oboe the popular library \emph{Uglify}
is used for minification. Uglify performs only surface optimisations,
operating on the AST level but concentrating mostly on compact syntax. I
also considered Google's Closure compiler. Closure resembles a
traditional compiler optimiser by leveraging a deeper understanding to
search for smaller representations, unfortunately at the cost of safety.
Decidability in highly dynamic languages is often impossible and Closure
operates on a well-advised subset of Javascript, delivering no
reasonable guarantee of equivalence when code is not written as the
Closure authors expected. Integration tests should catch any such
failures but for the time being I have a limited appetite for a workflow
which forces me to be suspicious of the project's build process.

\subsection{Styles of Programming}

The implementation of Oboe is mixed paradigm. Events flow throughout the
whole library but in terms of code style the components are a mix of
procedural, functional and object-oriented programming. Object
orientation is used only to wrap the library in an Object-oriented
public API and as a tuple-like store for multiple values. Constructors
are not used, nor is there any inheritance or notable polymorphism.
Closures, not objects, are used as the primary means of data storage and
hiding. Many of the entities painted in figure \ref{overallDesign} map
onto no single, addressable language construct and exist only as a set
of event handlers trapped inside the same closure, taking advantage of
the fact that their reachability from some event emitter prevents
required parameters from being garbage collected. From outside the
closure hidden values are not only private as would be seen in an OO
model, they are inherently unaddressable. Although only sparingly OO,
the high-level design's componentisation hasn't departed from how it
might be implemented in an OO metamodel and Object Oriented design
patterns remain influential despite being only loosely followed.

Because of the pressures on code size I decided not to use a general
purpose functional library and instead create my own with only the parts
that I need; see functional.js. Functional programming in Javascript is
known to be slower than other styles, particularly under Firefox because
it lacks Lambda Lifting and other similar optimisations (Guo 2013).
Considering to what degree performance concerns should dissuade us from
a functional style, we may consider the library's execution context.
Because of the single-threaded model any application's Javascript
execution is in between frames serving concurrent concerns so to
minimise the impact on latency for the other tasks it is important that
no task occupies the CPU for very long. On the browser about 16ms is a
fair maximum, allowing painting to occur at 60 frames per second. In
Node there is no hard limit but any CPU-hogging task degrades the
responsiveness of other responses. Context switching imposes a very low
overhead and responsive sharing generally proffers many small frames
over a few larger ones. In any case, server-side tasks especially are
more often i/o bound than CPU bound. Oboe's progressive design naturally
splits tasks which would otherwise be performed in a single frame over
many. For example, parsing and marshaling. Although the overall
computation may be higher, the total performance of the system should be
improved.

Javascript is of course an imperative language but over many iterations
Oboe has tended towards a declarative style. In
incrementalContentBuilder.js programming was initially stateful and
procedural, reading like the instructions to perform a task. Over many
refactors the flavour of the code has changed, the reading now tending
towards a description of desired behaviour.

\subsection{Incrementally building up the content}

As shown in figure \ref{overallDesign}, there is an incremental content
builder and ascent tracer which handle the output from the Clarinet JSON
SAX parser. Taken together, these might be considered a variant of the
Adaptor pattern, providing to the controller a simpler interface than is
presented by Clarinet. However, this is not the model implementation of
the pattern; the adapted interface is even-driven rather than
call-driven: we receive six kinds of event and in response emmit from a
narrower vocabulary of two.

To evaluate JSONPath expressions the controller requires a path to the
current JSON node, the node itself, and any ancestor nodes. This is
delivered by the incremental content builder as the payload of the
NODE\_FOUND and PATH\_FOUND events. For each Clarinet event the builder
provides a corresponding function which, working from the current path,
returns the next path after the event has been applied. For example, the
\texttt{objectopen} and \texttt{arrayopen} events move the current node
deeper in the document and are handled by adding new items to the path,
whereas for \texttt{closeobject} and \texttt{closearray} we remove one.
Over the course of parsing a complete JSON file the path will in this
way be manipulated to visit every node, allowing each to be tested
against the registered JSONPath expressions. Internally, the builder's
event handlers are declared as the combination of a smaller number of
basic reusable handler parts. Oboe is largely unconcerned regarding a
JSON node's type so given that several of the Clarinet events differ
only by the type of the nodes they announce, Oboe is able to generify
their handling by composing from a common pool of handler-parts. Picking
up \texttt{openobject} and \texttt{openarray} events, both fall through
to the same `nodeFound', differing only in a parameter. Similarly,
consider the \texttt{value} event which is fired when Clarinet
encounters a String or Number. Because primitive nodes are always leaves
the builder regards this as a node which instantaneously starts and
ends, handled programmatically as the functional composition of the
\texttt{nodeFound} and \texttt{curNodeFinished}. The reuse of smaller
instructions to build up larger ones is perhaps slightly reminiscent of
CISC CPU design in which micro-instructions are combined to implement
the chip's advertised interface.

Although the builder functions are stateless, ultimately the state
regarding the current path needs to be stored between clarinet calls.
This is handled by the ascent tracker. This tiny component merely serves
as a holder for this data, starting from an empty path it passes the
path to each builder function and stores the result to be given to the
next one.

\begin{figure}[htbp]
\centering
\includegraphics{images/ascent.png}
\caption{List representation of an ascent from leaf to root of a JSON
tree. Note the special ROOT token which represents the path mapping to
the root node (of course nothing maps to the root) - this is an object,
taking advantage of object identity to ensure that the token is unequal
to anything but itself. This list form is built up by the incremental
content builder and is the format that compiled JSONPath expressions
test against for matches \label{ascent}}
\end{figure}

The path of the current node is maintained as a singly linked list, with
each list element holding the field name and the node and the node
itself, see figure \ref{ascent}. The list is arranged with the JSON root
at the far end and the current node at the head. As we traverse the JSON
the current node is appended and removed many times whereas the root is
immutable. This ordering was chosen because it is computationally very
efficient since all updates to the list are at the head. Each link in
the list is immutable, enforced by newer Javascript engines as frozen
objects.\footnote{See
  \url{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global\textbackslash{}_Objects/Object/freeze}.
  Although older engines don't provide any ability to create immutable
  objects at run-time, we can be fairly certain that the code does not
  mutate these objects or the tests would fail when run in environments
  which are able to enforce this.}

Linked lists were chosen in preference to the more conventional approach
of using native Javascript Arrays for several reasons. Firstly, I find
this area of the program more easy to test and debug given immutable
data structures. Handling native Arrays without mutating would be very
expensive because on each new path the array would have to be copied
rather than edited in-place. Unpicking a stack trace is easier if I know
that every value revealed is the value that has always occupied that
space because I don't have to think four-dimensionally projecting my
mind forwards and back in time to different values that were there when
the variable was used. The lack of side effects means I can try explore
new commands in the debugger's CLI without worrying about breaking the
execution of the program. Most Javascript virtual machines are also
quite poor at array growing and shrinking so for collections whose size
changes often are outperformed by linked lists. Finally, this is a very
convenient format for the JSONPath engine to perform matching on as will
be discussed in the next section. The Javascript file lists.js
implements the list functions: \texttt{cons}, \texttt{head},
\texttt{tail}, \texttt{map}, \texttt{foldR}, \texttt{all}.

Because it is more common to quote paths as descents rather than ascent,
on the boundary to the outside world Oboe reverses the order and,
because Javascript programmers will not be familiar with this structure,
converts to arrays.

\subsection{Oboe JSONPath Implementation}

Not surprisingly given its importance, the JSONPath implementation is
one of the most refactored and considered parts of the Oboe codebase.
Like many small languages, on the first commit it was little more than a
series of regular expressions\footnote{JSONPath compiler from the first
  commit can be found at line 159 here:
  \url{https://github.com/jimhigson/oboe.js/blob/a17db7accc3a371853a2a0fd755153b10994c91e/src/main/progressive.js}\#L159.}
but has slowly evolved into a featureful and efficient
implementation\footnote{For contrast, the current source can be found at
  \url{https://github.com/jimhigson/oboe.js/blob/master/src/jsonPath.js}.}.
The extent of the rewriting was possible because the correct behaviour
is well defined by test specifications\footnote{The current tests are
  viewable at
  \url{https://github.com/jimhigson/oboe.js/blob/master/test/specs/jsonPath.unit.spec.js}
  and
  \url{https://github.com/jimhigson/oboe.js/blob/master/test/specs/jsonPathTokens.unit.spec.js}.}.

The JSONPath compiler exposes a single higher-order function to the rest
of Oboe. This function takes a JSONPath as a String and, proving it is a
valid expression, returns a function which tests for matches to the
JSONPath. Both the compiler and the functions that it generates benefit
from being stateless. The type of the compiler, expressed as Haskell
syntax would be:

\begin{Shaded}
\begin{Highlighting}[]
\DataTypeTok{String} \OtherTok{->} \DataTypeTok{Ascent} \OtherTok{->} \DataTypeTok{JsonPathMatchResult}
\end{Highlighting}
\end{Shaded}

The match result is either a failure to match, or a hit, with the node
that matched. In the case of path matching, the node may currently be
unknown. If the pattern has a clause prefixed with \texttt{\$}, the node
matching that clause is captured and returned as the result. Otherwise,
the last clause is implicitly capturing.

The usage profile for JSONPath expressions in Oboe is to be compiled
once and then evaluated many times, once for each node encountered while
parsing the JSON. Because matching is performed perhaps hundreds of
times per file the most pressing performance consideration is for
matching to execute quickly, the time required to compile is relatively
unimportant. Oboe's JSONPath design contrasts with JSONPath's reference
implementation which, because it provides a first order function,
freshly reinterprets the JSONPath string each time it is invoked.

The compilation is performed by recursively by examining the left-most
side of the string for a JSONPath clause. For each kind of clause there
is a function which matches ascents against that clause, for example by
checking the name field. By partial completion this function is
specialised to match against one particular name. Once a clause function
is generated, compilation recurs by passing to itself the remaining
unparsed portion of the JSONPath string. This continues until it is
called with a zero-length JSONPath. On each recursive call the clause
function is wrapped in the result from the next recursive call,
resulting ultimately in a linked series of clause functions. When
evaluated against an ascent, each clause functions examines the head of
the ascent and passes the ascent onto the next function if it passes. A
special clause functions, \texttt{skip1} is used for the \texttt{.}
syntax and places no condition on the head of the ascent but passes on
to the next clause only the tail, thus moving evaluation of the ascent
one node up the parsed JSON tree. Similarly, there is a
\texttt{skipMany} which maps onto the \texttt{..} syntax and recursively
consumes nodes until it can find a match in the next clause.

JsonPath implementation allows the compilation of complex expressions
into an executable form, but each part implementing the executable form
is locally simple. By using recursion, assembling the simple functions
into a more function expressing a more complex rule also follows as
being locally simple but gaining a usefully sophisticated behaviour
through composition of simple parts. Each recursive call of the parser
identifies one token for non-empty input and then recursively digests
the rest.

As an example, the pattern \texttt{!.\$person..\{height tShirtSize\}}
once compiled would roughly resemble the Javascript functional
representation below:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{statementExpr}\NormalTok{(             }\CommentTok{// wrapper, added when JSONPath is zero-length }
   \FunctionTok{duckTypeClause}\NormalTok{(         }\CommentTok{// token 6, \{height tShirtSize\}}
      \FunctionTok{skipMany}\NormalTok{(            }\CommentTok{// token 5, '..'  }
         \FunctionTok{capture}\NormalTok{(          }\CommentTok{// token 4, css4-style '$' notation}
            \FunctionTok{nameClause}\NormalTok{(    }\CommentTok{// token 3, 'person'}
               \FunctionTok{skip1}\NormalTok{(      }\CommentTok{// token 2, '.'  }
                  \NormalTok{rootExpr }\CommentTok{// token 1, '!' at start of JSONPath expression}
               \NormalTok{) }
            \StringTok{'person'} \NormalTok{)}
         \NormalTok{)}
   \NormalTok{), [}\StringTok{'height'}\NormalTok{, }\StringTok{'tShirtSize'}\NormalTok{])}
\NormalTok{)      }
\end{Highlighting}
\end{Shaded}

Since I am only using a side-effect free subset of Javascript for this
segment of Oboe it would be safe to use a functional cache. As well as
saving time by avoiding repeated execution, this could potentially also
save memory because where two JSONPath strings contain a common start
they could share the inner parts of their functional expression.
Although Javascript doesn't come with functional caching, it can be
added using the language itself.\footnote{Probably the best known
  example being \texttt{memoize} from Underscore.js:
  \url{http://underscorejs.org/}\#memoize.} I suspect, however, that
hashing the parameters might be slower than performing the matching.
Although the parameters are all immutable and could in theory be hashed
by object identity, in practice there is no way to access an object id
from inside the language so any hash of a node parsed out of JSON would
have to walk the entire subtree rooted from that node.

The JSONPath tokenisation is split out into its own file and separately
tested. The tokenisation implementation is based on regular expressions,
they are the simplest form able to express the clause patterns. The
regular expressions are hidden to the outside the tokenizer and only
functions are exposed to the main body of the compiler. The regular
expressions all start with \texttt{\^{}} so that they only match at the
head of the string. A more elegant alternative is the `y'\footnote{\href{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular\textbackslash{}_Expressions}{Https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular\textbackslash{}\_Expressions}.}
flag but as of now this lacks wide browser support.

By verifying the tokens through their own unit tests it is simpler to
thoroughly specify the tokenisation, producing simpler failure messages
than if it were done through the full JSONPath engine. We might consider
the unit test layer of the pyramid (figure \ref{testpyramid}) is further
split into two sub-layers. Arguably, the upper of these sub-layer is not
a unit test because it is verifying two units together. There is some
redundancy with the tokens being tested both individually and as full
expressions. I maintain that this is the best approach regardless
because stubbing out the tokenizer functions would be a considerable
effort and would not improve the rigor of the JSONPath specification.

\begin{figure}[htbp]
\centering
\includegraphics{images/placeholder.png}
\caption{Some kind of diagram showing jsonPath expressions and functions
partially completed to link back to the previous function. Include the
statementExpr pointing to the last clause}
\end{figure}

\section{Conclusion}

\subsection{Benchmarking vs non-progressive REST}

I feel it is important to experimentally answer the question, \emph{is
this actually any faster?}. To do this I have created a small
benchmarking suite that runs under Node.js. I chose Node because it at
its code is a very basic platform which I feel it gives a more
repeatable environment than modern browsers which at during the tests
could be performing any number of background tasks. These tests may be
seen in the \texttt{benchmark} folder of the project. Node also has the
advantage in measuring the memory of a running process is not swamped by
the memory taken up by the browser itself.

One of the proposed advantages of progressive REST is an improved user
experience because of earlier, more progressive interface rendering and
a perceptual improvement in speed. I am not focusing on this area for
benchmarking because it would be much more difficult to measure,
involving human participants. While I can't provide numbers on the
perceptual improvements, I have created sites using Oboe and the
improvement in responsiveness over slower networks is large enough to be
obvious.

The benchmark mimics a relational database-backed REST service.
Relational databases serve data to a cursor one tuple at a time. The
simulated service writes out twenty tuples as JSON objects, one every
ten milliseconds. To simulate network slowness, Apple's \emph{Network
Line Conditioner} was used. I chose the named presets ``3G, Average
Case'' and ``Cable modem'' to represent poor and good networks
respectively.\footnote{\href{http://mattgemmell.com/2011/07/25/network-link-conditioner-in-lion/}{Http://mattgemmell.com/2011/07/25/network-link-conditioner-in-lion/}.}
Each test involves two node processes, one acting as the client and one
as the server, with data transfer between them via normal http.

Memory was measured using Node's built in memory reporting tool,
\texttt{process.memoryusage()} and the maximum figure returned on each
run was taken

Each object in the returned JSON contains a URL to a further resource.
Each further resource is fetched and parsed. The aggregation is complete
when we have them all.

\begin{longtable}[c]{@{}llrrr@{}}
\hline\noalign{\medskip}
Strategy & Network & First output (ms) & Total time (ms) & Max. Memory
(Mb)
\\\noalign{\medskip}
\hline\noalign{\medskip}
Oboe.js & Good & 40 & 804 & 6.2
\\\noalign{\medskip}
Oboe.js & Poor & 60 & 1,526 & 6.2
\\\noalign{\medskip}
JSON.parse (DOM) & Good & 984 & 1,064 & 9,0
\\\noalign{\medskip}
JSON.parse (DOM) & Poor & 2550 & 2,609 & 8.9
\\\noalign{\medskip}
Clarinet (SAX) & Good & 34 & 781 & 5.5
\\\noalign{\medskip}
Clarinet (SAX) & Poor & 52 & 1,510 & 5.5
\\\noalign{\medskip}
\hline
\end{longtable}

Vs Json.parse shows a dramatic improvement over first output of about
96\% and a smaller but significant improvement of about 40\% in time
required to complete the task. Oboe's performance in terms of time is
about 15\% slower than Clarinet; since Oboe is built on Clarinet it
could not be faster but I had hoped for these results to be closer.

As expected, in this simulation of real-world usage, the extra
computation\\compared to JSON.parse which is needed by Oboe's more
involved algorithms or Clarinet's less efficient parsing\footnote{\href{http://writings.nunojob.com/2011/12/clarinet-sax-based-evented-streaming-json-parser-in-javascript-for-the-browser-and-nodejs.html}{Http://writings.nunojob.com/2011/12/clarinet-sax-based-evented-streaming-json-parser-in-javascript-for-the-browser-and-nodejs.html}.}
have been dwarfed by better i/o management. Reacting earlier using
slower handlers has been shown to be faster overall than reacting later
with quicker ones. I believe that this vindicates a focus on efficient
management of i/o over faster algorithms. I believe that much
programming takes a ``Hurry up and wait'' approach by concentrating
overly on optimal computation rather than optimal i/o management.

There is an unexpected improvement vs JSON.parse in terms of memory
usage. It is not clear why this would be but it may be attributable to
the json fetching library used to simplify the JSON.parse tests having a
large dependency tree. As expected, Clarinet shows the largest
improvements in terms of memory usage. For very large JSON I would
expect Clarinet's memory usage to remain roughly constant whilst the two
approaches rise linearly with the size of the resource.

\subsection{Comparative Programmer Ergonomics}

For each of the benchmarks above the code was laid out in the most
natural way for the strategy under test.

\begin{longtable}[c]{@{}lrr@{}}
\hline\noalign{\medskip}
Strategy & Code Required (lines) & Code required (chars)
\\\noalign{\medskip}
\hline\noalign{\medskip}
Oboe.js & 3 & 64
\\\noalign{\medskip}
JSON.parse & 5 & 102
\\\noalign{\medskip}
Clarinet (SAX) & 30 & lots!
\\\noalign{\medskip}
\hline
\end{longtable}

Oboe was the shortest:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{oboe}\NormalTok{(DB_URL).}\FunctionTok{node}\NormalTok{(}\StringTok{'\{id url\}.url'}\NormalTok{, }\KeywordTok{function}\NormalTok{(url)\{}
        
   \FunctionTok{oboe}\NormalTok{(url).}\FunctionTok{node}\NormalTok{(}\StringTok{'name'}\NormalTok{, }\KeywordTok{function}\NormalTok{(name)\{}
                   
      \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(name);               }
   \NormalTok{\});      }
\NormalTok{\});}
\end{Highlighting}
\end{Shaded}

Non-progressive parsing was slightly longer, requiring in addition a
loop, an if statement, and programmatically selecting specific parts of
the results:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// JSON.parse. The code is shortened and simplified by get-json from NPM:}
\CommentTok{// https://npmjs.org/package/get-json}

\FunctionTok{getJson}\NormalTok{(DB_URL, }\KeywordTok{function}\NormalTok{(err, records) \{}
    
   \OtherTok{records}\NormalTok{.}\OtherTok{data}\NormalTok{.}\FunctionTok{forEach}\NormalTok{( }\KeywordTok{function}\NormalTok{( record )\{}
    
      \KeywordTok{if}\NormalTok{( }\OtherTok{record}\NormalTok{.}\FunctionTok{url} \NormalTok{) \{}
      
         \FunctionTok{getJson}\NormalTok{(}\OtherTok{record}\NormalTok{.}\FunctionTok{url}\NormalTok{, }\KeywordTok{function}\NormalTok{(err, record) \{}
         
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\OtherTok{record}\NormalTok{.}\FunctionTok{name}\NormalTok{);}
         \NormalTok{\});}
      \NormalTok{\}}
   \NormalTok{\});}
\NormalTok{\});}
\end{Highlighting}
\end{Shaded}

The JSON.parse version is very closely coupled with the format that it
is handling. We can see this in the fragments \texttt{records.data},
\texttt{record.url}, \texttt{record.name} which expects to find
sub-trees at very specific locations in the JSON. The code might be said
to contain a description of the format that it is for. Conversely, the
Oboe version describes the format only so far as is needed to identify
the parts that it is interested in; the remainder of the format could
change and the code would continue to work. As well as being simpler to
program against than the previous simplest mode, I believe this
demonstrates a greater tolerance to changing formats.

The Clarinet version of the code may be seen in appendex (??). This
version is greater in verbosity and obfuscation. I don't think a person
could look at this source and understand what is being parsed without
thinking about it for a long time. Parameter names such as `key' or
`value' must be chosen by the position of the token in the markup, prior
to understanding the semantics it represents. By contrast, Oboe and
JSON.parse both allow names to be given by the meaning of the token.

\subsection{Performance of code styles under various engines}

The 15\% overhead of Oboe vs Clarinet suggests Oboe might be
computationally expensive. With very fast networks the extra computation
might outweigh a more efficient i/o strategy.

The file \texttt{test/specs/oboe.performance.spec.js} contains a simple
benchmark. This test registeres a very complex JSONPath expression which
intentionally uses all of the language and fetches a JSON file
containing 100 objects, each with 8 String properties against .
Correspondingly the expression is evaluated just over 800 times and 100
matches are found. Although real http is used, it is kept within the
localhost. The results below are averaged from ten runs. The tests
executed on a Macbook Air, except for Chrome Mobile which was tested on
an iPhone 5. Tests requiring Microsoft Windows were performed inside a
virtual machine.

Curl is a simple download to stdout from the shell and is included as a
control run to provide a baseline.

\begin{longtable}[c]{@{}lll@{}}
\hline\noalign{\medskip}
Platform & Total Time & Throughput (nodes per ms)
\\\noalign{\medskip}
\hline\noalign{\medskip}
Curl (control) & 42ms & \emph{n/a}
\\\noalign{\medskip}
Node.js v0.10.1 & 172ms & 4.67
\\\noalign{\medskip}
Chrome 30.0.1599 (Mac OS X 10.7.5) & 202ms & 3.98
\\\noalign{\medskip}
Safari 6.0.5 (Mac OS X 10.7.5) & 231ms & 3.48
\\\noalign{\medskip}
IE 10.0.0 (Windows 8) & 349ms & 2.30
\\\noalign{\medskip}
Chrome Mobile iOS 30.0.1599 (iOS 7.0.2) & 431ms & 1.86
\\\noalign{\medskip}
Firefox 24.0.0 (Mac OS X 10.7) & 547ms & 1.47
\\\noalign{\medskip}
IE 8.0.0 (Windows XP) & 3,048ms & 0.26
\\\noalign{\medskip}
\hline
\end{longtable}

We can see that Firefox is much slower than other modern browsers
despite its SpiderMonkey Javascript engine being normally quite fast.
This is probably explicable in part by SpiderMonkey's just-in-time
compiler being poor at optimising functional Javascript (Guo 2013).
Because the JSON nodes are not of a common type the related callsites
are not monomorphic which Firefox also optimises poorly (Guo 2013). When
the test was repeated using a simpler JSONPath expression Firefox showed
by far the largest improvement indicating that on this platform the
functional pattern matching is the bottleneck.

Of these results I find only the very low performance on old versions of
Internet Explorer concerning, almost certainly degrading user experience
more than it is improved. It might be reasonable to conclude that for
complex use cases Oboe is currently not unsuited to legacy platforms.
Since this platform cannot progressively interpret an XHR response, if
performance on legacy platforms becomes a serious concern one option
might be to create a non-progressive library with the same API which
could be selectively delivered to those platforms in place of the main
version.

Nonetheless, in its current form Oboe may slow down the total time when
working over the very fastest connections.

For an imperative language coded in a functional style the compiler may
not optimise as effectively as if a functional language was used. This
is especially the case under a highly dynamic language in which
everything, even the built-in constructs are mutable. I think Javascript
was a good choice of language given it is already well adopted and
allows the targeting of server and client side with only minimal effort,
giving a very large number of applications with the potential to adopt
Oboe. However, there are obvious inefficiencies such as the the descent
and ancestor arrays which are always created to be handed to application
callbacks but that I anticipate will be predominantly ignored. The
design of Oboe is very amicable to implementation under a functional
language and it would be interesting to see the results.

\subsection{Status as a micro-library}

Built versions of Oboe as delivered reside in the project's
\texttt{dist} folder. The file \texttt{oboe-browser.min.js} is the
minified version which should be sent to browsers gzipped. After gzip is
applied this file comes to 4966 bytes; close to but comfortably under
the 5120 limit. At roughly the size as a very small image, the size of
Oboe should not discourage adoption.

\subsection{potential future work}

\emph{Matching server-side tools}

There is nothing about Oboe which precludes working with other
tree-shaped format. If there is demand, An XML/XPATH version seems like
an obvious expansion. Currently Oboe only operates on http traffic.

Oboe stores all items that are parsed from the JSON it receives,
resulting in a memory use which is as high as a DOM parser. These are
kept in order to be able to provide a match to any possible JSONPath
expression. However, in most cases memory would be saved if the parsed
content were only stored so far as is needed to provide matches against
the JSONPath expressions which have actually been registered. For
typical use cases I expect this would allow the non-storage of large
branches. Likewise, the current implementation takes a rather brute
force approach when examining node for pattern matches: check every
registered JSONPath expression against every node and path that are
found in the JSON. For many expressions we are able to know there is no
possibility of matching a JSON tree, either because we have already
matched or because the the current node's ancestors already mandate
failure. A more sophisticated programme might disregard provably
unsatisfiable handlers for the duration of a subtree. Either of these
changes would involve some rather difficult programming and because
matching is fast enough I think brute force is the best approach for the
time being.

During JSONPath matching much of the computation is repeated. For
example, matching the expression \texttt{b.*} against many children of a
common parent will repeat the same test, checking if the parent's name
is `b', for each child node. Because the JSONPath matching is stateless,
recursive and side-effect free there is a potential to cut out repeated
computation by using a functional cache. This would reduce the overall
amount of computation needed for JSONPath expressions with common
substrings to their left side or nodes with a common ancestry. Current
Javascript implementations make it difficult to manage a functional
cache, or caches in general, from inside the language itself because
there is no way to occupy only the unused memory. Weak references are
proposed in ECMAScript 6 but currently only experimentally
supported\footnote{At time of writing, Firefox is the only engine
  supporting WeakHashMap by default. In Chome it is implemented but not
  available to Javascript unless explicitly enabled by a browser flag.
  \url{https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global\textbackslash{}_Objects/WeakMap}
  retrieved 11th October 2013.}. For future development they would be
ideal.

The nodes which Oboe hands to callbacks are mutable meaning that
potentially the correct workings of the library could be broken if the
containing application carelessly alters them. Newer implementations of
Javascript allows a whole object to be made immutable, or just certain
properties via an immutability decorator and the \texttt{defineProperty}
method. This would probably be an improvement.

\hyperdef{}{appendix_http_limits}{\section{Appendix i: Limits to number
of simultaneous connections under various http
clients}\label{appendix_http_limits}}

\begin{longtable}[c]{@{}ll@{}}
\hline\noalign{\medskip}
\begin{minipage}[b]{0.22\columnwidth}\raggedright
http Client
\end{minipage} & \begin{minipage}[b]{0.29\columnwidth}\raggedright
connection limit per server
\end{minipage}
\\\noalign{\medskip}
\hline\noalign{\medskip}
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Firefox
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright
6
\end{minipage}
\\\noalign{\medskip}
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Internet Explorer
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright
4
\end{minipage}
\\\noalign{\medskip}
\begin{minipage}[t]{0.22\columnwidth}\raggedright
Chrome / Chromium
\end{minipage} & \begin{minipage}[t]{0.29\columnwidth}\raggedright
32 sockets per proxy 6 sockets per destination host 256 sockets per
process
\end{minipage}
\\\noalign{\medskip}
\hline
\end{longtable}

\url{https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest}

\url{http://msdn.microsoft.com/de-de/magazine/ee330731.aspx}\#http11\_max\_con

\url{http://dev.chromium.org/developers/design-documents/network-stack}\#TOC-Connection-Management

\section{Appendix ii: Oboe.js source code listing}

\subsection{clarinetListenerAdaptor.js}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{/** }
\CommentTok{ * A bridge used to assign stateless functions to listen to clarinet.}
\CommentTok{ * }
\CommentTok{ * As well as the parameter from clarinet, each callback will also be passed}
\CommentTok{ * the result of the last callback.}
\CommentTok{ * }
\CommentTok{ * This may also be used to clear all listeners by assigning zero handlers:}
\CommentTok{ * }
\CommentTok{ *    clarinetListenerAdaptor( clarinet, \{\} )}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{clarinetListenerAdaptor}\NormalTok{(clarinetParser, handlers)\{}
    
   \KeywordTok{var} \NormalTok{state;}

   \OtherTok{clarinet}\NormalTok{.}\OtherTok{EVENTS}\NormalTok{.}\FunctionTok{forEach}\NormalTok{(}\KeywordTok{function}\NormalTok{(eventName)\{}
 
      \KeywordTok{var} \NormalTok{handlerFunction = handlers[eventName];}
      
      \NormalTok{clarinetParser[}\StringTok{'on'}\NormalTok{+eventName] = handlerFunction && }
                                       \KeywordTok{function}\NormalTok{(param) \{}
                                          \NormalTok{state = }\FunctionTok{handlerFunction}\NormalTok{( state, param);}
                                       \NormalTok{\};}
   \NormalTok{\});}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{events.js}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * This file declares some constants to use as names for event types.}
\CommentTok{ */}

\KeywordTok{var} \CommentTok{// NODE_FOUND, PATH_FOUND and ERROR_EVENT feature }
    \CommentTok{// in the public API via .on('node', ...) or .on('path', ...)}
    \CommentTok{// so these events are strings}
    \NormalTok{NODE_FOUND    = }\StringTok{'node'}\NormalTok{,  }
    \NormalTok{PATH_FOUND    = }\StringTok{'path'}\NormalTok{,   }
         
    \CommentTok{// these events are never exported so are kept as }
    \CommentTok{// the smallest possible representation, numbers:}
    \NormalTok{_S = }\DecValTok{0}\NormalTok{,}
    \NormalTok{ERROR_EVENT   = _S++,    }
    \NormalTok{ROOT_FOUND    = _S++,    }
    \NormalTok{NEW_CONTENT = _S++,}
    \NormalTok{END_OF_CONTENT = _S++,}
    \NormalTok{ABORTING = _S++;}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{functional.js}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/** }
\CommentTok{ * Partially complete a function.}
\CommentTok{ * }
\CommentTok{ * Eg: }
\CommentTok{ *    var add3 = partialComplete( function add(a,b)\{return a+b\}, 3 );}
\CommentTok{ *    }
\CommentTok{ *    add3(4) // gives 7}
\CommentTok{ *    }
\CommentTok{ *    }
\CommentTok{ *    function wrap(left, right, cen)\{return left + " " + cen + " " + right;\}}
\CommentTok{ *    }
\CommentTok{ *    var pirateGreeting = partialComplete( wrap , "I'm", ", a mighty pirate!" );}
\CommentTok{ *    }
\CommentTok{ *    pirateGreeting("Guybrush Threepwood"); }
\CommentTok{ *                         // gives "I'm Guybrush Threepwood, a mighty pirate!"}
\CommentTok{ */}
\KeywordTok{var} \NormalTok{partialComplete = }\FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{( fn, boundArgs ) \{}

      \KeywordTok{return} \FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{( callArgs ) \{}
               
         \KeywordTok{return} \OtherTok{fn}\NormalTok{.}\FunctionTok{apply}\NormalTok{(}\KeywordTok{this}\NormalTok{, }\OtherTok{boundArgs}\NormalTok{.}\FunctionTok{concat}\NormalTok{(callArgs));}
      \NormalTok{\}); }
   \NormalTok{\}),}


\CommentTok{/**}
\CommentTok{ * Compose zero or more functions:}
\CommentTok{ * }
\CommentTok{ *    compose(f1, f2, f3)(x) = f1(f2(f3(x))))}
\CommentTok{ * }
\CommentTok{ * The last (inner-most) function may take more than one parameter:}
\CommentTok{ * }
\CommentTok{ *    compose(f1, f2, f3)(x,y) = f1(f2(f3(x,y))))}
\CommentTok{ */}
   \NormalTok{compose = }\FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{(fns) \{}

      \KeywordTok{var} \NormalTok{fnsList = }\FunctionTok{arrayAsList}\NormalTok{(fns);}
   
      \KeywordTok{function} \FunctionTok{next}\NormalTok{(params, curFn) \{  }
         \KeywordTok{return} \NormalTok{[}\FunctionTok{apply}\NormalTok{(params, curFn)];   }
      \NormalTok{\}}
      
      \KeywordTok{return} \FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{(startParams)\{}
        
         \KeywordTok{return} \FunctionTok{foldR}\NormalTok{(next, startParams, fnsList)[}\DecValTok{0}\NormalTok{];}
      \NormalTok{\});}
   \NormalTok{\}),}

\CommentTok{/**}
\CommentTok{ * Call a list of functions with the same args until one returns a }
\CommentTok{ * truthy result. Similar to the \textbar{}\textbar{} operator.}
\CommentTok{ * }
\CommentTok{ * So:}
\CommentTok{ *      lazyUnion([f1,f2,f3 ... fn])( p1, p2 ... pn )}
\CommentTok{ *      }
\CommentTok{ * Is equivalent to: }
\CommentTok{ *      apply([p1, p2 ... pn], f1) \textbar{}\textbar{} }
\CommentTok{ *      apply([p1, p2 ... pn], f2) \textbar{}\textbar{} }
\CommentTok{ *      apply([p1, p2 ... pn], f3) ... apply(fn, [p1, p2 ... pn])  }
\CommentTok{ *  }
\CommentTok{ * }\KeywordTok{@returns}\CommentTok{ the first return value that is given that is truthy.}
\CommentTok{ */}
   \NormalTok{lazyUnion = }\FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{(fns) \{}

      \KeywordTok{return} \FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{(params)\{}
   
         \KeywordTok{var} \NormalTok{maybeValue;}
   
         \KeywordTok{for} \NormalTok{(}\KeywordTok{var} \NormalTok{i = }\DecValTok{0}\NormalTok{; i < }\FunctionTok{len}\NormalTok{(fns); i++) \{}
   
            \NormalTok{maybeValue = }\FunctionTok{apply}\NormalTok{(params, fns[i]);}
   
            \KeywordTok{if}\NormalTok{( maybeValue ) \{}
               \KeywordTok{return} \NormalTok{maybeValue;}
            \NormalTok{\}}
         \NormalTok{\}}
      \NormalTok{\});}
   \NormalTok{\});   }

\CommentTok{/**}
\CommentTok{ * This file declares various pieces of functional programming.}
\CommentTok{ * }
\CommentTok{ * This isn't a general purpose functional library, to keep things small it}
\CommentTok{ * has just the parts useful for Oboe.js.}
\CommentTok{ */}


\CommentTok{/**}
\CommentTok{ * Call a single function with the given arguments array.}
\CommentTok{ * Basically, a functional-style version of the OO-style Function#apply for }
\CommentTok{ * when we don't care about the context ('this') of the call.}
\CommentTok{ * }
\CommentTok{ * The order of arguments allows partial completion of the arguments array}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{apply}\NormalTok{(args, fn) \{}
   \KeywordTok{return} \OtherTok{fn}\NormalTok{.}\FunctionTok{apply}\NormalTok{(}\KeywordTok{undefined}\NormalTok{, args);}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * Define variable argument functions but cut out all that tedious messing about }
\CommentTok{ * with the arguments object. Delivers the variable-length part of the arguments}
\CommentTok{ * list as an array.}
\CommentTok{ * }
\CommentTok{ * Eg:}
\CommentTok{ * }
\CommentTok{ * var myFunction = varArgs(}
\CommentTok{ *    function( fixedArgument, otherFixedArgument, variableNumberOfArguments )\{}
\CommentTok{ *       console.log( variableNumberOfArguments );}
\CommentTok{ *    \}}
\CommentTok{ * )}
\CommentTok{ * }
\CommentTok{ * myFunction('a', 'b', 1, 2, 3); // logs [1,2,3]}
\CommentTok{ * }
\CommentTok{ * var myOtherFunction = varArgs(function( variableNumberOfArguments )\{}
\CommentTok{ *    console.log( variableNumberOfArguments );}
\CommentTok{ * \})}
\CommentTok{ * }
\CommentTok{ * myFunction(1, 2, 3); // logs [1,2,3]}
\CommentTok{ * }
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{varArgs}\NormalTok{(fn)\{}

   \KeywordTok{var} \NormalTok{numberOfFixedArguments = }\OtherTok{fn}\NormalTok{.}\FunctionTok{length} \NormalTok{-}\DecValTok{1}\NormalTok{;}
         
   \KeywordTok{return} \KeywordTok{function}\NormalTok{()\{}
   
      \KeywordTok{var} \NormalTok{numberOfVaraibleArguments = }\OtherTok{arguments}\NormalTok{.}\FunctionTok{length} \NormalTok{- numberOfFixedArguments,}
      
          \NormalTok{argumentsToFunction = }\OtherTok{Array}\NormalTok{.}\OtherTok{prototype}\NormalTok{.}\OtherTok{slice}\NormalTok{.}\FunctionTok{call}\NormalTok{(arguments);}
          
      \CommentTok{// remove the last n element from the array and append it onto the end of}
      \CommentTok{// itself as a sub-array}
      \OtherTok{argumentsToFunction}\NormalTok{.}\FunctionTok{push}\NormalTok{( }
         \OtherTok{argumentsToFunction}\NormalTok{.}\FunctionTok{splice}\NormalTok{(numberOfFixedArguments, numberOfVaraibleArguments)}
      \NormalTok{);   }
      
      \KeywordTok{return} \OtherTok{fn}\NormalTok{.}\FunctionTok{apply}\NormalTok{( }\KeywordTok{this}\NormalTok{, argumentsToFunction );}
   \NormalTok{\}       }
\NormalTok{\}}


\CommentTok{/**}
\CommentTok{ * Swap the order of parameters to a binary function}
\CommentTok{ * }
\CommentTok{ * A bit like this flip: http://zvon.org/other/haskell/Outputprelude/flip_f.html}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{flip}\NormalTok{(fn)\{}
   \KeywordTok{return} \KeywordTok{function}\NormalTok{(a, b)\{}
      \KeywordTok{return} \FunctionTok{fn}\NormalTok{(b,a);}
   \NormalTok{\}}
\NormalTok{\}}


\CommentTok{/**}
\CommentTok{ * Create a function which is the intersection of two other functions.}
\CommentTok{ * }
\CommentTok{ * Like the && operator, if the first is truthy, the second is never called,}
\CommentTok{ * otherwise the return value from the second is returned.}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{lazyIntersection}\NormalTok{(fn1, fn2) \{}

   \KeywordTok{return} \KeywordTok{function} \NormalTok{(param) \{}
                                                              
      \KeywordTok{return} \FunctionTok{fn1}\NormalTok{(param) && }\FunctionTok{fn2}\NormalTok{(param);}
   \NormalTok{\};   }
\NormalTok{\}}

\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{incrementalContentBuilder.js}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/** }
\CommentTok{ * This file provides various listeners which can be used to build up}
\CommentTok{ * a changing ascent based on the callbacks provided by Clarinet. It listens}
\CommentTok{ * to the low-level events from Clarinet and fires higher-level ones.}
\CommentTok{ *  }
\CommentTok{ * The building up is stateless so to track a JSON file}
\CommentTok{ * clarinetListenerAdaptor.js is required to store the ascent state}
\CommentTok{ * between calls.}
\CommentTok{ */}


\KeywordTok{var} \NormalTok{keyOf = }\FunctionTok{attr}\NormalTok{(}\StringTok{'key'}\NormalTok{);}
\KeywordTok{var} \NormalTok{nodeOf = }\FunctionTok{attr}\NormalTok{(}\StringTok{'node'}\NormalTok{);}


\CommentTok{/** }
\CommentTok{ * A special value to use in the path list to represent the path 'to' a root }
\CommentTok{ * object (which doesn't really have any path). This prevents the need for }
\CommentTok{ * special-casing detection of the root object and allows it to be treated }
\CommentTok{ * like any other object. We might think of this as being similar to the }
\CommentTok{ * 'unnamed root' domain ".", eg if I go to }
\CommentTok{ * http://en.wikipedia.org./wiki/En/Main_page the dot after 'org' deliminates }
\CommentTok{ * the unnamed root of the DNS.}
\CommentTok{ * }
\CommentTok{ * This is kept as an object to take advantage that in Javascript's OO objects }
\CommentTok{ * are guaranteed to be distinct, therefore no other object can possibly clash }
\CommentTok{ * with this one. Strings, numbers etc provide no such guarantee. }
\CommentTok{ **/}
\KeywordTok{var} \NormalTok{ROOT_PATH = \{\};}


\CommentTok{/**}
\CommentTok{ * Create a new set of handlers for clarinet's events, bound to the fire }
\CommentTok{ * function given.  }
\CommentTok{ */} 
\KeywordTok{function} \FunctionTok{incrementalContentBuilder}\NormalTok{( fire) \{}


   \KeywordTok{function} \FunctionTok{arrayIndicesAreKeys}\NormalTok{( possiblyInconsistentAscent, newDeepestNode) \{}
   
      \CommentTok{/* for values in arrays we aren't pre-warned of the coming paths }
\CommentTok{         (Clarinet gives no call to onkey like it does for values in objects) }
\CommentTok{         so if we are in an array we need to create this path ourselves. The }
\CommentTok{         key will be len(parentNode) because array keys are always sequential }
\CommentTok{         numbers. */}

      \KeywordTok{var} \NormalTok{parentNode = }\FunctionTok{nodeOf}\NormalTok{( }\FunctionTok{head}\NormalTok{( possiblyInconsistentAscent));}
      
      \KeywordTok{return}      \FunctionTok{isOfType}\NormalTok{( Array, parentNode)}
               \NormalTok{?}
                  \FunctionTok{pathFound}\NormalTok{(  possiblyInconsistentAscent, }
                              \FunctionTok{len}\NormalTok{(parentNode), }
                              \NormalTok{newDeepestNode}
                  \NormalTok{)}
               \NormalTok{:  }
                  \CommentTok{// nothing needed, return unchanged}
                  \NormalTok{possiblyInconsistentAscent }
               \NormalTok{;}
   \NormalTok{\}}
                 
   \KeywordTok{function} \FunctionTok{nodeFound}\NormalTok{( ascent, newDeepestNode ) \{}
      
      \KeywordTok{if}\NormalTok{( !ascent ) \{}
         \CommentTok{// we discovered the root node,}
         \FunctionTok{fire}\NormalTok{( ROOT_FOUND, newDeepestNode);}
                    
         \KeywordTok{return} \FunctionTok{pathFound}\NormalTok{( ascent, ROOT_PATH, newDeepestNode);         }
      \NormalTok{\}}

      \CommentTok{// we discovered a non-root node}
                 
      \KeywordTok{var} \NormalTok{arrayConsistentAscent  = }\FunctionTok{arrayIndicesAreKeys}\NormalTok{( ascent, newDeepestNode),      }
          \NormalTok{ancestorBranches       = }\FunctionTok{tail}\NormalTok{( arrayConsistentAscent),}
          \NormalTok{previouslyUnmappedName = }\FunctionTok{keyOf}\NormalTok{( }\FunctionTok{head}\NormalTok{( arrayConsistentAscent));}
          
      \FunctionTok{appendBuiltContent}\NormalTok{( }
         \NormalTok{ancestorBranches, }
         \NormalTok{previouslyUnmappedName, }
         \NormalTok{newDeepestNode }
      \NormalTok{);}
                                                                                                         
      \KeywordTok{return} \FunctionTok{cons}\NormalTok{( }
               \FunctionTok{namedNode}\NormalTok{( previouslyUnmappedName, newDeepestNode ), }
               \NormalTok{ancestorBranches}
      \NormalTok{);                                                                          }
   \NormalTok{\}}


   \CommentTok{/**}
\CommentTok{    * Add a new value to the object we are building up to represent the}
\CommentTok{    * parsed JSON}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{appendBuiltContent}\NormalTok{( ancestorBranches, key, node )\{}
     
      \FunctionTok{nodeOf}\NormalTok{( }\FunctionTok{head}\NormalTok{( ancestorBranches))[key] = node;}
   \NormalTok{\}}

   \CommentTok{/**}
\CommentTok{    * Get a new key->node mapping}
\CommentTok{    * }
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\textbar{}Number\}}\CommentTok{ key}
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Object\textbar{}Array\textbar{}String\textbar{}Number\textbar{}null\}}\CommentTok{ node a value found in the json}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{namedNode}\NormalTok{(key, node) \{}
      \KeywordTok{return} \NormalTok{\{}\DataTypeTok{key}\NormalTok{:key, }\DataTypeTok{node}\NormalTok{:node\};}
   \NormalTok{\}}
     
   \CommentTok{/**}
\CommentTok{    * For when we find a new key in the json.}
\CommentTok{    * }
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\textbar{}Number\textbar{}Object\}}\CommentTok{ newDeepestName the key. If we are in an }
\CommentTok{    *    array will be a number, otherwise a string. May take the special }
\CommentTok{    *    value ROOT_PATH if the root node has just been found}
\CommentTok{    *    }
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\textbar{}Number\textbar{}Object\textbar{}Array\textbar{}Null\textbar{}undefined\}}\CommentTok{ [maybeNewDeepestNode] }
\CommentTok{    *    usually this won't be known so can be undefined. Can't use null }
\CommentTok{    *    to represent unknown because null is a valid value in JSON}
\CommentTok{    **/}  
   \KeywordTok{function} \FunctionTok{pathFound}\NormalTok{(ascent, newDeepestName, maybeNewDeepestNode) \{}

      \KeywordTok{if}\NormalTok{( ascent ) \{ }\CommentTok{// if not root}
      
         \CommentTok{// If we have the key but (unless adding to an array) no known value}
         \CommentTok{// yet. Put that key in the output but against no defined value:      }
         \FunctionTok{appendBuiltContent}\NormalTok{( ascent, newDeepestName, maybeNewDeepestNode );}
      \NormalTok{\}}
   
      \KeywordTok{var} \NormalTok{ascentWithNewPath = }\FunctionTok{cons}\NormalTok{( }
                                 \FunctionTok{namedNode}\NormalTok{( newDeepestName, }
                                            \NormalTok{maybeNewDeepestNode), }
                                 \NormalTok{ascent}
                              \NormalTok{);}
     
      \FunctionTok{fire}\NormalTok{( PATH_FOUND, ascentWithNewPath);}
 
      \KeywordTok{return} \NormalTok{ascentWithNewPath;}
   \NormalTok{\}}


   \CommentTok{/**}
\CommentTok{    * For when the current node ends}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{curNodeFinished}\NormalTok{( ascent ) \{}

      \FunctionTok{fire}\NormalTok{( NODE_FOUND, ascent);}
                          
      \CommentTok{// pop the complete node and its path off the list:                                    }
      \KeywordTok{return} \FunctionTok{tail}\NormalTok{( ascent);}
   \NormalTok{\}      }
                 
   \KeywordTok{return} \NormalTok{\{ }

      \DataTypeTok{openobject }\NormalTok{: }\KeywordTok{function} \NormalTok{(ascent, firstKey) \{}

         \KeywordTok{var} \NormalTok{ascentAfterNodeFound = }\FunctionTok{nodeFound}\NormalTok{(ascent, \{\});         }

         \CommentTok{/* It is a perculiarity of Clarinet that for non-empty objects it}
\CommentTok{            gives the first key with the openobject event instead of}
\CommentTok{            in a subsequent key event.}
\CommentTok{                      }
\CommentTok{            firstKey could be the empty string in a JSON object like }
\CommentTok{            \{'':'foo'\} which is technically valid.}
\CommentTok{            }
\CommentTok{            So can't check with !firstKey, have to see if has any }
\CommentTok{            defined value. */}
         \KeywordTok{return} \FunctionTok{defined}\NormalTok{(firstKey)}
         \NormalTok{?          }
            \CommentTok{/* We know the first key of the newly parsed object. Notify that }
\CommentTok{               path has been found but don't put firstKey permanently onto }
\CommentTok{               pathList yet because we haven't identified what is at that key }
\CommentTok{               yet. Give null as the value because we haven't seen that far }
\CommentTok{               into the json yet */}
            \FunctionTok{pathFound}\NormalTok{(ascentAfterNodeFound, firstKey)}
         \NormalTok{:}
            \NormalTok{ascentAfterNodeFound}
         \NormalTok{;}
      \NormalTok{\},}
    
      \DataTypeTok{openarray}\NormalTok{: }\KeywordTok{function} \NormalTok{(ascent) \{}
         \KeywordTok{return} \FunctionTok{nodeFound}\NormalTok{(ascent, []);}
      \NormalTok{\},}

      \CommentTok{// called by Clarinet when keys are found in objects               }
      \DataTypeTok{key}\NormalTok{: pathFound,}
      
      \CommentTok{/* Emitted by Clarinet when primitive values are found, ie Strings,}
\CommentTok{         Numbers, and null.}
\CommentTok{         Because these are always leaves in the JSON, we find and finish the }
\CommentTok{         node in one step, expressed as functional composition: */}
      \DataTypeTok{value}\NormalTok{: }\FunctionTok{compose}\NormalTok{( curNodeFinished, nodeFound ),}
      
      \CommentTok{// we make no distinction in how we handle object and arrays closing.}
      \CommentTok{// For both, interpret as the end of the current node.}
      \DataTypeTok{closeobject}\NormalTok{: curNodeFinished,}
      \DataTypeTok{closearray}\NormalTok{: curNodeFinished       }
   \NormalTok{\};}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{instanceController.js}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * This file implements a light-touch central controller for an instance }
\CommentTok{ * of Oboe which provides the methods used for interacting with the instance }
\CommentTok{ * from the calling app.}
\CommentTok{ */}
 
 
\KeywordTok{function} \FunctionTok{instanceController}\NormalTok{(fire, on, clarinetParser, contentBuilderHandlers) \{}
  
   \KeywordTok{var} \NormalTok{oboeApi, rootNode;}

   \CommentTok{// when the root node is found grap a reference to it for later      }
   \FunctionTok{on}\NormalTok{(ROOT_FOUND, }\KeywordTok{function}\NormalTok{(root) \{}
      \NormalTok{rootNode = root;   }
   \NormalTok{\});}
                              
   \FunctionTok{on}\NormalTok{(NEW_CONTENT,         }
      \KeywordTok{function} \NormalTok{(nextDrip) \{}
         \CommentTok{// callback for when a bit more data arrives from the streaming XHR         }
          
         \KeywordTok{try} \NormalTok{\{}
            
            \OtherTok{clarinetParser}\NormalTok{.}\FunctionTok{write}\NormalTok{(nextDrip);            }
         \NormalTok{\} }\KeywordTok{catch}\NormalTok{(e) \{ }
            \CommentTok{/* we don't have to do anything here because we always assign}
\CommentTok{               a .onerror to clarinet which will have already been called }
\CommentTok{               by the time this exception is thrown. */}                
         \NormalTok{\}}
      \NormalTok{\}}
   \NormalTok{);}
   
   \CommentTok{/* At the end of the http content close the clarinet parser.}
\CommentTok{      This will provide an error if the total content provided was not }
\CommentTok{      valid json, ie if not all arrays, objects and Strings closed properly */}
   \FunctionTok{on}\NormalTok{(END_OF_CONTENT, }\OtherTok{clarinetParser}\NormalTok{.}\OtherTok{close}\NormalTok{.}\FunctionTok{bind}\NormalTok{(clarinetParser));}
   

   \CommentTok{/* If we abort this Oboe's request stop listening to the clarinet parser. }
\CommentTok{      This prevents more tokens being found after we abort in the case where }
\CommentTok{      we aborted during processing of an already filled buffer. */}
   \FunctionTok{on}\NormalTok{( ABORTING, }\KeywordTok{function}\NormalTok{() \{}
      \FunctionTok{clarinetListenerAdaptor}\NormalTok{(clarinetParser, \{\});}
   \NormalTok{\});   }

   \FunctionTok{clarinetListenerAdaptor}\NormalTok{(clarinetParser, contentBuilderHandlers);}
  
   \CommentTok{// react to errors by putting them on the event bus}
   \OtherTok{clarinetParser}\NormalTok{.}\FunctionTok{onerror} \NormalTok{= }\KeywordTok{function}\NormalTok{(e) \{          }
      \FunctionTok{fire}\NormalTok{(ERROR_EVENT, e);}
      
      \CommentTok{// note: don't close clarinet here because if it was not expecting}
      \CommentTok{// end of the json it will throw an error}
   \NormalTok{\};}

   \KeywordTok{function} \FunctionTok{addPathOrNodeCallback}\NormalTok{( eventId, pattern, callback ) \{}
   
      \KeywordTok{var} \NormalTok{matchesJsonPath = }\FunctionTok{jsonPathCompiler}\NormalTok{( pattern );}
   
      \CommentTok{// Add a new callback adaptor to the eventBus.}
      \CommentTok{// This listener first checks that he pattern matches then if it does, }
      \CommentTok{// passes it onto the callback. }
      \FunctionTok{on}\NormalTok{( eventId, }\KeywordTok{function}\NormalTok{( ascent )\{ }
 
         \KeywordTok{var} \NormalTok{maybeMatchingMapping = }\FunctionTok{matchesJsonPath}\NormalTok{( ascent );}
     
         \CommentTok{/* Possible values for maybeMatchingMapping are now:}

\CommentTok{            false: }
\CommentTok{               we did not match }
\CommentTok{  }
\CommentTok{            an object/array/string/number/null: }
\CommentTok{               we matched and have the node that matched.}
\CommentTok{               Because nulls are valid json values this can be null.}
\CommentTok{  }
\CommentTok{            undefined: }
\CommentTok{               we matched but don't have the matching node yet.}
\CommentTok{               ie, we know there is an upcoming node that matches but we }
\CommentTok{               can't say anything else about it. }
\CommentTok{         */}
         \KeywordTok{if}\NormalTok{( maybeMatchingMapping !== }\KeywordTok{false} \NormalTok{) \{                                 }

            \FunctionTok{notifyCallback}\NormalTok{(callback, maybeMatchingMapping, ascent);                           }
         \NormalTok{\}}
      \NormalTok{\});   }
   \NormalTok{\}   }
   
   \KeywordTok{function} \FunctionTok{notifyCallback}\NormalTok{(callback, matchingMapping, ascent) \{}
      \CommentTok{/* }
\CommentTok{         We're now calling back to outside of oboe where the Lisp-style }
\CommentTok{         lists that we are using internally will not be recognised }
\CommentTok{         so convert to standard arrays. }
\CommentTok{  }
\CommentTok{         Also, reverse the order because it is more common to list paths }
\CommentTok{         "root to leaf" than "leaf to root" }
\CommentTok{      */}
            
      \KeywordTok{var} \NormalTok{descent     = }\FunctionTok{reverseList}\NormalTok{(ascent),}
      
          \CommentTok{// To make a path, strip off the last item which is the special}
          \CommentTok{// ROOT_PATH token for the 'path' to the root node}
          \NormalTok{path       = }\FunctionTok{listAsArray}\NormalTok{(}\FunctionTok{tail}\NormalTok{(}\FunctionTok{map}\NormalTok{(keyOf,descent))),}
          \NormalTok{ancestors  = }\FunctionTok{listAsArray}\NormalTok{(}\FunctionTok{map}\NormalTok{(nodeOf, descent)); }
      
      \KeywordTok{try}\NormalTok{\{}
      
         \FunctionTok{callback}\NormalTok{( }\FunctionTok{nodeOf}\NormalTok{(matchingMapping), path, ancestors );   }
      \NormalTok{\}}\KeywordTok{catch}\NormalTok{(e)  \{}
      
         \CommentTok{// An error occured during the callback, publish it on the event bus }
         \FunctionTok{fire}\NormalTok{(ERROR_EVENT, e);}
      \NormalTok{\}          }
   \NormalTok{\}}

   \CommentTok{/**}
\CommentTok{    * Add several listeners at a time, from a map}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{addListenersMap}\NormalTok{(eventId, listenerMap) \{}
   
      \KeywordTok{for}\NormalTok{( }\KeywordTok{var} \NormalTok{pattern }\KeywordTok{in} \NormalTok{listenerMap ) \{}
         \FunctionTok{addPathOrNodeCallback}\NormalTok{(eventId, pattern, listenerMap[pattern]);}
      \NormalTok{\}}
   \NormalTok{\}    }
      
   \CommentTok{/**}
\CommentTok{    * implementation behind .onPath() and .onNode()}
\CommentTok{    */}       
   \KeywordTok{function} \FunctionTok{addNodeOrPathListenerApi}\NormalTok{( eventId, jsonPathOrListenerMap,}
                                      \NormalTok{callback, callbackContext )\{}
 
      \KeywordTok{if}\NormalTok{( }\FunctionTok{isString}\NormalTok{(jsonPathOrListenerMap) ) \{}
         \FunctionTok{addPathOrNodeCallback}\NormalTok{( }
            \NormalTok{eventId, }
            \NormalTok{jsonPathOrListenerMap, }
            \OtherTok{callback}\NormalTok{.}\FunctionTok{bind}\NormalTok{(callbackContext\textbar{}\textbar{}oboeApi)}
         \NormalTok{);}
      \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
         \FunctionTok{addListenersMap}\NormalTok{(eventId, jsonPathOrListenerMap);}
      \NormalTok{\}}
      
      \KeywordTok{return} \KeywordTok{this}\NormalTok{; }\CommentTok{// chaining}
   \NormalTok{\}}

   \CommentTok{/**}
\CommentTok{    * Construct and return the public API of the Oboe instance to be }
\CommentTok{    * returned to the calling application}
\CommentTok{    */}
   \KeywordTok{return} \NormalTok{oboeApi = \{ }
      \DataTypeTok{path  }\NormalTok{:  }\FunctionTok{partialComplete}\NormalTok{(addNodeOrPathListenerApi, PATH_FOUND), }
      \DataTypeTok{node  }\NormalTok{:  }\FunctionTok{partialComplete}\NormalTok{(addNodeOrPathListenerApi, NODE_FOUND),}
      \DataTypeTok{on    }\NormalTok{:  addNodeOrPathListenerApi,}
      \DataTypeTok{fail  }\NormalTok{:  }\FunctionTok{partialComplete}\NormalTok{(on, ERROR_EVENT),}
      \DataTypeTok{done  }\NormalTok{:  }\FunctionTok{partialComplete}\NormalTok{(addNodeOrPathListenerApi, NODE_FOUND, }\StringTok{'!'}\NormalTok{),}
      \DataTypeTok{abort }\NormalTok{:  }\FunctionTok{partialComplete}\NormalTok{(fire, ABORTING),}
      \DataTypeTok{root  }\NormalTok{:  }\KeywordTok{function} \FunctionTok{rootNodeFunctor}\NormalTok{() \{}
                  \KeywordTok{return} \NormalTok{rootNode;}
               \NormalTok{\}}
   \NormalTok{\};}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{jsonPath.js}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * The jsonPath evaluator compiler used for Oboe.js. }
\CommentTok{ * }
\CommentTok{ * One function is exposed. This function takes a String JSONPath spec and }
\CommentTok{ * returns a function to test candidate ascents for matches.}
\CommentTok{ * }
\CommentTok{ *  String jsonPath -> (List ascent) -> Boolean\textbar{}Object}
\CommentTok{ *}
\CommentTok{ * This file is coded in a pure functional style. That is, no function has }
\CommentTok{ * side effects, every function evaluates to the same value for the same }
\CommentTok{ * arguments and no variables are reassigned.}
\CommentTok{ */}  
\CommentTok{// the call to jsonPathSyntax injects the token syntaxes that are needed }
\CommentTok{// inside the compiler}
\KeywordTok{var} \NormalTok{jsonPathCompiler = }\FunctionTok{jsonPathSyntax}\NormalTok{(}\KeywordTok{function} \NormalTok{(pathNodeSyntax, }
                                                \NormalTok{doubleDotSyntax, }
                                                \NormalTok{dotSyntax,}
                                                \NormalTok{bangSyntax,}
                                                \NormalTok{emptySyntax ) \{}

   \KeywordTok{var} \NormalTok{CAPTURING_INDEX = }\DecValTok{1}\NormalTok{;}
   \KeywordTok{var} \NormalTok{NAME_INDEX = }\DecValTok{2}\NormalTok{;}
   \KeywordTok{var} \NormalTok{FIELD_LIST_INDEX = }\DecValTok{3}\NormalTok{;}

   \KeywordTok{var} \NormalTok{headKey = }\FunctionTok{compose}\NormalTok{(keyOf, head);}
                   
   \CommentTok{/**}
\CommentTok{    * Create an evaluator function for a named path node, expressed in the}
\CommentTok{    * JSONPath like:}
\CommentTok{    *    foo}
\CommentTok{    *    ["bar"]}
\CommentTok{    *    [2]   }
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{nameClause}\NormalTok{(previousExpr, detection ) \{}
     
      \KeywordTok{var} \NormalTok{name = detection[NAME_INDEX],}
            
          \NormalTok{matchesName = ( !name \textbar{}\textbar{} name == }\StringTok{'*'} \NormalTok{) }
                           \NormalTok{?  always}
                           \NormalTok{:  }\KeywordTok{function}\NormalTok{(ascent)\{}\KeywordTok{return} \FunctionTok{headKey}\NormalTok{(ascent) == name\};}
     

      \KeywordTok{return} \FunctionTok{lazyIntersection}\NormalTok{(matchesName, previousExpr);}
   \NormalTok{\}}

   \CommentTok{/**}
\CommentTok{    * Create an evaluator function for a a duck-typed node, expressed like:}
\CommentTok{    * }
\CommentTok{    *    \{spin, taste, colour\}}
\CommentTok{    *    .particle\{spin, taste, colour\}}
\CommentTok{    *    *\{spin, taste, colour\}}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{duckTypeClause}\NormalTok{(previousExpr, detection) \{}

      \KeywordTok{var} \NormalTok{fieldListStr = detection[FIELD_LIST_INDEX];}

      \KeywordTok{if} \NormalTok{(!fieldListStr) }
         \KeywordTok{return} \NormalTok{previousExpr; }\CommentTok{// don't wrap at all, return given expr as-is      }

      \KeywordTok{var} \NormalTok{hasAllrequiredFields = }\FunctionTok{partialComplete}\NormalTok{(}
                                    \NormalTok{hasAllProperties, }
                                    \FunctionTok{arrayAsList}\NormalTok{(}\OtherTok{fieldListStr}\NormalTok{.}\FunctionTok{split}\NormalTok{(}\OtherTok{/}\BaseNTok{\textbackslash{}W}\FloatTok{+}\OtherTok{/}\NormalTok{))}
                                 \NormalTok{),}
                                 
          \NormalTok{isMatch =  }\FunctionTok{compose}\NormalTok{( }
                        \NormalTok{hasAllrequiredFields, }
                        \NormalTok{nodeOf, }
                        \NormalTok{head}
                     \NormalTok{);}

      \KeywordTok{return} \FunctionTok{lazyIntersection}\NormalTok{(isMatch, previousExpr);}
   \NormalTok{\}}

   \CommentTok{/**}
\CommentTok{    * Expression for $, returns the evaluator function}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{capture}\NormalTok{( previousExpr, detection ) \{}

      \CommentTok{// extract meaning from the detection      }
      \KeywordTok{var} \NormalTok{capturing = !!detection[CAPTURING_INDEX];}

      \KeywordTok{if} \NormalTok{(!capturing)          }
         \KeywordTok{return} \NormalTok{previousExpr; }\CommentTok{// don't wrap at all, return given expr as-is      }
      
      \KeywordTok{return} \FunctionTok{lazyIntersection}\NormalTok{(previousExpr, head);}
            
   \NormalTok{\}            }
      
   \CommentTok{/**}
\CommentTok{    * Create an evaluator function that moves onto the next item on the }
\CommentTok{    * lists. This function is the place where the logic to move up a }
\CommentTok{    * level in the ascent exists. }
\CommentTok{    * }
\CommentTok{    * Eg, for JSONPath ".foo" we need skip1(nameClause(always, [,'foo']))}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{skip1}\NormalTok{(previousExpr) \{}
   
   
      \KeywordTok{if}\NormalTok{( previousExpr == always ) \{}
         \CommentTok{/* If there is no previous expression this consume command }
\CommentTok{            is at the start of the jsonPath.}
\CommentTok{            Since JSONPath specifies what we'd like to find but not }
\CommentTok{            necessarily everything leading down to it, when running}
\CommentTok{            out of JSONPath to check against we default to true */}
         \KeywordTok{return} \NormalTok{always;}
      \NormalTok{\}}

      \CommentTok{/** return true if the ascent we have contains only the JSON root,}
\CommentTok{       *  false otherwise}
\CommentTok{       */}
      \KeywordTok{function} \FunctionTok{notAtRoot}\NormalTok{(ascent)\{}
         \KeywordTok{return} \FunctionTok{headKey}\NormalTok{(ascent) != ROOT_PATH;}
      \NormalTok{\}}
      
      \KeywordTok{return} \FunctionTok{lazyIntersection}\NormalTok{(}
               \CommentTok{/* If we're already at the root but there are more }
\CommentTok{                  expressions to satisfy, can't consume any more. No match.}

\CommentTok{                  This check is why none of the other exprs have to be able }
\CommentTok{                  to handle empty lists; skip1 is the only evaluator that }
\CommentTok{                  moves onto the next token and it refuses to do so once it }
\CommentTok{                  reaches the last item in the list. */}
               \NormalTok{notAtRoot,}
               
               \CommentTok{/* We are not at the root of the ascent yet.}
\CommentTok{                  Move to the next level of the ascent by handing only }
\CommentTok{                  the tail to the previous expression */} 
               \FunctionTok{compose}\NormalTok{(previousExpr, tail) }
      \NormalTok{);}
                                                                                                               
   \NormalTok{\}   }
   
   \CommentTok{/**}
\CommentTok{    * Create an evaluator function for the .. (double dot) token. Consumes}
\CommentTok{    * zero or more levels of the ascent, the fewest that are required to find}
\CommentTok{    * a match when given to previousExpr.}
\CommentTok{    */}   
   \KeywordTok{function} \FunctionTok{skipMany}\NormalTok{(previousExpr) \{}

      \KeywordTok{if}\NormalTok{( previousExpr == always ) \{}
         \CommentTok{/* If there is no previous expression this consume command }
\CommentTok{            is at the start of the jsonPath.}
\CommentTok{            Since JSONPath specifies what we'd like to find but not }
\CommentTok{            necessarily everything leading down to it, when running}
\CommentTok{            out of JSONPath to check against we default to true */}            
         \KeywordTok{return} \NormalTok{always;}
      \NormalTok{\}}
          
      \KeywordTok{var} 
          \CommentTok{// In JSONPath .. is equivalent to !.. so if .. reaches the root}
          \CommentTok{// the match has succeeded. Ie, we might write ..foo or !..foo}
          \CommentTok{// and both should match identically.}
          \NormalTok{terminalCaseWhenArrivingAtRoot = }\FunctionTok{rootExpr}\NormalTok{(),}
          \NormalTok{terminalCaseWhenPreviousExpressionIsSatisfied = previousExpr, }
          \NormalTok{recursiveCase = }\FunctionTok{skip1}\NormalTok{(skipManyInner),}
          
          \NormalTok{cases = }\FunctionTok{lazyUnion}\NormalTok{(}
                     \NormalTok{terminalCaseWhenArrivingAtRoot}
                  \NormalTok{,  terminalCaseWhenPreviousExpressionIsSatisfied}
                  \NormalTok{,  recursiveCase}
                  \NormalTok{);                        }
            
      \KeywordTok{function} \FunctionTok{skipManyInner}\NormalTok{(ascent) \{}
      
         \KeywordTok{if}\NormalTok{( !ascent ) \{}
            \CommentTok{// have gone past the start, not a match:         }
            \KeywordTok{return} \KeywordTok{false}\NormalTok{;}
         \NormalTok{\}      }
                                                        
         \KeywordTok{return} \FunctionTok{cases}\NormalTok{(ascent);}
      \NormalTok{\}}
      
      \KeywordTok{return} \NormalTok{skipManyInner;}
   \NormalTok{\}      }
   
   \CommentTok{/**}
\CommentTok{    * Generate an evaluator for ! - matches only the root element of the json}
\CommentTok{    * and ignores any previous expressions since nothing may precede !. }
\CommentTok{    */}   
   \KeywordTok{function} \FunctionTok{rootExpr}\NormalTok{() \{}
      
      \KeywordTok{return} \KeywordTok{function}\NormalTok{(ascent)\{}
         \KeywordTok{return} \FunctionTok{headKey}\NormalTok{(ascent) == ROOT_PATH;}
      \NormalTok{\};}
   \NormalTok{\}   }
         
   \CommentTok{/**}
\CommentTok{    * Generate a statement wrapper to sit around the outermost }
\CommentTok{    * clause evaluator.}
\CommentTok{    * }
\CommentTok{    * Handles the case where the capturing is implicit because the JSONPath}
\CommentTok{    * did not contain a '$' by returning the last node.}
\CommentTok{    */}   
   \KeywordTok{function} \FunctionTok{statementExpr}\NormalTok{(lastClause) \{}
      
      \KeywordTok{return} \KeywordTok{function}\NormalTok{(ascent) \{}
   
         \CommentTok{// kick off the evaluation by passing through to the last clause}
         \KeywordTok{var} \NormalTok{exprMatch = }\FunctionTok{lastClause}\NormalTok{(ascent);}
                                                     
         \KeywordTok{return} \NormalTok{exprMatch === }\KeywordTok{true} \NormalTok{? }\FunctionTok{head}\NormalTok{(ascent) : exprMatch;}
      \NormalTok{\};}
   \NormalTok{\}      }
                          
   \CommentTok{/**}
\CommentTok{    * For when a token has been found in the JSONPath input.}
\CommentTok{    * Compiles the parser for that token and returns in combination with the}
\CommentTok{    * parser already generated.}
\CommentTok{    * }
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ exprs  a list of the clause evaluator generators for}
\CommentTok{    *                          the token that was found}
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ parserGeneratedSoFar the parser already found}
\CommentTok{    * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Array\}}\CommentTok{ detection the match given by the regex engine when }
\CommentTok{    *                          the feature was found}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{expressionsReader}\NormalTok{( exprs, parserGeneratedSoFar, detection ) \{}
                     
      \CommentTok{// if exprs is zero-length foldR will pass back the }
      \CommentTok{// parserGeneratedSoFar as-is so we don't need to treat }
      \CommentTok{// this as a special case}
      
      \KeywordTok{return}   \FunctionTok{foldR}\NormalTok{( }
                  \KeywordTok{function}\NormalTok{( parserGeneratedSoFar, expr )\{}
         
                     \KeywordTok{return} \FunctionTok{expr}\NormalTok{(parserGeneratedSoFar, detection);}
                  \NormalTok{\}, }
                  \NormalTok{parserGeneratedSoFar, }
                  \NormalTok{exprs}
               \NormalTok{);                     }

   \NormalTok{\}}

   \CommentTok{/** }
\CommentTok{    *  If jsonPath matches the given detector function, creates a function which}
\CommentTok{    *  evaluates against every clause in the clauseEvaluatorGenerators. The}
\CommentTok{    *  created function is propagated to the onSuccess function, along with}
\CommentTok{    *  the remaining unparsed JSONPath substring.}
\CommentTok{    *  }
\CommentTok{    *  The intended use is to create a clauseMatcher by filling in}
\CommentTok{    *  the first two arguments, thus providing a function that knows}
\CommentTok{    *  some syntax to match and what kind of generator to create if it}
\CommentTok{    *  finds it. The parameter list once completed is:}
\CommentTok{    *  }
\CommentTok{    *    (jsonPath, parserGeneratedSoFar, onSuccess)}
\CommentTok{    *  }
\CommentTok{    *  onSuccess may be compileJsonPathToFunction, to recursively continue }
\CommentTok{    *  parsing after finding a match or returnFoundParser to stop here.}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{generateClauseReaderIfTokenFound} \NormalTok{(}
     
                        \NormalTok{tokenDetector, clauseEvaluatorGenerators,}
                         
                        \NormalTok{jsonPath, parserGeneratedSoFar, onSuccess) \{}
                        
      \KeywordTok{var} \NormalTok{detected = }\FunctionTok{tokenDetector}\NormalTok{(jsonPath);}

      \KeywordTok{if}\NormalTok{(detected) \{}
         \KeywordTok{var} \NormalTok{compiledParser = }\FunctionTok{expressionsReader}\NormalTok{(}
                                 \NormalTok{clauseEvaluatorGenerators, }
                                 \NormalTok{parserGeneratedSoFar, }
                                 \NormalTok{detected}
                              \NormalTok{),}
         
             \NormalTok{remainingUnparsedJsonPath = }\OtherTok{jsonPath}\NormalTok{.}\FunctionTok{substr}\NormalTok{(}\FunctionTok{len}\NormalTok{(detected[}\DecValTok{0}\NormalTok{]));                }
                               
         \KeywordTok{return} \FunctionTok{onSuccess}\NormalTok{(remainingUnparsedJsonPath, compiledParser);}
      \NormalTok{\}         }
   \NormalTok{\}}
                 
   \CommentTok{/**}
\CommentTok{    * Partially completes generateClauseReaderIfTokenFound above. }
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{clauseMatcher}\NormalTok{(tokenDetector, exprs) \{}
        
      \KeywordTok{return}   \FunctionTok{partialComplete}\NormalTok{( }
                  \NormalTok{generateClauseReaderIfTokenFound, }
                  \NormalTok{tokenDetector, }
                  \NormalTok{exprs }
               \NormalTok{);}
   \NormalTok{\}}

   \CommentTok{/**}
\CommentTok{    * clauseForJsonPath is a function which attempts to match against }
\CommentTok{    * several clause matchers in order until one matches. If non match the}
\CommentTok{    * jsonPath expression is invalid and an error is thrown.}
\CommentTok{    * }
\CommentTok{    * The parameter list is the same as a single clauseMatcher:}
\CommentTok{    * }
\CommentTok{    *    (jsonPath, parserGeneratedSoFar, onSuccess)}
\CommentTok{    */}     
   \KeywordTok{var} \NormalTok{clauseForJsonPath = }\FunctionTok{lazyUnion}\NormalTok{(}

      \FunctionTok{clauseMatcher}\NormalTok{(pathNodeSyntax   , }\FunctionTok{list}\NormalTok{( capture, }
                                             \NormalTok{duckTypeClause, }
                                             \NormalTok{nameClause, }
                                             \NormalTok{skip1 ))}
                                                     
   \NormalTok{,  }\FunctionTok{clauseMatcher}\NormalTok{(doubleDotSyntax  , }\FunctionTok{list}\NormalTok{( skipMany))}
       
       \CommentTok{// dot is a separator only (like whitespace in other languages) but }
       \CommentTok{// rather than make it a special case, use an empty list of }
       \CommentTok{// expressions when this token is found}
   \NormalTok{,  }\FunctionTok{clauseMatcher}\NormalTok{(dotSyntax        , }\FunctionTok{list}\NormalTok{() )  }
                                                                                      
   \NormalTok{,  }\FunctionTok{clauseMatcher}\NormalTok{(bangSyntax       , }\FunctionTok{list}\NormalTok{( capture,}
                                             \NormalTok{rootExpr))}
                                                          
   \NormalTok{,  }\FunctionTok{clauseMatcher}\NormalTok{(emptySyntax      , }\FunctionTok{list}\NormalTok{( statementExpr))}
   
   \NormalTok{,  }\KeywordTok{function} \NormalTok{(jsonPath) \{}
         \KeywordTok{throw} \FunctionTok{Error}\NormalTok{(}\StringTok{'"'} \NormalTok{+ jsonPath + }\StringTok{'" could not be tokenised'}\NormalTok{)      }
      \NormalTok{\}}
   \NormalTok{);}


   \CommentTok{/**}
\CommentTok{    * One of two possible values for the onSuccess argument of }
\CommentTok{    * generateClauseReaderIfTokenFound.}
\CommentTok{    * }
\CommentTok{    * When this function is used, generateClauseReaderIfTokenFound simply }
\CommentTok{    * returns the compiledParser that it made, regardless of if there is }
\CommentTok{    * any remaining jsonPath to be compiled.}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{returnFoundParser}\NormalTok{(_remainingJsonPath, compiledParser)\{ }
      \KeywordTok{return} \NormalTok{compiledParser }
   \NormalTok{\}     }
              
   \CommentTok{/**}
\CommentTok{    * Recursively compile a JSONPath expression.}
\CommentTok{    * }
\CommentTok{    * This function serves as one of two possible values for the onSuccess }
\CommentTok{    * argument of generateClauseReaderIfTokenFound, meaning continue to}
\CommentTok{    * recursively compile. Otherwise, returnFoundParser is given and}
\CommentTok{    * compilation terminates.}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{compileJsonPathToFunction}\NormalTok{( uncompiledJsonPath, }
                                       \NormalTok{parserGeneratedSoFar ) \{}

      \CommentTok{/**}
\CommentTok{       * On finding a match, if there is remaining text to be compiled}
\CommentTok{       * we want to either continue parsing using a recursive call to }
\CommentTok{       * compileJsonPathToFunction. Otherwise, we want to stop and return }
\CommentTok{       * the parser that we have found so far.}
\CommentTok{       */}
      \KeywordTok{var} \NormalTok{onFind =      uncompiledJsonPath}
                     \NormalTok{?  compileJsonPathToFunction }
                     \NormalTok{:  returnFoundParser;}
                   
      \KeywordTok{return}   \FunctionTok{clauseForJsonPath}\NormalTok{( }
                  \NormalTok{uncompiledJsonPath, }
                  \NormalTok{parserGeneratedSoFar, }
                  \NormalTok{onFind}
               \NormalTok{);                              }
   \NormalTok{\}}

   \CommentTok{/**}
\CommentTok{    * This is the function that we expose to the rest of the library.}
\CommentTok{    */}
   \KeywordTok{return} \KeywordTok{function}\NormalTok{(jsonPath)\{}
        
      \KeywordTok{try} \NormalTok{\{}
         \CommentTok{// Kick off the recursive parsing of the jsonPath }
         \KeywordTok{return} \FunctionTok{compileJsonPathToFunction}\NormalTok{(jsonPath, always);}
         
      \NormalTok{\} }\KeywordTok{catch}\NormalTok{( e ) \{}
         \KeywordTok{throw} \FunctionTok{Error}\NormalTok{( }\StringTok{'Could not compile "'} \NormalTok{+ jsonPath + }
                      \StringTok{'" because '} \NormalTok{+ }\OtherTok{e}\NormalTok{.}\FunctionTok{message}
         \NormalTok{);}
      \NormalTok{\}}
   \NormalTok{\}}

\NormalTok{\});}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{jsonPathSyntax.js}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var} \NormalTok{jsonPathSyntax = (}\KeywordTok{function}\NormalTok{() \{}
 
   \KeywordTok{var}
   
   \CommentTok{/** }
\CommentTok{    * Export a regular expression as a simple function by exposing just }
\CommentTok{    * the Regex#exec. This allows regex tests to be used under the same }
\CommentTok{    * interface as differently implemented tests, or for a user of the}
\CommentTok{    * tests to not concern themselves with their implementation as regular}
\CommentTok{    * expressions.}
\CommentTok{    * }
\CommentTok{    * This could also be expressed point-free as:}
\CommentTok{    *   Function.prototype.bind.bind(RegExp.prototype.exec),}
\CommentTok{    *   }
\CommentTok{    * But that's far too confusing! (and not even smaller once minified }
\CommentTok{    * and gzipped)}
\CommentTok{    */}
       \NormalTok{regexDescriptor = }\KeywordTok{function} \FunctionTok{regexDescriptor}\NormalTok{(regex) \{}
            \KeywordTok{return} \OtherTok{regex}\NormalTok{.}\OtherTok{exec}\NormalTok{.}\FunctionTok{bind}\NormalTok{(regex);}
       \NormalTok{\}}
       
   \CommentTok{/**}
\CommentTok{    * Join several regular expressions and express as a function.}
\CommentTok{    * This allows the token patterns to reuse component regular expressions}
\CommentTok{    * instead of being expressed in full using huge and confusing regular}
\CommentTok{    * expressions.}
\CommentTok{    */}       
   \NormalTok{,   jsonPathClause = }\FunctionTok{varArgs}\NormalTok{(}\KeywordTok{function}\NormalTok{( componentRegexes ) \{}

            \CommentTok{// The regular expressions all start with ^ because we }
            \CommentTok{// only want to find matches at the start of the }
            \CommentTok{// JSONPath fragment we are inspecting           }
            \OtherTok{componentRegexes}\NormalTok{.}\FunctionTok{unshift}\NormalTok{(}\OtherTok{/}\FloatTok{^}\OtherTok{/}\NormalTok{);}
            
            \KeywordTok{return}   \FunctionTok{regexDescriptor}\NormalTok{(}
                        \FunctionTok{RegExp}\NormalTok{(}
                           \OtherTok{componentRegexes}\NormalTok{.}\FunctionTok{map}\NormalTok{(}\FunctionTok{attr}\NormalTok{(}\StringTok{'source'}\NormalTok{)).}\FunctionTok{join}\NormalTok{(}\StringTok{''}\NormalTok{)}
                        \NormalTok{)}
                     \NormalTok{);}
       \NormalTok{\})}
       
   \NormalTok{,   possiblyCapturing =           }\OtherTok{/}\FloatTok{(\textbackslash{}$?)}\OtherTok{/}
   \NormalTok{,   namedNode =                   }\OtherTok{/}\FloatTok{(}\BaseNTok{[}\FloatTok{\textbackslash{}w}\BaseNTok{-_]}\FloatTok{+\textbar{}\textbackslash{}*)}\OtherTok{/}
   \NormalTok{,   namePlaceholder =             }\OtherTok{/}\FloatTok{()}\OtherTok{/}
   \NormalTok{,   nodeInArrayNotation =         }\OtherTok{/}\FloatTok{\textbackslash{}[}\OtherTok{"}\FloatTok{(}\BaseNTok{[}\FloatTok{^}\BaseNTok{"]}\FloatTok{+)}\OtherTok{"}\FloatTok{\textbackslash{}]}\OtherTok{/}
   \NormalTok{,   numberedNodeInArrayNotation = }\OtherTok{/}\FloatTok{\textbackslash{}[(}\BaseNTok{\textbackslash{}d}\FloatTok{+\textbar{}\textbackslash{}*)\textbackslash{}]}\OtherTok{/}
   \NormalTok{,   fieldList =                      }\OtherTok{/\{}\FloatTok{(}\BaseNTok{[}\FloatTok{\textbackslash{}w}\BaseNTok{ ]}\FloatTok{*?)}\OtherTok{\}/}
   \NormalTok{,   optionalFieldList =           }\OtherTok{/}\FloatTok{(?}\OtherTok{:\{}\FloatTok{(}\BaseNTok{[}\FloatTok{\textbackslash{}w}\BaseNTok{ ]}\FloatTok{*?)}\OtherTok{\}}\FloatTok{)?}\OtherTok{/}
    

       \CommentTok{//   foo or *                  }
   \NormalTok{,   jsonPathNamedNodeInObjectNotation   = }\FunctionTok{jsonPathClause}\NormalTok{( }
                                                \NormalTok{possiblyCapturing, }
                                                \NormalTok{namedNode, }
                                                \NormalTok{optionalFieldList}
                                             \NormalTok{)}
                                             
       \CommentTok{//   ["foo"]   }
   \NormalTok{,   jsonPathNamedNodeInArrayNotation    = }\FunctionTok{jsonPathClause}\NormalTok{( }
                                                \NormalTok{possiblyCapturing, }
                                                \NormalTok{nodeInArrayNotation, }
                                                \NormalTok{optionalFieldList}
                                             \NormalTok{)  }

       \CommentTok{//   [2] or [*]       }
   \NormalTok{,   jsonPathNumberedNodeInArrayNotation = }\FunctionTok{jsonPathClause}\NormalTok{( }
                                                \NormalTok{possiblyCapturing, }
                                                \NormalTok{numberedNodeInArrayNotation, }
                                                \NormalTok{optionalFieldList}
                                             \NormalTok{)}

       \CommentTok{//   \{a b c\}      }
   \NormalTok{,   jsonPathPureDuckTyping              = }\FunctionTok{jsonPathClause}\NormalTok{( }
                                                \NormalTok{possiblyCapturing, }
                                                \NormalTok{namePlaceholder, }
                                                \NormalTok{fieldList}
                                             \NormalTok{)}
   
       \CommentTok{//   ..}
   \NormalTok{,   jsonPathDoubleDot                   = }\FunctionTok{jsonPathClause}\NormalTok{(}\OtherTok{/}\FloatTok{\textbackslash{}.\textbackslash{}.}\OtherTok{/}\NormalTok{)                  }
   
       \CommentTok{//   .}
   \NormalTok{,   jsonPathDot                         = }\FunctionTok{jsonPathClause}\NormalTok{(}\OtherTok{/}\FloatTok{\textbackslash{}.}\OtherTok{/}\NormalTok{)                    }
   
       \CommentTok{//   !}
   \NormalTok{,   jsonPathBang                        = }\FunctionTok{jsonPathClause}\NormalTok{(}
                                                \NormalTok{possiblyCapturing, }
                                                \OtherTok{/!/}
                                             \NormalTok{)  }
   
       \CommentTok{//   nada!}
   \NormalTok{,   emptyString                         = }\FunctionTok{jsonPathClause}\NormalTok{(}\OtherTok{/}\FloatTok{$}\OtherTok{/}\NormalTok{)                     }
   
   \NormalTok{;}
   
  
   \CommentTok{/* We export only a single function. When called, this function injects }
\CommentTok{      into another function the descriptors from above.             }
\CommentTok{    */}
   \KeywordTok{return} \KeywordTok{function} \NormalTok{(fn)\{      }
      \KeywordTok{return} \FunctionTok{fn}\NormalTok{(      }
         \FunctionTok{lazyUnion}\NormalTok{(}
            \NormalTok{jsonPathNamedNodeInObjectNotation}
         \NormalTok{,  jsonPathNamedNodeInArrayNotation}
         \NormalTok{,  jsonPathNumberedNodeInArrayNotation}
         \NormalTok{,  jsonPathPureDuckTyping }
         \NormalTok{)}
      \NormalTok{,  jsonPathDoubleDot}
      \NormalTok{,  jsonPathDot}
      \NormalTok{,  jsonPathBang}
      \NormalTok{,  emptyString }
      \NormalTok{);}
   \NormalTok{\}; }

\NormalTok{\}());}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{lists.js}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * Like cons in Lisp}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{cons}\NormalTok{(x, xs) \{}
   
   \CommentTok{/* Internally lists are linked 2-element Javascript arrays.}
\CommentTok{    }
\CommentTok{      So that lists are all immutable we Object.freeze in newer }
\CommentTok{      Javascript runtimes.}
\CommentTok{      }
\CommentTok{      In older engines freeze should have been polyfilled as the }
\CommentTok{      identity function. */}
   \KeywordTok{return} \OtherTok{Object}\NormalTok{.}\FunctionTok{freeze}\NormalTok{([x,xs]);}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * The empty list}
\CommentTok{ */}
\KeywordTok{var} \NormalTok{emptyList = }\KeywordTok{null}\NormalTok{,}

\CommentTok{/**}
\CommentTok{ * Get the head of a list.}
\CommentTok{ * }
\CommentTok{ * Ie, head(cons(a,b)) = a}
\CommentTok{ */}
    \NormalTok{head = }\FunctionTok{attr}\NormalTok{(}\DecValTok{0}\NormalTok{),}

\CommentTok{/**}
\CommentTok{ * Get the tail of a list.}
\CommentTok{ * }
\CommentTok{ * Ie, head(cons(a,b)) = a}
\CommentTok{ */}
    \NormalTok{tail = }\FunctionTok{attr}\NormalTok{(}\DecValTok{1}\NormalTok{);}


\CommentTok{/** }
\CommentTok{ * Converts an array to a list }
\CommentTok{ * }
\CommentTok{ *    asList([a,b,c])}
\CommentTok{ * }
\CommentTok{ * is equivalent to:}
\CommentTok{ *    }
\CommentTok{ *    cons(a, cons(b, cons(c, emptyList))) }
\CommentTok{ **/}
\KeywordTok{function} \FunctionTok{arrayAsList}\NormalTok{(inputArray)\{}

   \KeywordTok{return} \FunctionTok{reverseList}\NormalTok{( }
      \OtherTok{inputArray}\NormalTok{.}\FunctionTok{reduce}\NormalTok{(}
         \FunctionTok{flip}\NormalTok{(cons),}
         \NormalTok{emptyList }
      \NormalTok{)}
   \NormalTok{);}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * A varargs version of arrayAsList. Works a bit like list}
\CommentTok{ * in LISP.}
\CommentTok{ * }
\CommentTok{ *    list(a,b,c) }
\CommentTok{ *    }
\CommentTok{ * is equivalent to:}
\CommentTok{ * }
\CommentTok{ *    cons(a, cons(b, cons(c, emptyList)))}
\CommentTok{ */}
\KeywordTok{var} \NormalTok{list = }\FunctionTok{varArgs}\NormalTok{(arrayAsList);}

\CommentTok{/**}
\CommentTok{ * Convert a list back to a js native array}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{listAsArray}\NormalTok{(list)\{}

   \KeywordTok{return} \FunctionTok{foldR}\NormalTok{( }\KeywordTok{function}\NormalTok{(arraySoFar, listItem)\{}
      
      \OtherTok{arraySoFar}\NormalTok{.}\FunctionTok{unshift}\NormalTok{(listItem);}
      \KeywordTok{return} \NormalTok{arraySoFar;}
           
   \NormalTok{\}, [], list );}
   
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * Map a function over a list }
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{map}\NormalTok{(fn, list) \{}

   \KeywordTok{return} \NormalTok{list}
            \NormalTok{? }\FunctionTok{cons}\NormalTok{(}\FunctionTok{fn}\NormalTok{(}\FunctionTok{head}\NormalTok{(list)), }\FunctionTok{map}\NormalTok{(fn,}\FunctionTok{tail}\NormalTok{(list)))}
            \NormalTok{: emptyList}
            \NormalTok{;}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * foldR implementation. Reduce a list down to a single value.}
\CommentTok{ * }
\CommentTok{ * }\NormalTok{@pram}\CommentTok{ \{Function\} fn     (rightEval, curVal) -> result }
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{foldR}\NormalTok{(fn, startValue, list) \{}
      
   \KeywordTok{return} \NormalTok{list }
            \NormalTok{? }\FunctionTok{fn}\NormalTok{(}\FunctionTok{foldR}\NormalTok{(fn, startValue, }\FunctionTok{tail}\NormalTok{(list)), }\FunctionTok{head}\NormalTok{(list))}
            \NormalTok{: startValue}
            \NormalTok{;}
\NormalTok{\}}

\CommentTok{/** }
\CommentTok{ * Returns true if the given function holds for every item in }
\CommentTok{ * the list, false otherwise }
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{all}\NormalTok{(fn, list) \{}
   
   \KeywordTok{return} \NormalTok{!list \textbar{}\textbar{} }
          \FunctionTok{fn}\NormalTok{(}\FunctionTok{head}\NormalTok{(list)) && }\FunctionTok{all}\NormalTok{(fn, }\FunctionTok{tail}\NormalTok{(list));}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * Apply a function to every item in a list}
\CommentTok{ * }
\CommentTok{ * This doesn't make any sense if we're doing pure functional because }
\CommentTok{ * it doesn't return anything. Hence, this is only really useful if fn }
\CommentTok{ * has side-effects. }
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{each}\NormalTok{(fn, list) \{}

   \KeywordTok{if}\NormalTok{( list )\{  }
      \FunctionTok{fn}\NormalTok{(}\FunctionTok{head}\NormalTok{(list));}
      \FunctionTok{each}\NormalTok{(fn, }\FunctionTok{tail}\NormalTok{(list));}
   \NormalTok{\}}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * Reverse the order of a list}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{reverseList}\NormalTok{(list)\{ }

   \CommentTok{// js re-implementation of 3rd solution from:}
   \CommentTok{//    http://www.haskell.org/haskellwiki/99_questions/Solutions/5}
   \KeywordTok{function} \FunctionTok{reverseInner}\NormalTok{( list, reversedAlready ) \{}
      \KeywordTok{if}\NormalTok{( !list ) \{}
         \KeywordTok{return} \NormalTok{reversedAlready;}
      \NormalTok{\}}
      
      \KeywordTok{return} \FunctionTok{reverseInner}\NormalTok{(}\FunctionTok{tail}\NormalTok{(list), }\FunctionTok{cons}\NormalTok{(}\FunctionTok{head}\NormalTok{(list), reversedAlready))}
   \NormalTok{\}}

   \KeywordTok{return} \FunctionTok{reverseInner}\NormalTok{(list, emptyList);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{pubSub.js}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * Isn't this the cutest little pub-sub you've ever seen?}
\CommentTok{ * }
\CommentTok{ * Does not allow unsubscription because is never needed inside Oboe.}
\CommentTok{ * Instead, when an Oboe instance is finished the whole of it should be}
\CommentTok{ * available for GC'ing.}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{pubSub}\NormalTok{()\{}

   \KeywordTok{var} \NormalTok{listeners = \{\};}
                             
   \KeywordTok{return} \NormalTok{\{}

      \DataTypeTok{on}\NormalTok{:}\KeywordTok{function}\NormalTok{( eventId, fn ) \{}
         
         \NormalTok{listeners[eventId] = }\FunctionTok{cons}\NormalTok{(fn, listeners[eventId]);}

         \KeywordTok{return} \KeywordTok{this}\NormalTok{; }\CommentTok{// chaining}
      \NormalTok{\}, }
    
      \DataTypeTok{fire}\NormalTok{:}\KeywordTok{function} \NormalTok{( eventId, event ) \{}
               
         \FunctionTok{each}\NormalTok{(}
            \FunctionTok{partialComplete}\NormalTok{( apply, [event \textbar{}\textbar{} }\KeywordTok{undefined}\NormalTok{] ), }
            \NormalTok{listeners[eventId]}
         \NormalTok{);}
      \NormalTok{\}           }
   \NormalTok{\};}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{publicApi.js}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// export public API}
\KeywordTok{var} \NormalTok{oboe = }\FunctionTok{apiMethod}\NormalTok{(}\StringTok{'GET'}\NormalTok{);}
\OtherTok{oboe}\NormalTok{.}\FunctionTok{doGet}    \NormalTok{= oboe;}
\OtherTok{oboe}\NormalTok{.}\FunctionTok{doDelete} \NormalTok{= }\FunctionTok{apiMethod}\NormalTok{(}\StringTok{'DELETE'}\NormalTok{);}
\OtherTok{oboe}\NormalTok{.}\FunctionTok{doPost}   \NormalTok{= }\FunctionTok{apiMethod}\NormalTok{(}\StringTok{'POST'}\NormalTok{, }\KeywordTok{true}\NormalTok{);}
\OtherTok{oboe}\NormalTok{.}\FunctionTok{doPut}    \NormalTok{= }\FunctionTok{apiMethod}\NormalTok{(}\StringTok{'PUT'}\NormalTok{, }\KeywordTok{true}\NormalTok{);}
\OtherTok{oboe}\NormalTok{.}\FunctionTok{doPatch}  \NormalTok{= }\FunctionTok{apiMethod}\NormalTok{(}\StringTok{'PATCH'}\NormalTok{, }\KeywordTok{true}\NormalTok{);}

\KeywordTok{function} \FunctionTok{apiMethod}\NormalTok{(httpMethodName, mayHaveRequestBody) \{}
               
   \KeywordTok{return} \KeywordTok{function}\NormalTok{(firstArg) \{}

      \KeywordTok{if} \NormalTok{(}\OtherTok{firstArg}\NormalTok{.}\FunctionTok{url}\NormalTok{) \{}

         \CommentTok{// method signature is:}
         \CommentTok{//    .doMethod(\{url:u, body:b, complete:c, headers:\{...\}\})}

         \KeywordTok{return} \FunctionTok{wire}\NormalTok{(}
             \NormalTok{httpMethodName,}
             \OtherTok{firstArg}\NormalTok{.}\FunctionTok{url}\NormalTok{,}
             \OtherTok{firstArg}\NormalTok{.}\FunctionTok{body}\NormalTok{,}
             \OtherTok{firstArg}\NormalTok{.}\FunctionTok{headers}
         \NormalTok{);}
      \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}

         \CommentTok{// parameters specified as arguments}
         \CommentTok{//}
         \CommentTok{//  if (mayHaveContext == true) method signature is:}
         \CommentTok{//     .doMethod( url, content )}
         \CommentTok{//}
         \CommentTok{//  else it is:}
         \CommentTok{//     .doMethod( url )            }
         \CommentTok{//                                }
         \KeywordTok{return} \FunctionTok{wire}\NormalTok{(}
             \NormalTok{httpMethodName,}
             \NormalTok{firstArg, }\CommentTok{// url}
             \NormalTok{mayHaveRequestBody && arguments[}\DecValTok{1}\NormalTok{]         }\CommentTok{// body}
         \NormalTok{);}
      \NormalTok{\}}
   \NormalTok{\};}
\NormalTok{\}   }
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{streamingHttp-browser.js}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{httpTransport}\NormalTok{()\{}
   \KeywordTok{return} \KeywordTok{new} \FunctionTok{XMLHttpRequest}\NormalTok{();}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * A wrapper around the browser XmlHttpRequest object that raises an }
\CommentTok{ * event whenever a new part of the response is available.}
\CommentTok{ * }
\CommentTok{ * In older browsers progressive reading is impossible so all the }
\CommentTok{ * content is given in a single call. For newer ones several events}
\CommentTok{ * should be raised, allowing progressive interpretation of the response.}
\CommentTok{ *      }
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ fire a function to pass events to when something happens}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ on a function to use to subscribe to events}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{XMLHttpRequest\}}\CommentTok{ xhr the xhr to use as the transport. Under normal}
\CommentTok{ *          operation, will have been created using httpTransport() above}
\CommentTok{ *          but for tests a stub can be provided instead.}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\}}\CommentTok{ method one of 'GET' 'POST' 'PUT' 'PATCH' 'DELETE'}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\}}\CommentTok{ url the url to make a request to}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\textbar{}Object\}}\CommentTok{ data some content to be sent with the request.}
\CommentTok{ *                        Only valid if method is POST or PUT.}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Object\}}\CommentTok{ [headers] the http request headers to send                       }
\CommentTok{ */}  
\KeywordTok{function} \FunctionTok{streamingHttp}\NormalTok{(fire, on, xhr, method, url, data, headers) \{}
        
   \KeywordTok{var} \NormalTok{numberOfCharsAlreadyGivenToCallback = }\DecValTok{0}\NormalTok{;}

   \CommentTok{// When an ABORTING message is put on the event bus abort }
   \CommentTok{// the ajax request         }
   \FunctionTok{on}\NormalTok{( ABORTING, }\KeywordTok{function}\NormalTok{()\{}
  
      \CommentTok{// if we keep the onreadystatechange while aborting the XHR gives }
      \CommentTok{// a callback like a successful call so first remove this listener}
      \CommentTok{// by assigning null:}
      \OtherTok{xhr}\NormalTok{.}\FunctionTok{onreadystatechange} \NormalTok{= }\KeywordTok{null}\NormalTok{;}
            
      \OtherTok{xhr}\NormalTok{.}\FunctionTok{abort}\NormalTok{();}
   \NormalTok{\});}

   \CommentTok{/** Given a value from the user to send as the request body, return in}
\CommentTok{    *  a form that is suitable to sending over the wire. Returns either a }
\CommentTok{    *  string, or null.        }
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{validatedRequestBody}\NormalTok{( body ) \{}
      \KeywordTok{if}\NormalTok{( !body )}
         \KeywordTok{return} \KeywordTok{null}\NormalTok{;}
   
      \KeywordTok{return} \FunctionTok{isString}\NormalTok{(body)? body: }\OtherTok{JSON}\NormalTok{.}\FunctionTok{stringify}\NormalTok{(body);}
   \NormalTok{\}      }

   \CommentTok{/** }
\CommentTok{    * Handle input from the underlying xhr: either a state change,}
\CommentTok{    * the progress event or the request being complete.}
\CommentTok{    */}
   \KeywordTok{function} \FunctionTok{handleProgress}\NormalTok{() \{}
                        
      \KeywordTok{var} \NormalTok{textSoFar = }\OtherTok{xhr}\NormalTok{.}\FunctionTok{responseText}\NormalTok{,}
          \NormalTok{newText = }\OtherTok{textSoFar}\NormalTok{.}\FunctionTok{substr}\NormalTok{(numberOfCharsAlreadyGivenToCallback);}
      
      
      \CommentTok{/* Raise the event for new text.}
\CommentTok{      }
\CommentTok{         On older browsers, the new text is the whole response. }
\CommentTok{         On newer/better ones, the fragment part that we got since }
\CommentTok{         last progress. */}
         
      \KeywordTok{if}\NormalTok{( newText ) \{}
         \FunctionTok{fire}\NormalTok{( NEW_CONTENT, newText );}
      \NormalTok{\} }

      \NormalTok{numberOfCharsAlreadyGivenToCallback = }\FunctionTok{len}\NormalTok{(textSoFar);}
   \NormalTok{\}}
   
   
   \KeywordTok{if}\NormalTok{(}\StringTok{'onprogress'} \KeywordTok{in} \NormalTok{xhr)\{  }\CommentTok{// detect browser support for progressive delivery}
      \OtherTok{xhr}\NormalTok{.}\FunctionTok{onprogress} \NormalTok{= handleProgress;}
   \NormalTok{\}}
   
   \OtherTok{xhr}\NormalTok{.}\FunctionTok{onreadystatechange} \NormalTok{= }\KeywordTok{function}\NormalTok{() \{}
            
      \KeywordTok{if}\NormalTok{(}\OtherTok{xhr}\NormalTok{.}\FunctionTok{readyState} \NormalTok{== }\DecValTok{4} \NormalTok{) \{}

         \CommentTok{// is this a 2xx http code?}
         \KeywordTok{var} \NormalTok{sucessful = }\FunctionTok{String}\NormalTok{(}\OtherTok{xhr}\NormalTok{.}\FunctionTok{status}\NormalTok{)[}\DecValTok{0}\NormalTok{] == }\DecValTok{2}\NormalTok{;}
         
         \KeywordTok{if}\NormalTok{( sucessful ) \{}
            \CommentTok{// In Chrome 29 (not 28) no onprogress is fired when a response}
            \CommentTok{// is complete before the onload. We need to always do handleInput}
            \CommentTok{// in case we get the load but have not had a final progress event.}
            \CommentTok{// This looks like a bug and may change in future but let's take}
            \CommentTok{// the safest approach and assume we might not have received a }
            \CommentTok{// progress event for each part of the response}
            \FunctionTok{handleProgress}\NormalTok{();}
            
            \FunctionTok{fire}\NormalTok{( END_OF_CONTENT );}
         \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
         
            \FunctionTok{fire}\NormalTok{( ERROR_EVENT, }\OtherTok{xhr}\NormalTok{.}\FunctionTok{status} \NormalTok{);}
         \NormalTok{\}}
      \NormalTok{\}}
   \NormalTok{\};}

   \KeywordTok{try}\NormalTok{\{}
   
      \OtherTok{xhr}\NormalTok{.}\FunctionTok{open}\NormalTok{(method, url, }\KeywordTok{true}\NormalTok{);}
   
      \KeywordTok{for}\NormalTok{( }\KeywordTok{var} \NormalTok{headerName }\KeywordTok{in} \NormalTok{headers )\{}
         \OtherTok{xhr}\NormalTok{.}\FunctionTok{setRequestHeader}\NormalTok{(headerName, headers[headerName]);}
      \NormalTok{\}}
      
      \OtherTok{xhr}\NormalTok{.}\FunctionTok{send}\NormalTok{(}\FunctionTok{validatedRequestBody}\NormalTok{(data));}
      
   \NormalTok{\} }\KeywordTok{catch}\NormalTok{( e ) \{}
      \CommentTok{// To keep a consistent interface with Node, we can't fire an event here.}
      \CommentTok{// Node's streaming http adaptor receives the error as an asynchronous}
      \CommentTok{// event rather than as an exception. If we fired now, the Oboe user}
      \CommentTok{// has had no chance to add a .fail listener so there is no way}
      \CommentTok{// the event could be useful. For both these reasons defer the}
      \CommentTok{// firing to the next JS frame.  }
      \OtherTok{window}\NormalTok{.}\FunctionTok{setTimeout}\NormalTok{(}\FunctionTok{partialComplete}\NormalTok{(fire, ERROR_EVENT, e), }\DecValTok{0}\NormalTok{);}
   \NormalTok{\}            }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{streamingHttp-node.js}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function} \FunctionTok{httpTransport}\NormalTok{()\{}
   \KeywordTok{return} \FunctionTok{require}\NormalTok{(}\StringTok{'http'}\NormalTok{);}
\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * A wrapper around the browser XmlHttpRequest object that raises an }
\CommentTok{ * event whenever a new part of the response is available.}
\CommentTok{ * }
\CommentTok{ * In older browsers progressive reading is impossible so all the }
\CommentTok{ * content is given in a single call. For newer ones several events}
\CommentTok{ * should be raised, allowing progressive interpretation of the response.}
\CommentTok{ *      }
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ fire a function to pass events to when something happens}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Function\}}\CommentTok{ on a function to use to subscribe to events}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{XMLHttpRequest\}}\CommentTok{ http the http implementation to use as the transport. Under normal}
\CommentTok{ *          operation, will have been created using httpTransport() above}
\CommentTok{ *          and therefore be Node's http}
\CommentTok{ *          but for tests a stub may be provided instead.}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\}}\CommentTok{ method one of 'GET' 'POST' 'PUT' 'PATCH' 'DELETE'}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\}}\CommentTok{ contentSource the url to make a request to, or a stream to read from}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{String\textbar{}Object\}}\CommentTok{ data some content to be sent with the request.}
\CommentTok{ *                        Only valid if method is POST or PUT.}
\CommentTok{ * }\KeywordTok{@param}\CommentTok{ }\KeywordTok{\{Object\}}\CommentTok{ [headers] the http request headers to send                       }
\CommentTok{ */}  
\KeywordTok{function} \FunctionTok{streamingHttp}\NormalTok{(fire, on, http, method, contentSource, data, headers) \{}

   \KeywordTok{function} \FunctionTok{readFromStream}\NormalTok{(readableStream) \{}
         
      \CommentTok{// use stream in flowing mode   }
      \OtherTok{readableStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'data'}\NormalTok{, }\KeywordTok{function} \NormalTok{(chunk) \{}
                                             
         \FunctionTok{fire}\NormalTok{( NEW_CONTENT, }\OtherTok{chunk}\NormalTok{.}\FunctionTok{toString}\NormalTok{() );}
      \NormalTok{\});}
      
      \OtherTok{readableStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'end'}\NormalTok{, }\KeywordTok{function}\NormalTok{() \{}
               
         \FunctionTok{fire}\NormalTok{( END_OF_CONTENT );}
      \NormalTok{\});}
   \NormalTok{\}}
   
   \KeywordTok{function} \FunctionTok{fetchUrl}\NormalTok{( url ) \{}
      \KeywordTok{if}\NormalTok{( !}\OtherTok{contentSource}\NormalTok{.}\FunctionTok{match}\NormalTok{(}\OtherTok{/http:}\FloatTok{\textbackslash{}/\textbackslash{}/}\OtherTok{/}\NormalTok{) ) \{}
         \NormalTok{contentSource = }\StringTok{'http://'} \NormalTok{+ contentSource;}
      \NormalTok{\}                           }
                           
      \KeywordTok{var} \NormalTok{parsedUrl = }\FunctionTok{require}\NormalTok{(}\StringTok{'url'}\NormalTok{).}\FunctionTok{parse}\NormalTok{(contentSource); }
   
      \KeywordTok{var} \NormalTok{req = }\OtherTok{http}\NormalTok{.}\FunctionTok{request}\NormalTok{(\{}
         \DataTypeTok{hostname}\NormalTok{: }\OtherTok{parsedUrl}\NormalTok{.}\FunctionTok{hostname}\NormalTok{,}
         \DataTypeTok{port}\NormalTok{: }\OtherTok{parsedUrl}\NormalTok{.}\FunctionTok{port}\NormalTok{, }
         \DataTypeTok{path}\NormalTok{: }\OtherTok{parsedUrl}\NormalTok{.}\FunctionTok{pathname}\NormalTok{,}
         \DataTypeTok{method}\NormalTok{: method,}
         \DataTypeTok{headers}\NormalTok{: headers }
      \NormalTok{\});}
      
      \OtherTok{req}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'response'}\NormalTok{, }\KeywordTok{function}\NormalTok{(res)\{}
         \KeywordTok{var} \NormalTok{statusCode = }\OtherTok{res}\NormalTok{.}\FunctionTok{statusCode}\NormalTok{,}
             \NormalTok{sucessful = }\FunctionTok{String}\NormalTok{(statusCode)[}\DecValTok{0}\NormalTok{] == }\DecValTok{2}\NormalTok{;}
                                
         \KeywordTok{if}\NormalTok{( sucessful ) \{          }
               
            \FunctionTok{readFromStream}\NormalTok{(res)}
            
         \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
         
            \FunctionTok{fire}\NormalTok{( ERROR_EVENT, statusCode );}
         \NormalTok{\}      }
      \NormalTok{\});}
      
      \OtherTok{req}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'error'}\NormalTok{, }\KeywordTok{function}\NormalTok{(e) \{}
         \FunctionTok{fire}\NormalTok{( ERROR_EVENT, e );}
      \NormalTok{\});}
      
      \FunctionTok{on}\NormalTok{( ABORTING, }\KeywordTok{function}\NormalTok{()\{              }
         \OtherTok{req}\NormalTok{.}\FunctionTok{abort}\NormalTok{();}
      \NormalTok{\});}
         
      \KeywordTok{if}\NormalTok{( data ) \{}
         \KeywordTok{var} \NormalTok{body = }\FunctionTok{isString}\NormalTok{(data)? data: }\OtherTok{JSON}\NormalTok{.}\FunctionTok{stringify}\NormalTok{(data);}
         \OtherTok{req}\NormalTok{.}\FunctionTok{write}\NormalTok{(body);}
      \NormalTok{\}}
      
      \OtherTok{req}\NormalTok{.}\FunctionTok{end}\NormalTok{();         }
   \NormalTok{\}}
   
   \KeywordTok{if}\NormalTok{( }\FunctionTok{isString}\NormalTok{(contentSource) ) \{}
      \FunctionTok{fetchUrl}\NormalTok{(contentSource);}
   \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
      \CommentTok{// contentsource is a stream}
      \FunctionTok{readFromStream}\NormalTok{(contentSource);   }
   \NormalTok{\}}

\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{util.js}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * This file defines some loosely associated syntactic sugar for }
\CommentTok{ * Javascript programming }
\CommentTok{ */}


\CommentTok{/**}
\CommentTok{ * Returns true if the given candidate is of type T}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{isOfType}\NormalTok{(T, maybeSomething)\{}
   \KeywordTok{return} \NormalTok{maybeSomething && }\OtherTok{maybeSomething}\NormalTok{.}\FunctionTok{constructor} \NormalTok{=== T;}
\NormalTok{\}}
\KeywordTok{function} \FunctionTok{pluck}\NormalTok{(key, object)\{}
   \KeywordTok{return} \NormalTok{object[key];}
\NormalTok{\}}

\KeywordTok{var} \NormalTok{attr = }\FunctionTok{partialComplete}\NormalTok{(partialComplete, pluck),}
    \NormalTok{len = }\FunctionTok{attr}\NormalTok{(}\StringTok{'length'}\NormalTok{),    }
    \NormalTok{isString = }\FunctionTok{partialComplete}\NormalTok{(isOfType, String);}

\CommentTok{/** }
\CommentTok{ * I don't like saying this:}
\CommentTok{ * }
\CommentTok{ *    foo !=== undefined}
\CommentTok{ *    }
\CommentTok{ * because of the double-negative. I find this:}
\CommentTok{ * }
\CommentTok{ *    defined(foo)}
\CommentTok{ *    }
\CommentTok{ * easier to read.}
\CommentTok{ */} 
\KeywordTok{function} \FunctionTok{defined}\NormalTok{( value ) \{}
   \KeywordTok{return} \NormalTok{value !== }\KeywordTok{undefined}\NormalTok{;}
\NormalTok{\}}

\KeywordTok{function} \FunctionTok{always}\NormalTok{()\{}\KeywordTok{return} \KeywordTok{true}\NormalTok{\}}

\CommentTok{/**}
\CommentTok{ * Returns true if object o has a key named like every property in }
\CommentTok{ * the properties array. Will give false if any are missing, or if o }
\CommentTok{ * is not an object.}
\CommentTok{ */}
\KeywordTok{function} \FunctionTok{hasAllProperties}\NormalTok{(fieldList, o) \{}

   \KeywordTok{return}      \NormalTok{(o }\KeywordTok{instanceof} \NormalTok{Object) }
            \NormalTok{&&}
               \FunctionTok{all}\NormalTok{(}\KeywordTok{function} \NormalTok{(field) \{         }
                  \KeywordTok{return} \NormalTok{(field }\KeywordTok{in} \NormalTok{o);         }
               \NormalTok{\}, fieldList);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{wire.js}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**}
\CommentTok{ * This file sits just behind the API which is used to attain a new}
\CommentTok{ * Oboe instance. It creates the new components that are required}
\CommentTok{ * and introduces them to each other.}
\CommentTok{ */}

\KeywordTok{function} \FunctionTok{wire} \NormalTok{(httpMethodName, contentSource, body, headers)\{}

   \KeywordTok{var} \NormalTok{eventBus = }\FunctionTok{pubSub}\NormalTok{();}
               
   \FunctionTok{streamingHttp}\NormalTok{( }\OtherTok{eventBus}\NormalTok{.}\FunctionTok{fire}\NormalTok{, }\OtherTok{eventBus}\NormalTok{.}\FunctionTok{on}\NormalTok{,}
                  \FunctionTok{httpTransport}\NormalTok{(), }
                  \NormalTok{httpMethodName, contentSource, body, headers );                              }
     
   \KeywordTok{return} \FunctionTok{instanceController}\NormalTok{( }
               \OtherTok{eventBus}\NormalTok{.}\FunctionTok{fire}\NormalTok{, }\OtherTok{eventBus}\NormalTok{.}\FunctionTok{on}\NormalTok{, }
               \OtherTok{clarinet}\NormalTok{.}\FunctionTok{parser}\NormalTok{(), }
               \FunctionTok{incrementalContentBuilder}\NormalTok{(}\OtherTok{eventBus}\NormalTok{.}\FunctionTok{fire}\NormalTok{) }
   \NormalTok{);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{Appendix iii: Benchmarking}

\subsection{benchmarkClient.js}

\begin{Shaded}
\begin{Highlighting}[]

\CommentTok{/* call this script from the command line with first argument either}
\CommentTok{    oboe, jsonParse, or clarinet.}
\CommentTok{    }
\CommentTok{   This script won't time the events, I'm using `time` on the command line}
\CommentTok{   to keep things simple.}
\CommentTok{ */}

\FunctionTok{require}\NormalTok{(}\StringTok{'color'}\NormalTok{);}

\KeywordTok{var} \NormalTok{DB_URL = }\StringTok{'http://localhost:4444/db'}\NormalTok{;  }


\KeywordTok{function} \FunctionTok{aggregateWithOboe}\NormalTok{() \{}

   \KeywordTok{var} \NormalTok{oboe = }\FunctionTok{require}\NormalTok{(}\StringTok{'../dist/oboe-node.js'}\NormalTok{);}
   
   \FunctionTok{oboe}\NormalTok{(DB_URL).}\FunctionTok{node}\NormalTok{(}\StringTok{'\{id url\}.url'}\NormalTok{, }\KeywordTok{function}\NormalTok{(url)\{}
           
      \FunctionTok{oboe}\NormalTok{(url).}\FunctionTok{node}\NormalTok{(}\StringTok{'name'}\NormalTok{, }\KeywordTok{function}\NormalTok{(name)\{}
                      
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(name);}
         \KeywordTok{this}\NormalTok{.}\FunctionTok{abort}\NormalTok{();}
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\OtherTok{process}\NormalTok{.}\FunctionTok{memoryUsage}\NormalTok{().}\FunctionTok{heapUsed} \NormalTok{);         }
      \NormalTok{\});      }
   \NormalTok{\});                 }
\NormalTok{\}}

\KeywordTok{function} \FunctionTok{aggregateWithJsonParse}\NormalTok{() \{}

   \KeywordTok{var} \NormalTok{getJson = }\FunctionTok{require}\NormalTok{(}\StringTok{'get-json'}\NormalTok{);}

   \FunctionTok{getJson}\NormalTok{(DB_URL, }\KeywordTok{function}\NormalTok{(err, records) \{}
       
      \OtherTok{records}\NormalTok{.}\OtherTok{data}\NormalTok{.}\FunctionTok{forEach}\NormalTok{( }\KeywordTok{function}\NormalTok{( record )\{}
       
         \KeywordTok{var} \NormalTok{url = }\OtherTok{record}\NormalTok{.}\FunctionTok{url}\NormalTok{;}
         
         \FunctionTok{getJson}\NormalTok{(url, }\KeywordTok{function}\NormalTok{(err, record) \{}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\OtherTok{record}\NormalTok{.}\FunctionTok{name}\NormalTok{);}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\OtherTok{process}\NormalTok{.}\FunctionTok{memoryUsage}\NormalTok{().}\FunctionTok{heapUsed} \NormalTok{);}
         \NormalTok{\});}
      \NormalTok{\});}

   \NormalTok{\});   }

\NormalTok{\}}


\KeywordTok{function} \FunctionTok{aggregateWithClarinet}\NormalTok{() \{}

   \KeywordTok{var} \NormalTok{clarinet = }\FunctionTok{require}\NormalTok{(}\StringTok{'clarinet'}\NormalTok{);   }
   \KeywordTok{var} \NormalTok{http = }\FunctionTok{require}\NormalTok{(}\StringTok{'http'}\NormalTok{);}
   \KeywordTok{var} \NormalTok{outerClarinetStream = }\OtherTok{clarinet}\NormalTok{.}\FunctionTok{createStream}\NormalTok{();}
   \KeywordTok{var} \NormalTok{outerKey;}
   
   \KeywordTok{var} \NormalTok{outerRequest = }\OtherTok{http}\NormalTok{.}\FunctionTok{request}\NormalTok{(DB_URL, }\KeywordTok{function}\NormalTok{(res) \{}
                              
      \OtherTok{res}\NormalTok{.}\FunctionTok{pipe}\NormalTok{(outerClarinetStream);}
   \NormalTok{\});}
   
   \NormalTok{outerClarinetStream = }\OtherTok{clarinet}\NormalTok{.}\FunctionTok{createStream}\NormalTok{();}
      
   \OtherTok{outerRequest}\NormalTok{.}\FunctionTok{end}\NormalTok{();}
      
   \OtherTok{outerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'openobject'}\NormalTok{, }\KeywordTok{function}\NormalTok{( keyName )\{      }
      \KeywordTok{if}\NormalTok{( keyName ) \{}
         \NormalTok{outerKey = keyName;      }
      \NormalTok{\}}
   \NormalTok{\});}
   
   \OtherTok{outerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'key'}\NormalTok{, }\KeywordTok{function}\NormalTok{(keyName)\{}
      \NormalTok{outerKey = keyName;}
   \NormalTok{\});}
   
   \OtherTok{outerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'value'}\NormalTok{, }\KeywordTok{function}\NormalTok{(value)\{}
      \KeywordTok{if}\NormalTok{( outerKey == }\StringTok{'url'} \NormalTok{) \{}
         \FunctionTok{innerRequest}\NormalTok{(value)}
      \NormalTok{\}}
   \NormalTok{\});      }
   
   
   \KeywordTok{function} \FunctionTok{innerRequest}\NormalTok{(url) \{}
      
      \KeywordTok{var} \NormalTok{innerRequest = }\OtherTok{http}\NormalTok{.}\FunctionTok{request}\NormalTok{(url, }\KeywordTok{function}\NormalTok{(res) \{}
                                 
         \OtherTok{res}\NormalTok{.}\FunctionTok{pipe}\NormalTok{(innerClarinetStream);}
      \NormalTok{\});}
      
      \KeywordTok{var} \NormalTok{innerClarinetStream = }\OtherTok{clarinet}\NormalTok{.}\FunctionTok{createStream}\NormalTok{();}
      
      \OtherTok{innerRequest}\NormalTok{.}\FunctionTok{end}\NormalTok{();            }
      
      \KeywordTok{var} \NormalTok{innerKey;}
      
      \OtherTok{innerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'openobject'}\NormalTok{, }\KeywordTok{function}\NormalTok{( keyName )\{      }
         \KeywordTok{if}\NormalTok{( keyName ) \{}
            \NormalTok{innerKey = keyName;      }
         \NormalTok{\}}
      \NormalTok{\});}
      
      \OtherTok{innerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'key'}\NormalTok{, }\KeywordTok{function}\NormalTok{(keyName)\{}
         \NormalTok{innerKey = keyName;}
      \NormalTok{\});}
      
      \OtherTok{innerClarinetStream}\NormalTok{.}\FunctionTok{on}\NormalTok{(}\StringTok{'value'}\NormalTok{, }\KeywordTok{function}\NormalTok{(value)\{}
         \KeywordTok{if}\NormalTok{( innerKey == }\StringTok{'name'} \NormalTok{) \{}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( value )}
            \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{( }\OtherTok{process}\NormalTok{.}\FunctionTok{memoryUsage}\NormalTok{().}\FunctionTok{heapUsed} \NormalTok{);            }
         \NormalTok{\}}
      \NormalTok{\});            }
   \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{var} \NormalTok{strategies = \{}
   \DataTypeTok{oboe}\NormalTok{:       aggregateWithOboe,}
   \DataTypeTok{jsonParse}\NormalTok{:  aggregateWithJsonParse,}
   \DataTypeTok{clarinet}\NormalTok{:   aggregateWithClarinet}
\NormalTok{\}}

\KeywordTok{var} \NormalTok{strategyName = }\OtherTok{process}\NormalTok{.}\FunctionTok{argv}\NormalTok{[}\DecValTok{2}\NormalTok{];}

\CommentTok{// use any of the above three strategies depending on a command line argument:}
\OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'benchmarking strategy'}\NormalTok{, strategyName);}

\NormalTok{strategies[strategyName]();}

\end{Highlighting}
\end{Shaded}

\pagebreak

\subsection{benchmarkServer.js}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{/**   }
\CommentTok{ */}

\StringTok{"use strict"}\NormalTok{;}

\KeywordTok{var} \NormalTok{PORT = }\DecValTok{4444}\NormalTok{;}

\KeywordTok{var} \NormalTok{TIME_BETWEEN_RECORDS = }\DecValTok{15}\NormalTok{;}
\CommentTok{// 80 records but only every other one has a URL:}
\KeywordTok{var} \NormalTok{NUMBER_OF_RECORDS = }\DecValTok{80}\NormalTok{;}

\KeywordTok{function} \FunctionTok{sendJsonHeaders}\NormalTok{(res) \{}
   \KeywordTok{var} \NormalTok{JSON_MIME_TYPE = }\StringTok{"application/octet-stream"}\NormalTok{;}
   \OtherTok{res}\NormalTok{.}\FunctionTok{setHeader}\NormalTok{(}\StringTok{"Content-Type"}\NormalTok{, JSON_MIME_TYPE);}
   \OtherTok{res}\NormalTok{.}\FunctionTok{writeHead}\NormalTok{(}\DecValTok{200}\NormalTok{);}
\NormalTok{\}}

\KeywordTok{function} \FunctionTok{serveItemList}\NormalTok{(_req, res) \{}

   \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'slow fake db server: send simulated database data'}\NormalTok{);}

   \OtherTok{res}\NormalTok{.}\FunctionTok{write}\NormalTok{(}\StringTok{'\{"data": ['}\NormalTok{);}

   \KeywordTok{var} \NormalTok{i = }\DecValTok{0}\NormalTok{;}

   \KeywordTok{var} \NormalTok{inervalId = }\FunctionTok{setInterval}\NormalTok{(}\KeywordTok{function} \NormalTok{() \{}

      \KeywordTok{if}\NormalTok{( i % }\DecValTok{2} \NormalTok{== }\DecValTok{0} \NormalTok{) \{}

         \OtherTok{res}\NormalTok{.}\FunctionTok{write}\NormalTok{(}\OtherTok{JSON}\NormalTok{.}\FunctionTok{stringify}\NormalTok{(\{}
            \StringTok{"id"}\NormalTok{: i,}
            \StringTok{"url"}\NormalTok{: }\StringTok{"http://localhost:4444/item/"} \NormalTok{+ i         }
         \NormalTok{\}));}
      \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
         \OtherTok{res}\NormalTok{.}\FunctionTok{write}\NormalTok{(}\OtherTok{JSON}\NormalTok{.}\FunctionTok{stringify}\NormalTok{(\{}
            \StringTok{"id"}\NormalTok{: i         }
         \NormalTok{\}));      }
      \NormalTok{\}}
      
      \KeywordTok{if} \NormalTok{(i == NUMBER_OF_RECORDS) \{}

         \OtherTok{res}\NormalTok{.}\FunctionTok{end}\NormalTok{(}\StringTok{']\}'}\NormalTok{);}
         
         \FunctionTok{clearInterval}\NormalTok{(inervalId);}
         
         \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'db server: finished writing to stream'}\NormalTok{);}
      \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
         \OtherTok{res}\NormalTok{.}\FunctionTok{write}\NormalTok{(}\StringTok{','}\NormalTok{);}
      \NormalTok{\}}
      
      \NormalTok{i++;  }

   \NormalTok{\}, TIME_BETWEEN_RECORDS);}
\NormalTok{\}}

\KeywordTok{function} \FunctionTok{serveItem}\NormalTok{(req, res)\{}

   \KeywordTok{var} \NormalTok{id = }\OtherTok{req}\NormalTok{.}\OtherTok{params}\NormalTok{.}\FunctionTok{id}\NormalTok{;}
   
   \OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'will output fake record with id'}\NormalTok{, id);     }

   \FunctionTok{setTimeout}\NormalTok{(}\KeywordTok{function}\NormalTok{()\{}
      \CommentTok{// the items served are all the same except for the id field.}
      \CommentTok{// this is realistic looking but randomly generated object fro}
      \CommentTok{// <project>/test/json/oneHundredrecords.json   }
      \OtherTok{res}\NormalTok{.}\FunctionTok{end}\NormalTok{(}\OtherTok{JSON}\NormalTok{.}\FunctionTok{stringify}\NormalTok{(\{}
         \StringTok{"id"} \NormalTok{: id,}
         \StringTok{"url"}\NormalTok{: }\StringTok{"http://localhost:4444/item/"} \NormalTok{+ id,      }
         \StringTok{"guid"}\NormalTok{: }\StringTok{"046447ee-da78-478c-b518-b612111942a5"}\NormalTok{,}
         \StringTok{"picture"}\NormalTok{: }\StringTok{"http://placehold.it/32x32"}\NormalTok{,}
         \StringTok{"age"}\NormalTok{: }\DecValTok{37}\NormalTok{,}
         \StringTok{"name"}\NormalTok{: }\StringTok{"Humanoid robot number "} \NormalTok{+ id,}
         \StringTok{"company"}\NormalTok{: }\StringTok{"Robotomic"}\NormalTok{,}
         \StringTok{"phone"}\NormalTok{: }\StringTok{"806-587-2379"}\NormalTok{,}
         \StringTok{"email"}\NormalTok{: }\StringTok{"payton@robotomic.com"}
      \NormalTok{\}));}
            
   \NormalTok{\}, TIME_BETWEEN_RECORDS);}

\NormalTok{\}}

\KeywordTok{function} \FunctionTok{routing}\NormalTok{() \{}
   \KeywordTok{var} \NormalTok{Router = }\FunctionTok{require}\NormalTok{(}\StringTok{'node-simple-router'}\NormalTok{),}
       \NormalTok{router = }\FunctionTok{Router}\NormalTok{();}

   \OtherTok{router}\NormalTok{.}\FunctionTok{get}\NormalTok{( }\StringTok{'/db'}\NormalTok{,         serveItemList);}
   \OtherTok{router}\NormalTok{.}\FunctionTok{get}\NormalTok{( }\StringTok{'/item/:id'}\NormalTok{,   serveItem);}
   
   \KeywordTok{return} \NormalTok{router;}
\NormalTok{\}}
      
\KeywordTok{var} \NormalTok{server = }\FunctionTok{require}\NormalTok{(}\StringTok{'http'}\NormalTok{).}\FunctionTok{createServer}\NormalTok{(}\FunctionTok{routing}\NormalTok{()).}\FunctionTok{listen}\NormalTok{(PORT);}

\OtherTok{console}\NormalTok{.}\FunctionTok{log}\NormalTok{(}\StringTok{'Benchmark server started on port'}\NormalTok{, }\FunctionTok{String}\NormalTok{(PORT));}
\end{Highlighting}
\end{Shaded}

\section{Bibliography}

Ahuvia, Yogev. 2013. ``Design Patterns: Infinite Scrolling: Let's Get To
The Bottom Of This
http://uxdesign.smashingmagazine.com/2013/05/03/infinite-scrolling-get-bottom/.''
Smashing Magazine.

Conway, Mel. 2004. \emph{Humanizing Application Building: An
Anthropological Perspective}.
\url{http://melconway.com/Home/pdf/humanize.pdf}.

Cragg, Duncan. 2006. ``Duncan Cragg on Declarative Architectures: STREST
(Service-Trampled REST) Will Break Web 2.0.''
\url{http://duncan-cragg.org/blog/post/strest-service-trampled-rest-will-break-web-20/}.

Douglas, Crockford. 2009. ``JSON: The fat-free alternative to XML.''
\url{http://json.org}.

Eberhart, Andreas, and Stefan Fischer. 2002. \emph{Java Tools: Using
XML, EJB, CORBA, Servlets and SOAP}.

Etemad, Elika J, and Tab Atkins. 2013. ``Selectors Level 4.''
\url{http://dev.w3.org/csswg/selectors4/}.

Fielding, R. T. 2000. ``Principled design of the modern Web
architecture.''

Geelhoed, Erik, Peter Toft, Suzanne Roberts, and Patrick Hyland. 1995.
``To influence Time Perception.'' Hewlett Packard Labs.
\url{http://www.sigchi.org/chi95/proceedings/shortppr/egd_bdy.htm}.

Gill, Brendan. 2013. ``OpenSignal.''

Goessner, Stefan. 2007. ``JSONPath - XPath for JSON.''
\url{http://goessner.net/articles/JsonPath/}.

Guo, shu-yu. 2013. ``Two Reasons Functional Style Is Slow in
SpiderMonkey.''
\url{http://rfrn.org//~shu/2013/03/20/two-reasons-functional-style-is-slow-in-spidermonkey.html}.

Lea, Tom. 2012. ``Improving performance on twitter.com.''
\url{{[}https://blog.twitter.com/2012/improving-performance-twittercom{]}}.

Martelli, Alex. 2000. ``Discussion of typing in Python language, 2000.''
\url{https://groups.google.com/forum/?hl=en\textbackslash{}\#!msg/comp.lang.python/CCs2oJdyuzc/NYjla5HKMOIJ}.

Martin, Robert ``Uncle Bob.'' 2008. \emph{Clean Code: A Handbook of
Agile Software Craftsmanship}.

McLuhan, Marshall. 1964. \emph{Understanding Media: The Extensions of
Man}.

Ogden, Max. 2012. ``Streaming XHR.''
\url{http://maxogden.com/a-proposal-for-streaming-xhr.html}.

Reis, Eric. 2011. \emph{The Lean Startup: How Today's Entrepreneurs Use
Continuous Innovation to Create Radically Successful Businesses.} Crown
Business Publishing.

Stefanov, Stoyan. 2009. ``Progressive rendering via multiple flushes.''
\url{http://www.phpied.com/progressive-rendering-via-multiple-flushes/}.

Whorf, B. L. 1956. ``Language, Thought and Reality (ed. J. B.
Carroll).'' Cambridge, MA: MIT Press.

Yukihiro, Matsumoto. 2003. ``The Power and Philosophy of Ruby.''
\url{http://www.rubyist.net/~matz/slides/oscon2003/index.html}.

van Kesteren, Anne. 2012. ``XMLHttpRequest Level 2 Working Draft.''
\url{http://www.w3.org/TR/XMLHttpRequest2/\#make-progress-notifications}.

van Kesteren, Anne, and Dean Jackson. 2006. ``The XMLHttpRequest
Object.'' \url{http://www.w3.org/TR/2006/WD-XMLHttpRequest-20060405/}.

\end{document}
